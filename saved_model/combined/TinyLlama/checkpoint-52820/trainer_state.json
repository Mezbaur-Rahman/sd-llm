{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 19.99810695693327,
  "eval_steps": 500,
  "global_step": 52820,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "learning_rate": 0.0001999999823122357,
      "loss": 3.1141,
      "step": 10
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00019999992924894894,
      "loss": 2.2929,
      "step": 20
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00019999984081015858,
      "loss": 1.7365,
      "step": 30
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0001999997169958958,
      "loss": 1.3474,
      "step": 40
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.00019999955780620457,
      "loss": 1.3199,
      "step": 50
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.00019999936324114104,
      "loss": 1.2943,
      "step": 60
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0001999991333007741,
      "loss": 1.2672,
      "step": 70
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0001999988679851851,
      "loss": 1.2543,
      "step": 80
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.00019999856729446792,
      "loss": 1.1777,
      "step": 90
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.00019999823122872888,
      "loss": 1.2085,
      "step": 100
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0001999978597880869,
      "loss": 1.2,
      "step": 110
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.00019999745297267333,
      "loss": 1.1826,
      "step": 120
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.00019999701078263216,
      "loss": 1.168,
      "step": 130
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.00019999653321811972,
      "loss": 1.1767,
      "step": 140
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.00019999602027930506,
      "loss": 1.2418,
      "step": 150
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.00019999547196636956,
      "loss": 1.1221,
      "step": 160
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.00019999488827950724,
      "loss": 1.1108,
      "step": 170
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.00019999426921892452,
      "loss": 1.2126,
      "step": 180
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.00019999361478484045,
      "loss": 1.1492,
      "step": 190
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0001999929249774865,
      "loss": 1.1988,
      "step": 200
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.00019999219979710672,
      "loss": 1.1444,
      "step": 210
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.00019999143924395764,
      "loss": 1.1356,
      "step": 220
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0001999906433183083,
      "loss": 1.1267,
      "step": 230
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.00019998981202044028,
      "loss": 1.1764,
      "step": 240
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.00019998894535064763,
      "loss": 1.1331,
      "step": 250
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.00019998804330923699,
      "loss": 1.1357,
      "step": 260
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.00019998710589652738,
      "loss": 1.1249,
      "step": 270
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.00019998613311285047,
      "loss": 1.1331,
      "step": 280
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0001999851249585504,
      "loss": 1.1966,
      "step": 290
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.00019998408143398377,
      "loss": 1.1094,
      "step": 300
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.00019998300253951977,
      "loss": 1.1597,
      "step": 310
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.00019998188827554005,
      "loss": 1.1585,
      "step": 320
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0001999807386424388,
      "loss": 1.1301,
      "step": 330
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.00019997955364062264,
      "loss": 1.145,
      "step": 340
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.00019997833327051084,
      "loss": 1.1171,
      "step": 350
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0001999770775325351,
      "loss": 1.0888,
      "step": 360
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.00019997578642713966,
      "loss": 1.178,
      "step": 370
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0001999744599547812,
      "loss": 1.163,
      "step": 380
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.000199973098115929,
      "loss": 1.1447,
      "step": 390
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.00019997170091106482,
      "loss": 1.1252,
      "step": 400
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.00019997026834068295,
      "loss": 1.084,
      "step": 410
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.00019996880040529016,
      "loss": 1.0896,
      "step": 420
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.00019996729710540569,
      "loss": 1.2139,
      "step": 430
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.00019996575844156137,
      "loss": 1.1793,
      "step": 440
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.00019996418441430155,
      "loss": 1.0906,
      "step": 450
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.000199962575024183,
      "loss": 1.1245,
      "step": 460
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.00019996093027177506,
      "loss": 1.1044,
      "step": 470
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.00019995925015765963,
      "loss": 1.1282,
      "step": 480
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.00019995753468243094,
      "loss": 1.0581,
      "step": 490
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.00019995578384669594,
      "loss": 1.11,
      "step": 500
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.00019995399765107398,
      "loss": 1.1532,
      "step": 510
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0001999521760961969,
      "loss": 1.1226,
      "step": 520
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.00019995031918270913,
      "loss": 1.1369,
      "step": 530
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.00019994842691126757,
      "loss": 1.1323,
      "step": 540
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.00019994649928254155,
      "loss": 1.1206,
      "step": 550
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.00019994453629721307,
      "loss": 1.1112,
      "step": 560
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0001999425379559765,
      "loss": 1.1048,
      "step": 570
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.00019994050425953873,
      "loss": 1.166,
      "step": 580
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0001999384352086193,
      "loss": 1.1404,
      "step": 590
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.00019993633080395,
      "loss": 1.1398,
      "step": 600
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.00019993419104627534,
      "loss": 1.1607,
      "step": 610
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.00019993201593635233,
      "loss": 1.1587,
      "step": 620
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.00019992980547495036,
      "loss": 1.2019,
      "step": 630
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0001999275596628514,
      "loss": 1.1282,
      "step": 640
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00019992527850084995,
      "loss": 1.0726,
      "step": 650
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00019992296198975297,
      "loss": 1.0657,
      "step": 660
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0001999206101303799,
      "loss": 1.1447,
      "step": 670
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.00019991822292356274,
      "loss": 1.1188,
      "step": 680
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.000199915800370146,
      "loss": 1.0952,
      "step": 690
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.00019991334247098665,
      "loss": 1.1632,
      "step": 700
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.00019991084922695422,
      "loss": 1.1744,
      "step": 710
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0001999083206389307,
      "loss": 1.1223,
      "step": 720
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0001999057567078105,
      "loss": 1.1305,
      "step": 730
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.00019990315743450077,
      "loss": 1.0593,
      "step": 740
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.00019990052281992088,
      "loss": 1.1577,
      "step": 750
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.00019989785286500295,
      "loss": 1.1166,
      "step": 760
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.00019989514757069143,
      "loss": 1.1115,
      "step": 770
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.00019989240693794335,
      "loss": 1.0953,
      "step": 780
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0001998896309677282,
      "loss": 1.1216,
      "step": 790
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.00019988681966102802,
      "loss": 1.0592,
      "step": 800
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.00019988397301883733,
      "loss": 1.1238,
      "step": 810
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.00019988109104216313,
      "loss": 1.0708,
      "step": 820
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.00019987817373202493,
      "loss": 1.0869,
      "step": 830
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.00019987522108945476,
      "loss": 1.1536,
      "step": 840
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.00019987223311549712,
      "loss": 1.1178,
      "step": 850
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.00019986920981120902,
      "loss": 1.0466,
      "step": 860
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.00019986615117765998,
      "loss": 1.1449,
      "step": 870
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.000199863057215932,
      "loss": 1.1418,
      "step": 880
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0001998599279271196,
      "loss": 1.1036,
      "step": 890
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.00019985676331232973,
      "loss": 1.0908,
      "step": 900
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.000199853563372682,
      "loss": 1.1032,
      "step": 910
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.00019985032810930828,
      "loss": 1.0961,
      "step": 920
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.00019984705752335312,
      "loss": 1.0735,
      "step": 930
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.00019984375161597354,
      "loss": 1.0727,
      "step": 940
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.00019984041038833896,
      "loss": 1.082,
      "step": 950
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0001998370338416314,
      "loss": 1.1294,
      "step": 960
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0001998336219770453,
      "loss": 1.1187,
      "step": 970
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.00019983017479578762,
      "loss": 1.0906,
      "step": 980
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.00019982669229907785,
      "loss": 1.1087,
      "step": 990
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.00019982317448814798,
      "loss": 1.0738,
      "step": 1000
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.00019981962136424235,
      "loss": 1.0484,
      "step": 1010
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.00019981603292861796,
      "loss": 1.0774,
      "step": 1020
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.00019981240918254424,
      "loss": 1.1189,
      "step": 1030
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.00019980875012730312,
      "loss": 1.1312,
      "step": 1040
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.00019980505576418892,
      "loss": 1.122,
      "step": 1050
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.00019980132609450868,
      "loss": 1.1497,
      "step": 1060
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0001997975611195817,
      "loss": 1.0612,
      "step": 1070
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.00019979376084073986,
      "loss": 1.1015,
      "step": 1080
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.00019978992525932756,
      "loss": 1.0928,
      "step": 1090
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0001997860543767016,
      "loss": 1.0833,
      "step": 1100
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.00019978214819423143,
      "loss": 1.1264,
      "step": 1110
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0001997782067132988,
      "loss": 1.1152,
      "step": 1120
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.00019977422993529807,
      "loss": 1.1907,
      "step": 1130
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.00019977021786163598,
      "loss": 1.0962,
      "step": 1140
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0001997661704937319,
      "loss": 1.1255,
      "step": 1150
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0001997620878330176,
      "loss": 1.1407,
      "step": 1160
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00019975796988093731,
      "loss": 1.0892,
      "step": 1170
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00019975381663894779,
      "loss": 1.0858,
      "step": 1180
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00019974962810851828,
      "loss": 1.0721,
      "step": 1190
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00019974540429113045,
      "loss": 1.1023,
      "step": 1200
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00019974114518827855,
      "loss": 1.1151,
      "step": 1210
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00019973685080146923,
      "loss": 1.1128,
      "step": 1220
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.00019973252113222168,
      "loss": 1.0939,
      "step": 1230
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.00019972815618206753,
      "loss": 1.0591,
      "step": 1240
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0001997237559525509,
      "loss": 1.0469,
      "step": 1250
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00019971932044522838,
      "loss": 1.1517,
      "step": 1260
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0001997148496616691,
      "loss": 1.0847,
      "step": 1270
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00019971034360345458,
      "loss": 1.119,
      "step": 1280
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.00019970580227217887,
      "loss": 1.123,
      "step": 1290
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0001997012256694485,
      "loss": 1.0929,
      "step": 1300
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.00019969661379688248,
      "loss": 1.1001,
      "step": 1310
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.00019969196665611225,
      "loss": 1.1207,
      "step": 1320
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.00019968728424878175,
      "loss": 1.0961,
      "step": 1330
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0001996825665765475,
      "loss": 1.0926,
      "step": 1340
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0001996778136410783,
      "loss": 1.1181,
      "step": 1350
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00019967302544405556,
      "loss": 1.0387,
      "step": 1360
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.00019966820198717312,
      "loss": 1.0465,
      "step": 1370
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.00019966334327213735,
      "loss": 1.0819,
      "step": 1380
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.000199658449300667,
      "loss": 1.0974,
      "step": 1390
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.00019965352007449334,
      "loss": 1.0982,
      "step": 1400
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.00019964855559536013,
      "loss": 1.1253,
      "step": 1410
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.00019964355586502355,
      "loss": 1.1462,
      "step": 1420
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.00019963852088525233,
      "loss": 1.0672,
      "step": 1430
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0001996334506578276,
      "loss": 1.1462,
      "step": 1440
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00019962834518454293,
      "loss": 1.1167,
      "step": 1450
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0001996232044672045,
      "loss": 1.1074,
      "step": 1460
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00019961802850763076,
      "loss": 1.1606,
      "step": 1470
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00019961281730765282,
      "loss": 1.1232,
      "step": 1480
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00019960757086911413,
      "loss": 1.1019,
      "step": 1490
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.00019960228919387065,
      "loss": 1.1449,
      "step": 1500
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.00019959697228379085,
      "loss": 1.1106,
      "step": 1510
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.00019959162014075553,
      "loss": 1.0661,
      "step": 1520
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.00019958623276665808,
      "loss": 1.0812,
      "step": 1530
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0001995808101634043,
      "loss": 1.0774,
      "step": 1540
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0001995753523329125,
      "loss": 1.0234,
      "step": 1550
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.00019956985927711338,
      "loss": 1.1318,
      "step": 1560
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.00019956433099795016,
      "loss": 1.0766,
      "step": 1570
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00019955876749737847,
      "loss": 1.1129,
      "step": 1580
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00019955316877736645,
      "loss": 1.1215,
      "step": 1590
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00019954753483989468,
      "loss": 1.1492,
      "step": 1600
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0001995418656869562,
      "loss": 1.1412,
      "step": 1610
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00019953616132055646,
      "loss": 1.1615,
      "step": 1620
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.00019953042174271346,
      "loss": 1.1385,
      "step": 1630
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.00019952464695545757,
      "loss": 1.098,
      "step": 1640
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.00019951883696083168,
      "loss": 1.0294,
      "step": 1650
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.00019951299176089107,
      "loss": 1.0733,
      "step": 1660
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.00019950711135770358,
      "loss": 1.0984,
      "step": 1670
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00019950119575334933,
      "loss": 1.0977,
      "step": 1680
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00019949524494992108,
      "loss": 1.0609,
      "step": 1690
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00019948925894952395,
      "loss": 1.0748,
      "step": 1700
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0001994832377542755,
      "loss": 1.1451,
      "step": 1710
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.00019947718136630575,
      "loss": 1.0535,
      "step": 1720
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0001994710897877572,
      "loss": 1.1006,
      "step": 1730
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00019946496302078473,
      "loss": 1.1112,
      "step": 1740
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00019945880106755575,
      "loss": 1.1088,
      "step": 1750
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00019945260393025013,
      "loss": 1.0624,
      "step": 1760
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00019944637161106013,
      "loss": 1.1093,
      "step": 1770
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00019944010411219036,
      "loss": 1.1149,
      "step": 1780
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0001994338014358581,
      "loss": 1.095,
      "step": 1790
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0001994274635842929,
      "loss": 1.0973,
      "step": 1800
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00019942109055973682,
      "loss": 1.0933,
      "step": 1810
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00019941468236444433,
      "loss": 1.1035,
      "step": 1820
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0001994082390006824,
      "loss": 1.0282,
      "step": 1830
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.00019940176047073037,
      "loss": 1.1067,
      "step": 1840
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0001993952467768801,
      "loss": 1.1372,
      "step": 1850
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0001993886979214358,
      "loss": 1.0981,
      "step": 1860
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.00019938211390671415,
      "loss": 1.103,
      "step": 1870
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.00019937549473504436,
      "loss": 1.082,
      "step": 1880
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00019936884040876792,
      "loss": 1.0706,
      "step": 1890
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00019936215093023884,
      "loss": 1.1423,
      "step": 1900
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00019935542630182359,
      "loss": 1.0575,
      "step": 1910
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.000199348666525901,
      "loss": 1.0905,
      "step": 1920
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00019934187160486244,
      "loss": 1.0892,
      "step": 1930
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00019933504154111162,
      "loss": 1.0808,
      "step": 1940
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0001993281763370647,
      "loss": 1.1151,
      "step": 1950
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.00019932127599515023,
      "loss": 1.0904,
      "step": 1960
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00019931434051780937,
      "loss": 1.093,
      "step": 1970
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00019930736990749547,
      "loss": 1.0942,
      "step": 1980
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00019930036416667448,
      "loss": 1.1155,
      "step": 1990
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00019929332329782467,
      "loss": 1.0611,
      "step": 2000
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0001992862473034369,
      "loss": 1.0991,
      "step": 2010
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00019927913618601417,
      "loss": 1.0968,
      "step": 2020
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.00019927198994807216,
      "loss": 1.0787,
      "step": 2030
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0001992648085921389,
      "loss": 1.104,
      "step": 2040
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00019925759212075485,
      "loss": 1.1683,
      "step": 2050
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00019925034053647285,
      "loss": 1.1263,
      "step": 2060
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00019924305384185815,
      "loss": 1.1252,
      "step": 2070
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00019923573203948851,
      "loss": 1.0603,
      "step": 2080
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00019922837513195403,
      "loss": 1.1433,
      "step": 2090
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00019922098312185726,
      "loss": 1.1129,
      "step": 2100
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00019921355601181317,
      "loss": 1.0423,
      "step": 2110
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00019920609380444916,
      "loss": 1.0341,
      "step": 2120
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00019919859650240494,
      "loss": 1.1263,
      "step": 2130
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0001991910641083328,
      "loss": 1.0533,
      "step": 2140
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00019918349662489737,
      "loss": 1.0736,
      "step": 2150
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0001991758940547756,
      "loss": 1.0975,
      "step": 2160
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00019916825640065705,
      "loss": 1.0952,
      "step": 2170
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00019916058366524353,
      "loss": 1.0788,
      "step": 2180
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00019915287585124932,
      "loss": 1.091,
      "step": 2190
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00019914513296140105,
      "loss": 1.0685,
      "step": 2200
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00019913735499843787,
      "loss": 1.0747,
      "step": 2210
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00019912954196511125,
      "loss": 1.1185,
      "step": 2220
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0001991216938641851,
      "loss": 1.0378,
      "step": 2230
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0001991138106984357,
      "loss": 1.11,
      "step": 2240
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00019910589247065184,
      "loss": 1.1185,
      "step": 2250
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.00019909793918363453,
      "loss": 1.0891,
      "step": 2260
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.00019908995084019735,
      "loss": 1.1041,
      "step": 2270
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0001990819274431662,
      "loss": 1.0617,
      "step": 2280
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.00019907386899537942,
      "loss": 1.0975,
      "step": 2290
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.00019906577549968772,
      "loss": 1.1251,
      "step": 2300
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0001990576469589542,
      "loss": 1.1103,
      "step": 2310
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.00019904948337605438,
      "loss": 1.0289,
      "step": 2320
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.00019904128475387617,
      "loss": 1.1271,
      "step": 2330
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.00019903305109531991,
      "loss": 1.0316,
      "step": 2340
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.00019902478240329825,
      "loss": 1.0811,
      "step": 2350
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0001990164786807363,
      "loss": 1.0882,
      "step": 2360
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.00019900813993057158,
      "loss": 1.1035,
      "step": 2370
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.00019899976615575388,
      "loss": 1.0447,
      "step": 2380
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.00019899135735924555,
      "loss": 1.1274,
      "step": 2390
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00019898291354402125,
      "loss": 1.0632,
      "step": 2400
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.000198974434713068,
      "loss": 1.0675,
      "step": 2410
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.00019896592086938517,
      "loss": 1.0366,
      "step": 2420
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.00019895737201598468,
      "loss": 1.0205,
      "step": 2430
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.00019894878815589068,
      "loss": 1.1073,
      "step": 2440
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.00019894016929213976,
      "loss": 1.0427,
      "step": 2450
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.00019893151542778087,
      "loss": 1.1277,
      "step": 2460
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0001989228265658754,
      "loss": 1.1017,
      "step": 2470
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00019891410270949704,
      "loss": 1.0922,
      "step": 2480
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00019890534386173196,
      "loss": 1.0724,
      "step": 2490
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00019889655002567857,
      "loss": 1.08,
      "step": 2500
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0001988877212044478,
      "loss": 1.1291,
      "step": 2510
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0001988788574011629,
      "loss": 1.0176,
      "step": 2520
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0001988699586189594,
      "loss": 1.0921,
      "step": 2530
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.00019886102486098536,
      "loss": 1.0637,
      "step": 2540
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00019885205613040115,
      "loss": 1.1151,
      "step": 2550
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0001988430524303795,
      "loss": 1.0627,
      "step": 2560
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00019883401376410547,
      "loss": 1.0748,
      "step": 2570
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00019882494013477654,
      "loss": 1.0195,
      "step": 2580
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00019881583154560267,
      "loss": 1.052,
      "step": 2590
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00019880668799980594,
      "loss": 1.0481,
      "step": 2600
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.00019879750950062096,
      "loss": 1.0559,
      "step": 2610
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0001987882960512947,
      "loss": 1.1242,
      "step": 2620
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00019877904765508645,
      "loss": 1.0823,
      "step": 2630
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00019876976431526788,
      "loss": 1.1026,
      "step": 2640
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00019876044603512304,
      "loss": 1.0216,
      "step": 2650
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00019875109281794825,
      "loss": 1.0493,
      "step": 2660
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00019874170466705238,
      "loss": 1.0717,
      "step": 2670
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00019873228158575644,
      "loss": 1.0533,
      "step": 2680
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.00019872282357739392,
      "loss": 1.0344,
      "step": 2690
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.00019871333064531066,
      "loss": 1.0516,
      "step": 2700
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0001987038027928648,
      "loss": 1.0876,
      "step": 2710
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0001986942400234269,
      "loss": 1.0315,
      "step": 2720
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00019868464234037986,
      "loss": 1.1245,
      "step": 2730
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.00019867500974711885,
      "loss": 1.0558,
      "step": 2740
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.00019866534224705147,
      "loss": 1.1052,
      "step": 2750
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.00019865563984359768,
      "loss": 1.1135,
      "step": 2760
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0001986459025401897,
      "loss": 1.0974,
      "step": 2770
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.00019863613034027224,
      "loss": 1.0834,
      "step": 2780
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0001986263232473022,
      "loss": 1.0627,
      "step": 2790
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0001986164812647489,
      "loss": 1.0064,
      "step": 2800
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.00019860660439609403,
      "loss": 1.048,
      "step": 2810
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.00019859669264483154,
      "loss": 1.0544,
      "step": 2820
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.00019858674601446776,
      "loss": 1.0256,
      "step": 2830
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.00019857676450852138,
      "loss": 1.0761,
      "step": 2840
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.00019856674813052344,
      "loss": 1.0798,
      "step": 2850
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.00019855669688401725,
      "loss": 1.051,
      "step": 2860
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.00019854661077255853,
      "loss": 1.1061,
      "step": 2870
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.00019853648979971522,
      "loss": 1.0079,
      "step": 2880
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.00019852633396906774,
      "loss": 1.0969,
      "step": 2890
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.00019851614328420872,
      "loss": 1.0761,
      "step": 2900
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.00019850591774874324,
      "loss": 1.0672,
      "step": 2910
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.00019849565736628858,
      "loss": 1.0583,
      "step": 2920
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.00019848536214047438,
      "loss": 1.0104,
      "step": 2930
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.00019847503207494268,
      "loss": 1.0777,
      "step": 2940
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.00019846466717334777,
      "loss": 1.1307,
      "step": 2950
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0001984542674393563,
      "loss": 1.066,
      "step": 2960
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.00019844383287664726,
      "loss": 1.0507,
      "step": 2970
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.00019843336348891185,
      "loss": 1.1018,
      "step": 2980
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.00019842285927985378,
      "loss": 1.0783,
      "step": 2990
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.00019841232025318887,
      "loss": 1.0532,
      "step": 3000
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0001984017464126454,
      "loss": 1.0402,
      "step": 3010
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.00019839113776196396,
      "loss": 1.0934,
      "step": 3020
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.00019838049430489734,
      "loss": 1.0756,
      "step": 3030
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.00019836981604521076,
      "loss": 1.0636,
      "step": 3040
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0001983591029866817,
      "loss": 1.0323,
      "step": 3050
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.00019834835513310003,
      "loss": 1.0729,
      "step": 3060
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0001983375724882677,
      "loss": 1.0776,
      "step": 3070
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0001983267550559993,
      "loss": 1.0438,
      "step": 3080
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.00019831590284012144,
      "loss": 1.0858,
      "step": 3090
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.00019830501584447324,
      "loss": 1.042,
      "step": 3100
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.00019829409407290594,
      "loss": 1.1062,
      "step": 3110
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0001982831375292832,
      "loss": 1.0862,
      "step": 3120
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.00019827214621748098,
      "loss": 1.0366,
      "step": 3130
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.00019826112014138754,
      "loss": 1.0949,
      "step": 3140
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.00019825005930490335,
      "loss": 1.1243,
      "step": 3150
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.00019823896371194124,
      "loss": 1.1065,
      "step": 3160
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.00019822783336642642,
      "loss": 1.0569,
      "step": 3170
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.00019821666827229623,
      "loss": 1.1012,
      "step": 3180
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.00019820546843350037,
      "loss": 1.0137,
      "step": 3190
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0001981942338540009,
      "loss": 1.0908,
      "step": 3200
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.00019818296453777206,
      "loss": 1.016,
      "step": 3210
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.00019817166048880048,
      "loss": 1.0796,
      "step": 3220
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.000198160321711085,
      "loss": 1.0725,
      "step": 3230
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.00019814894820863676,
      "loss": 1.0854,
      "step": 3240
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.00019813753998547924,
      "loss": 1.064,
      "step": 3250
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0001981260970456481,
      "loss": 1.0765,
      "step": 3260
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.00019811461939319138,
      "loss": 1.0551,
      "step": 3270
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.00019810310703216938,
      "loss": 1.0886,
      "step": 3280
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.00019809155996665457,
      "loss": 1.1052,
      "step": 3290
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0001980799782007319,
      "loss": 1.0807,
      "step": 3300
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0001980683617384984,
      "loss": 1.0349,
      "step": 3310
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0001980567105840635,
      "loss": 1.0137,
      "step": 3320
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.00019804502474154884,
      "loss": 1.037,
      "step": 3330
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.00019803330421508833,
      "loss": 1.0795,
      "step": 3340
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0001980215490088282,
      "loss": 1.1023,
      "step": 3350
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0001980097591269269,
      "loss": 1.1151,
      "step": 3360
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.00019799793457355515,
      "loss": 1.1022,
      "step": 3370
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.00019798607535289597,
      "loss": 1.0755,
      "step": 3380
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.00019797418146914463,
      "loss": 1.0986,
      "step": 3390
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0001979622529265086,
      "loss": 1.1372,
      "step": 3400
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.00019795028972920776,
      "loss": 1.0873,
      "step": 3410
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.00019793829188147406,
      "loss": 1.0715,
      "step": 3420
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.00019792625938755184,
      "loss": 1.0624,
      "step": 3430
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0001979141922516977,
      "loss": 1.0493,
      "step": 3440
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.00019790209047818036,
      "loss": 1.0347,
      "step": 3450
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.00019788995407128097,
      "loss": 1.0614,
      "step": 3460
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0001978777830352928,
      "loss": 1.0631,
      "step": 3470
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.00019786557737452146,
      "loss": 1.0458,
      "step": 3480
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.00019785333709328474,
      "loss": 1.117,
      "step": 3490
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.00019784106219591268,
      "loss": 1.0833,
      "step": 3500
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.00019782875268674764,
      "loss": 1.0804,
      "step": 3510
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.00019781640857014413,
      "loss": 1.1021,
      "step": 3520
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.00019780402985046899,
      "loss": 1.0665,
      "step": 3530
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0001977916165321012,
      "loss": 1.105,
      "step": 3540
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.00019777916861943212,
      "loss": 1.0617,
      "step": 3550
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.00019776668611686516,
      "loss": 1.0683,
      "step": 3560
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0001977541690288162,
      "loss": 1.1159,
      "step": 3570
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00019774161735971308,
      "loss": 1.0521,
      "step": 3580
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00019772903111399615,
      "loss": 1.0897,
      "step": 3590
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00019771641029611776,
      "loss": 1.0743,
      "step": 3600
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00019770375491054266,
      "loss": 1.1136,
      "step": 3610
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0001976910649617477,
      "loss": 1.0316,
      "step": 3620
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0001976783404542221,
      "loss": 1.0306,
      "step": 3630
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00019766558139246713,
      "loss": 1.0847,
      "step": 3640
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00019765278778099645,
      "loss": 1.0429,
      "step": 3650
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0001976399596243358,
      "loss": 1.1026,
      "step": 3660
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00019762709692702332,
      "loss": 1.0694,
      "step": 3670
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0001976141996936091,
      "loss": 1.0018,
      "step": 3680
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0001976012679286557,
      "loss": 1.0598,
      "step": 3690
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00019758830163673784,
      "loss": 1.0313,
      "step": 3700
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0001975753008224423,
      "loss": 1.0381,
      "step": 3710
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0001975622654903683,
      "loss": 1.0959,
      "step": 3720
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00019754919564512707,
      "loss": 1.1001,
      "step": 3730
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00019753609129134216,
      "loss": 1.0579,
      "step": 3740
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00019752295243364933,
      "loss": 1.0087,
      "step": 3750
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00019750977907669653,
      "loss": 1.1023,
      "step": 3760
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00019749657122514384,
      "loss": 1.1029,
      "step": 3770
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00019748332888366366,
      "loss": 1.0991,
      "step": 3780
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00019747005205694054,
      "loss": 1.0403,
      "step": 3790
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0001974567407496712,
      "loss": 1.056,
      "step": 3800
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0001974433949665646,
      "loss": 1.0619,
      "step": 3810
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00019743001471234193,
      "loss": 1.0417,
      "step": 3820
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00019741659999173642,
      "loss": 1.0685,
      "step": 3830
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00019740315080949368,
      "loss": 1.0514,
      "step": 3840
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0001973896671703714,
      "loss": 1.0091,
      "step": 3850
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00019737614907913947,
      "loss": 1.0377,
      "step": 3860
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00019736259654058003,
      "loss": 1.0613,
      "step": 3870
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00019734900955948735,
      "loss": 1.0082,
      "step": 3880
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0001973353881406679,
      "loss": 1.0708,
      "step": 3890
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00019732173228894026,
      "loss": 1.0882,
      "step": 3900
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00019730804200913536,
      "loss": 1.1159,
      "step": 3910
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00019729431730609615,
      "loss": 1.0818,
      "step": 3920
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00019728055818467785,
      "loss": 1.0636,
      "step": 3930
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0001972667646497478,
      "loss": 1.0651,
      "step": 3940
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0001972529367061855,
      "loss": 1.1319,
      "step": 3950
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00019723907435888273,
      "loss": 1.083,
      "step": 3960
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00019722517761274334,
      "loss": 1.0423,
      "step": 3970
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00019721124647268336,
      "loss": 1.0918,
      "step": 3980
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00019719728094363105,
      "loss": 1.0448,
      "step": 3990
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00019718328103052673,
      "loss": 1.0646,
      "step": 4000
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00019716924673832297,
      "loss": 1.09,
      "step": 4010
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00019715517807198448,
      "loss": 1.0664,
      "step": 4020
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0001971410750364881,
      "loss": 1.0911,
      "step": 4030
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00019712693763682292,
      "loss": 1.0915,
      "step": 4040
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00019711276587799006,
      "loss": 1.0446,
      "step": 4050
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00019709855976500284,
      "loss": 1.0961,
      "step": 4060
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0001970843193028868,
      "loss": 1.0847,
      "step": 4070
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00019707004449667957,
      "loss": 1.0523,
      "step": 4080
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0001970557353514309,
      "loss": 1.0829,
      "step": 4090
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00019704139187220275,
      "loss": 1.0504,
      "step": 4100
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0001970270140640692,
      "loss": 1.0466,
      "step": 4110
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00019701260193211647,
      "loss": 1.094,
      "step": 4120
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00019699815548144297,
      "loss": 1.0563,
      "step": 4130
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00019698367471715912,
      "loss": 1.109,
      "step": 4140
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00019696915964438768,
      "loss": 1.1005,
      "step": 4150
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00019695461026826333,
      "loss": 1.0686,
      "step": 4160
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00019694002659393305,
      "loss": 1.0535,
      "step": 4170
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00019692540862655585,
      "loss": 1.0171,
      "step": 4180
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00019691075637130298,
      "loss": 1.0822,
      "step": 4190
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0001968960698333577,
      "loss": 1.0691,
      "step": 4200
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0001968813490179154,
      "loss": 1.0766,
      "step": 4210
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00019686659393018378,
      "loss": 1.0671,
      "step": 4220
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00019685180457538245,
      "loss": 1.1065,
      "step": 4230
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0001968369809587432,
      "loss": 1.1174,
      "step": 4240
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00019682212308550997,
      "loss": 1.074,
      "step": 4250
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0001968072309609389,
      "loss": 1.1011,
      "step": 4260
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00019679230459029805,
      "loss": 1.098,
      "step": 4270
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00019677734397886775,
      "loss": 1.0935,
      "step": 4280
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00019676234913194038,
      "loss": 1.0932,
      "step": 4290
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00019674732005482047,
      "loss": 1.0426,
      "step": 4300
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0001967322567528246,
      "loss": 1.0161,
      "step": 4310
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00019671715923128154,
      "loss": 1.052,
      "step": 4320
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00019670202749553207,
      "loss": 0.9789,
      "step": 4330
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00019668686155092916,
      "loss": 1.0906,
      "step": 4340
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00019667166140283784,
      "loss": 1.059,
      "step": 4350
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001966564270566352,
      "loss": 1.0662,
      "step": 4360
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001966411585177105,
      "loss": 1.0788,
      "step": 4370
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00019662585579146509,
      "loss": 1.0738,
      "step": 4380
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00019661051888331235,
      "loss": 1.0982,
      "step": 4390
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0001965951477986778,
      "loss": 1.0784,
      "step": 4400
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00019657974254299907,
      "loss": 1.0381,
      "step": 4410
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00019656430312172584,
      "loss": 1.1337,
      "step": 4420
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00019654882954031985,
      "loss": 1.0243,
      "step": 4430
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.000196533321804255,
      "loss": 1.1627,
      "step": 4440
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001965177799190172,
      "loss": 1.0836,
      "step": 4450
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00019650220389010454,
      "loss": 1.0395,
      "step": 4460
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00019648659372302707,
      "loss": 1.0744,
      "step": 4470
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00019647094942330698,
      "loss": 1.0395,
      "step": 4480
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00019645527099647851,
      "loss": 1.1267,
      "step": 4490
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00019643955844808798,
      "loss": 1.0602,
      "step": 4500
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00019642381178369385,
      "loss": 1.0615,
      "step": 4510
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0001964080310088665,
      "loss": 1.0617,
      "step": 4520
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00019639221612918853,
      "loss": 1.093,
      "step": 4530
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00019637636715025454,
      "loss": 1.0928,
      "step": 4540
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00019636048407767112,
      "loss": 1.0543,
      "step": 4550
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.00019634456691705702,
      "loss": 1.0548,
      "step": 4560
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.0001963286156740431,
      "loss": 1.0719,
      "step": 4570
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.00019631263035427206,
      "loss": 1.1279,
      "step": 4580
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.0001962966109633989,
      "loss": 1.0222,
      "step": 4590
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.0001962805575070905,
      "loss": 1.0655,
      "step": 4600
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.0001962644699910259,
      "loss": 1.0759,
      "step": 4610
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.00019624834842089613,
      "loss": 1.0615,
      "step": 4620
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.00019623219280240424,
      "loss": 1.0466,
      "step": 4630
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.0001962160031412654,
      "loss": 1.066,
      "step": 4640
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.00019619977944320682,
      "loss": 1.0249,
      "step": 4650
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.00019618352171396768,
      "loss": 1.0766,
      "step": 4660
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.00019616722995929924,
      "loss": 1.0651,
      "step": 4670
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.0001961509041849648,
      "loss": 1.0295,
      "step": 4680
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.00019613454439673967,
      "loss": 1.0952,
      "step": 4690
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.00019611815060041125,
      "loss": 1.0889,
      "step": 4700
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.00019610172280177892,
      "loss": 1.062,
      "step": 4710
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.00019608526100665406,
      "loss": 1.0408,
      "step": 4720
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.0001960687652208602,
      "loss": 1.0224,
      "step": 4730
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.00019605223545023271,
      "loss": 1.1078,
      "step": 4740
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.00019603567170061917,
      "loss": 1.0163,
      "step": 4750
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.00019601907397787902,
      "loss": 1.0458,
      "step": 4760
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.00019600244228788386,
      "loss": 1.0213,
      "step": 4770
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.0001959857766365172,
      "loss": 1.0971,
      "step": 4780
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.00019596907702967462,
      "loss": 1.0025,
      "step": 4790
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.0001959523434732637,
      "loss": 1.0403,
      "step": 4800
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.00019593557597320395,
      "loss": 1.0493,
      "step": 4810
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.0001959187745354271,
      "loss": 1.0828,
      "step": 4820
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.0001959019391658766,
      "loss": 1.0384,
      "step": 4830
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.00019588506987050814,
      "loss": 1.0814,
      "step": 4840
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.00019586816665528934,
      "loss": 1.0434,
      "step": 4850
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.00019585122952619973,
      "loss": 1.0587,
      "step": 4860
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.00019583425848923092,
      "loss": 1.0859,
      "step": 4870
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.00019581725355038656,
      "loss": 1.0326,
      "step": 4880
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.0001958002147156822,
      "loss": 1.0417,
      "step": 4890
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.00019578314199114542,
      "loss": 1.0217,
      "step": 4900
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.00019576603538281579,
      "loss": 1.0275,
      "step": 4910
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.00019574889489674485,
      "loss": 1.0934,
      "step": 4920
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.00019573172053899619,
      "loss": 1.0706,
      "step": 4930
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.00019571451231564525,
      "loss": 1.0587,
      "step": 4940
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.00019569727023277956,
      "loss": 1.0851,
      "step": 4950
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.00019567999429649863,
      "loss": 1.1121,
      "step": 4960
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.00019566268451291386,
      "loss": 1.0157,
      "step": 4970
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.00019564534088814875,
      "loss": 1.0784,
      "step": 4980
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.00019562796342833863,
      "loss": 1.0856,
      "step": 4990
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.0001956105521396309,
      "loss": 1.0585,
      "step": 5000
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.0001955931070281849,
      "loss": 1.0568,
      "step": 5010
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.00019557562810017191,
      "loss": 1.0406,
      "step": 5020
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.00019555811536177523,
      "loss": 1.0318,
      "step": 5030
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.00019554056881919003,
      "loss": 1.1189,
      "step": 5040
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.00019552298847862353,
      "loss": 1.0821,
      "step": 5050
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.00019550537434629485,
      "loss": 1.0299,
      "step": 5060
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.00019548772642843509,
      "loss": 1.0503,
      "step": 5070
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.0001954700447312873,
      "loss": 1.094,
      "step": 5080
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.00019545232926110648,
      "loss": 1.0218,
      "step": 5090
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.00019543458002415956,
      "loss": 1.0744,
      "step": 5100
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.00019541679702672542,
      "loss": 1.1155,
      "step": 5110
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.00019539898027509488,
      "loss": 1.0626,
      "step": 5120
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.00019538112977557075,
      "loss": 1.0145,
      "step": 5130
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.0001953632455344677,
      "loss": 1.0787,
      "step": 5140
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.0001953453275581124,
      "loss": 1.0247,
      "step": 5150
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.00019532737585284342,
      "loss": 1.0757,
      "step": 5160
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.00019530939042501126,
      "loss": 1.0885,
      "step": 5170
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.00019529137128097837,
      "loss": 1.0636,
      "step": 5180
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.0001952733184271191,
      "loss": 1.091,
      "step": 5190
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.0001952552318698198,
      "loss": 1.0995,
      "step": 5200
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.00019523711161547862,
      "loss": 1.0787,
      "step": 5210
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.00019521895767050574,
      "loss": 1.0845,
      "step": 5220
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.00019520077004132316,
      "loss": 1.0719,
      "step": 5230
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.0001951825487343649,
      "loss": 1.0418,
      "step": 5240
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.00019516429375607684,
      "loss": 1.02,
      "step": 5250
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.00019514600511291675,
      "loss": 1.0663,
      "step": 5260
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.00019512768281135435,
      "loss": 1.0899,
      "step": 5270
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.00019510932685787123,
      "loss": 1.0695,
      "step": 5280
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.00019509093725896096,
      "loss": 1.0764,
      "step": 5290
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.0001950725140211289,
      "loss": 1.0232,
      "step": 5300
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.0001950540571508924,
      "loss": 1.032,
      "step": 5310
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.00019503556665478067,
      "loss": 1.062,
      "step": 5320
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.0001950170425393348,
      "loss": 1.013,
      "step": 5330
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.0001949984848111078,
      "loss": 1.0244,
      "step": 5340
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.00019497989347666458,
      "loss": 1.0793,
      "step": 5350
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.00019496126854258195,
      "loss": 1.0369,
      "step": 5360
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.0001949426100154485,
      "loss": 1.0688,
      "step": 5370
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.00019492391790186487,
      "loss": 1.0674,
      "step": 5380
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.00019490519220844343,
      "loss": 0.9696,
      "step": 5390
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.00019488643294180853,
      "loss": 1.0579,
      "step": 5400
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.0001948676401085963,
      "loss": 1.0477,
      "step": 5410
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.0001948488137154549,
      "loss": 1.0596,
      "step": 5420
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.0001948299537690442,
      "loss": 1.056,
      "step": 5430
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.000194811060276036,
      "loss": 1.0374,
      "step": 5440
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.00019479213324311403,
      "loss": 1.0644,
      "step": 5450
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.00019477317267697377,
      "loss": 1.0658,
      "step": 5460
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.00019475417858432262,
      "loss": 0.9741,
      "step": 5470
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.0001947351509718799,
      "loss": 1.0319,
      "step": 5480
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.00019471608984637667,
      "loss": 0.9941,
      "step": 5490
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.00019469699521455596,
      "loss": 1.086,
      "step": 5500
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.00019467786708317255,
      "loss": 1.0383,
      "step": 5510
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.0001946587054589931,
      "loss": 1.0783,
      "step": 5520
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.0001946395103487962,
      "loss": 1.0267,
      "step": 5530
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.00019462028175937216,
      "loss": 1.0553,
      "step": 5540
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.00019460101969752324,
      "loss": 1.0032,
      "step": 5550
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.00019458172417006347,
      "loss": 1.0928,
      "step": 5560
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.00019456239518381879,
      "loss": 1.1078,
      "step": 5570
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.00019454303274562683,
      "loss": 1.0246,
      "step": 5580
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.00019452363686233727,
      "loss": 1.0467,
      "step": 5590
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.00019450420754081143,
      "loss": 1.103,
      "step": 5600
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.00019448474478792258,
      "loss": 1.0801,
      "step": 5610
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.00019446524861055573,
      "loss": 1.0931,
      "step": 5620
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.0001944457190156078,
      "loss": 1.0726,
      "step": 5630
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.00019442615600998747,
      "loss": 1.042,
      "step": 5640
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.00019440655960061522,
      "loss": 1.0725,
      "step": 5650
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.00019438692979442345,
      "loss": 1.0918,
      "step": 5660
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.00019436726659835627,
      "loss": 1.0249,
      "step": 5670
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.00019434757001936964,
      "loss": 1.0277,
      "step": 5680
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.00019432784006443132,
      "loss": 0.9854,
      "step": 5690
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.00019430807674052092,
      "loss": 1.0737,
      "step": 5700
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.00019428828005462978,
      "loss": 0.994,
      "step": 5710
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.00019426845001376114,
      "loss": 1.0514,
      "step": 5720
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.0001942485866249299,
      "loss": 1.039,
      "step": 5730
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.00019422868989516287,
      "loss": 1.0697,
      "step": 5740
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.00019420875983149866,
      "loss": 1.0786,
      "step": 5750
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.0001941887964409876,
      "loss": 1.0405,
      "step": 5760
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.0001941687997306919,
      "loss": 1.0438,
      "step": 5770
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.00019414876970768542,
      "loss": 1.0582,
      "step": 5780
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.00019412870637905392,
      "loss": 1.0569,
      "step": 5790
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.00019410860975189488,
      "loss": 1.0481,
      "step": 5800
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.0001940884798333177,
      "loss": 1.0474,
      "step": 5810
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.00019406831663044329,
      "loss": 1.0578,
      "step": 5820
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.00019404812015040462,
      "loss": 1.0506,
      "step": 5830
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.00019402789040034622,
      "loss": 1.0512,
      "step": 5840
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.0001940076273874245,
      "loss": 1.0484,
      "step": 5850
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.00019398733111880762,
      "loss": 1.0737,
      "step": 5860
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.00019396700160167547,
      "loss": 1.0678,
      "step": 5870
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.00019394663884321971,
      "loss": 1.0435,
      "step": 5880
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.00019392624285064384,
      "loss": 1.0892,
      "step": 5890
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.00019390581363116298,
      "loss": 1.0748,
      "step": 5900
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.0001938853511920041,
      "loss": 1.0552,
      "step": 5910
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.0001938648555404059,
      "loss": 1.0357,
      "step": 5920
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.00019384432668361883,
      "loss": 1.0369,
      "step": 5930
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.00019382376462890504,
      "loss": 1.0659,
      "step": 5940
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.00019380316938353854,
      "loss": 0.9902,
      "step": 5950
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.00019378254095480494,
      "loss": 0.9979,
      "step": 5960
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.0001937618793500017,
      "loss": 1.0621,
      "step": 5970
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.00019374118457643792,
      "loss": 1.0704,
      "step": 5980
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.00019372045664143455,
      "loss": 1.0827,
      "step": 5990
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.00019369969555232416,
      "loss": 1.0574,
      "step": 6000
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.00019367890131645113,
      "loss": 1.0379,
      "step": 6010
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.0001936580739411715,
      "loss": 1.0024,
      "step": 6020
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.00019363721343385306,
      "loss": 1.0922,
      "step": 6030
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.00019361631980187535,
      "loss": 1.0604,
      "step": 6040
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.0001935953930526296,
      "loss": 1.0483,
      "step": 6050
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.00019357443319351875,
      "loss": 0.9714,
      "step": 6060
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.00019355344023195748,
      "loss": 1.0316,
      "step": 6070
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.00019353241417537214,
      "loss": 0.992,
      "step": 6080
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.00019351135503120078,
      "loss": 1.1165,
      "step": 6090
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.0001934902628068932,
      "loss": 1.0635,
      "step": 6100
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.00019346913750991097,
      "loss": 1.0491,
      "step": 6110
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.00019344797914772717,
      "loss": 0.9886,
      "step": 6120
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.00019342678772782672,
      "loss": 1.0134,
      "step": 6130
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.0001934055632577062,
      "loss": 1.0054,
      "step": 6140
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.00019338430574487384,
      "loss": 1.0609,
      "step": 6150
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.0001933630151968497,
      "loss": 1.0084,
      "step": 6160
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.00019334169162116532,
      "loss": 1.0748,
      "step": 6170
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.00019332033502536403,
      "loss": 1.0405,
      "step": 6180
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.0001932989454170009,
      "loss": 1.0729,
      "step": 6190
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.0001932775228036426,
      "loss": 1.0531,
      "step": 6200
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.00019325606719286748,
      "loss": 1.1037,
      "step": 6210
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.00019323457859226557,
      "loss": 0.9952,
      "step": 6220
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.0001932130570094386,
      "loss": 1.0838,
      "step": 6230
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.0001931915024519999,
      "loss": 1.0488,
      "step": 6240
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.00019316991492757457,
      "loss": 1.0475,
      "step": 6250
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.00019314829444379926,
      "loss": 1.0144,
      "step": 6260
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.00019312664100832233,
      "loss": 1.0689,
      "step": 6270
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.00019310495462880384,
      "loss": 1.0018,
      "step": 6280
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.00019308323531291543,
      "loss": 1.0486,
      "step": 6290
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.00019306148306834042,
      "loss": 0.997,
      "step": 6300
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.0001930396979027738,
      "loss": 1.0369,
      "step": 6310
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.00019301787982392219,
      "loss": 1.0248,
      "step": 6320
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.0001929960288395038,
      "loss": 1.0354,
      "step": 6330
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.00019297414495724862,
      "loss": 1.0032,
      "step": 6340
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.00019295222818489812,
      "loss": 1.0334,
      "step": 6350
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.00019293027853020548,
      "loss": 1.1087,
      "step": 6360
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.00019290829600093553,
      "loss": 1.0512,
      "step": 6370
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.0001928862806048647,
      "loss": 1.141,
      "step": 6380
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.00019286423234978105,
      "loss": 1.1053,
      "step": 6390
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.00019284215124348424,
      "loss": 1.053,
      "step": 6400
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.00019282003729378561,
      "loss": 1.0644,
      "step": 6410
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.0001927978905085081,
      "loss": 1.0591,
      "step": 6420
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.00019277571089548623,
      "loss": 1.073,
      "step": 6430
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.00019275349846256613,
      "loss": 1.0854,
      "step": 6440
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.00019273125321760562,
      "loss": 1.0661,
      "step": 6450
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.00019270897516847403,
      "loss": 1.0307,
      "step": 6460
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.00019268666432305237,
      "loss": 1.0203,
      "step": 6470
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.00019266432068923322,
      "loss": 1.0425,
      "step": 6480
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.0001926419442749207,
      "loss": 1.0666,
      "step": 6490
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.00019261953508803065,
      "loss": 1.0944,
      "step": 6500
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.0001925970931364904,
      "loss": 1.0795,
      "step": 6510
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.00019257461842823897,
      "loss": 1.0767,
      "step": 6520
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.0001925521109712268,
      "loss": 1.0304,
      "step": 6530
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.00019252957077341612,
      "loss": 1.0246,
      "step": 6540
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.0001925069978427806,
      "loss": 1.0219,
      "step": 6550
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.00019248439218730554,
      "loss": 1.1172,
      "step": 6560
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.00019246175381498778,
      "loss": 1.0037,
      "step": 6570
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.00019244135131362008,
      "loss": 0.9952,
      "step": 6580
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.0001924186508013741,
      "loss": 0.9933,
      "step": 6590
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.00019239591759554183,
      "loss": 1.0869,
      "step": 6600
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.00019237315170416523,
      "loss": 1.0478,
      "step": 6610
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.00019235035313529787,
      "loss": 1.0281,
      "step": 6620
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.00019232752189700486,
      "loss": 1.0439,
      "step": 6630
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.0001923046579973629,
      "loss": 1.0547,
      "step": 6640
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.00019228176144446015,
      "loss": 1.0253,
      "step": 6650
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.00019225883224639645,
      "loss": 1.0585,
      "step": 6660
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.0001922358704112831,
      "loss": 1.0704,
      "step": 6670
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.00019221287594724297,
      "loss": 1.0541,
      "step": 6680
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.00019218984886241048,
      "loss": 1.0252,
      "step": 6690
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.00019216678916493158,
      "loss": 1.0369,
      "step": 6700
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.00019214369686296374,
      "loss": 1.0627,
      "step": 6710
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.00019212057196467603,
      "loss": 1.0784,
      "step": 6720
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.000192097414478249,
      "loss": 1.0316,
      "step": 6730
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.00019207422441187464,
      "loss": 1.0439,
      "step": 6740
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.00019205100177375667,
      "loss": 1.013,
      "step": 6750
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.00019202774657211017,
      "loss": 0.9809,
      "step": 6760
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.00019200445881516182,
      "loss": 1.1025,
      "step": 6770
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.00019198113851114977,
      "loss": 1.0107,
      "step": 6780
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.00019195778566832367,
      "loss": 1.0425,
      "step": 6790
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.00019193440029494478,
      "loss": 1.0392,
      "step": 6800
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.00019191098239928572,
      "loss": 1.0781,
      "step": 6810
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.00019188753198963077,
      "loss": 1.0107,
      "step": 6820
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.00019186404907427557,
      "loss": 1.0441,
      "step": 6830
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.00019184053366152738,
      "loss": 1.0667,
      "step": 6840
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.00019181698575970488,
      "loss": 1.0617,
      "step": 6850
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.00019179340537713824,
      "loss": 1.0445,
      "step": 6860
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.00019176979252216917,
      "loss": 1.0362,
      "step": 6870
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.00019174614720315086,
      "loss": 1.0859,
      "step": 6880
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.00019172246942844793,
      "loss": 1.0243,
      "step": 6890
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.00019169875920643654,
      "loss": 1.0983,
      "step": 6900
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.00019167501654550432,
      "loss": 1.0254,
      "step": 6910
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.00019165124145405034,
      "loss": 1.0313,
      "step": 6920
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.00019162743394048515,
      "loss": 1.0229,
      "step": 6930
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.0001916035940132308,
      "loss": 1.0707,
      "step": 6940
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.0001915797216807208,
      "loss": 1.007,
      "step": 6950
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.00019155581695140007,
      "loss": 1.0198,
      "step": 6960
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.0001915318798337251,
      "loss": 1.0558,
      "step": 6970
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.00019150791033616376,
      "loss": 1.0849,
      "step": 6980
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.00019148390846719532,
      "loss": 1.02,
      "step": 6990
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.00019145987423531066,
      "loss": 1.0256,
      "step": 7000
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.00019143580764901196,
      "loss": 1.0344,
      "step": 7010
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.00019141170871681294,
      "loss": 1.0725,
      "step": 7020
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.00019138757744723866,
      "loss": 1.0783,
      "step": 7030
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.0001913634138488257,
      "loss": 1.0637,
      "step": 7040
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.00019133921793012214,
      "loss": 1.0205,
      "step": 7050
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.00019131498969968735,
      "loss": 1.074,
      "step": 7060
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.0001912907291660922,
      "loss": 1.0458,
      "step": 7070
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.00019126643633791897,
      "loss": 1.0325,
      "step": 7080
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.00019124211122376137,
      "loss": 1.0605,
      "step": 7090
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.0001912177538322246,
      "loss": 1.0096,
      "step": 7100
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.00019119336417192516,
      "loss": 1.019,
      "step": 7110
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.00019116894225149102,
      "loss": 1.0496,
      "step": 7120
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.0001911444880795616,
      "loss": 1.0248,
      "step": 7130
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.0001911200016647877,
      "loss": 1.0502,
      "step": 7140
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.00019109548301583145,
      "loss": 1.045,
      "step": 7150
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.00019107093214136648,
      "loss": 1.0202,
      "step": 7160
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.00019104634905007782,
      "loss": 1.0171,
      "step": 7170
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.00019102173375066191,
      "loss": 1.0467,
      "step": 7180
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.00019099708625182642,
      "loss": 1.0611,
      "step": 7190
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.00019097240656229062,
      "loss": 1.0481,
      "step": 7200
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.00019094769469078503,
      "loss": 1.0715,
      "step": 7210
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.00019092295064605165,
      "loss": 1.007,
      "step": 7220
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.00019089817443684382,
      "loss": 1.0381,
      "step": 7230
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.00019087336607192623,
      "loss": 1.0902,
      "step": 7240
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.00019084852556007498,
      "loss": 1.0536,
      "step": 7250
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.00019082365291007752,
      "loss": 1.0498,
      "step": 7260
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.00019079874813073268,
      "loss": 1.032,
      "step": 7270
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.00019077381123085068,
      "loss": 1.0051,
      "step": 7280
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.00019074884221925308,
      "loss": 1.0527,
      "step": 7290
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.00019072384110477276,
      "loss": 1.0879,
      "step": 7300
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.00019069880789625402,
      "loss": 1.0772,
      "step": 7310
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.0001906737426025525,
      "loss": 1.0012,
      "step": 7320
    },
    {
      "epoch": 2.78,
      "learning_rate": 0.0001906486452325352,
      "loss": 1.036,
      "step": 7330
    },
    {
      "epoch": 2.78,
      "learning_rate": 0.00019062351579508037,
      "loss": 1.0901,
      "step": 7340
    },
    {
      "epoch": 2.78,
      "learning_rate": 0.00019059835429907778,
      "loss": 1.0613,
      "step": 7350
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.0001905731607534284,
      "loss": 1.0237,
      "step": 7360
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.00019054793516704455,
      "loss": 1.0719,
      "step": 7370
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.00019052267754884994,
      "loss": 1.0985,
      "step": 7380
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.00019049738790777958,
      "loss": 1.0452,
      "step": 7390
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.00019047206625277983,
      "loss": 1.0328,
      "step": 7400
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.00019044671259280834,
      "loss": 1.0926,
      "step": 7410
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.0001904213269368341,
      "loss": 1.0388,
      "step": 7420
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.00019039590929383746,
      "loss": 1.0904,
      "step": 7430
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.00019037045967281,
      "loss": 1.0678,
      "step": 7440
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.00019034497808275469,
      "loss": 1.0099,
      "step": 7450
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.00019031946453268572,
      "loss": 1.0361,
      "step": 7460
    },
    {
      "epoch": 2.83,
      "learning_rate": 0.00019029391903162873,
      "loss": 1.0238,
      "step": 7470
    },
    {
      "epoch": 2.83,
      "learning_rate": 0.00019026834158862048,
      "loss": 1.0728,
      "step": 7480
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.00019024273221270922,
      "loss": 1.024,
      "step": 7490
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.00019021709091295431,
      "loss": 1.0725,
      "step": 7500
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.0001901914176984266,
      "loss": 1.116,
      "step": 7510
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.00019016571257820806,
      "loss": 1.0072,
      "step": 7520
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.00019013997556139198,
      "loss": 1.0876,
      "step": 7530
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.00019011420665708304,
      "loss": 1.0444,
      "step": 7540
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.00019008840587439707,
      "loss": 1.0325,
      "step": 7550
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.00019006257322246126,
      "loss": 1.077,
      "step": 7560
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.00019003670871041407,
      "loss": 1.0108,
      "step": 7570
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.00019001081234740514,
      "loss": 1.0327,
      "step": 7580
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.0001899848841425955,
      "loss": 1.0806,
      "step": 7590
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.0001899589241051574,
      "loss": 1.1065,
      "step": 7600
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.00018993293224427429,
      "loss": 1.0207,
      "step": 7610
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.00018990690856914095,
      "loss": 1.0498,
      "step": 7620
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.00018988085308896342,
      "loss": 1.0202,
      "step": 7630
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.00018985476581295893,
      "loss": 1.0052,
      "step": 7640
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.000189828646750356,
      "loss": 1.0268,
      "step": 7650
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.00018980249591039438,
      "loss": 1.1054,
      "step": 7660
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.00018977631330232512,
      "loss": 1.0614,
      "step": 7670
    },
    {
      "epoch": 2.91,
      "learning_rate": 0.00018975009893541035,
      "loss": 1.0434,
      "step": 7680
    },
    {
      "epoch": 2.91,
      "learning_rate": 0.00018972385281892367,
      "loss": 1.0231,
      "step": 7690
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.00018969757496214965,
      "loss": 1.0496,
      "step": 7700
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.00018967126537438434,
      "loss": 1.0115,
      "step": 7710
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.0001896449240649348,
      "loss": 1.0805,
      "step": 7720
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.00018961855104311949,
      "loss": 0.9967,
      "step": 7730
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.00018959214631826795,
      "loss": 1.0557,
      "step": 7740
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.000189565709899721,
      "loss": 1.0104,
      "step": 7750
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.0001895392417968307,
      "loss": 1.0024,
      "step": 7760
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.0001895127420189602,
      "loss": 1.0317,
      "step": 7770
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.00018948621057548402,
      "loss": 1.0494,
      "step": 7780
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.00018945964747578775,
      "loss": 1.0993,
      "step": 7790
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.00018943305272926824,
      "loss": 1.0644,
      "step": 7800
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.00018940642634533356,
      "loss": 1.0838,
      "step": 7810
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.00018937976833340289,
      "loss": 1.0459,
      "step": 7820
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.00018935307870290662,
      "loss": 1.0734,
      "step": 7830
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.00018932635746328643,
      "loss": 1.0884,
      "step": 7840
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.000189299604623995,
      "loss": 0.9998,
      "step": 7850
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.00018927282019449635,
      "loss": 0.9893,
      "step": 7860
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.00018924600418426563,
      "loss": 1.0547,
      "step": 7870
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.00018921915660278908,
      "loss": 1.0493,
      "step": 7880
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.00018919227745956425,
      "loss": 1.0546,
      "step": 7890
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.0001891653667640997,
      "loss": 1.0795,
      "step": 7900
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.0001891384245259153,
      "loss": 0.9787,
      "step": 7910
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.00018911145075454195,
      "loss": 1.0645,
      "step": 7920
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.00018908444545952184,
      "loss": 1.0566,
      "step": 7930
    },
    {
      "epoch": 3.01,
      "learning_rate": 0.00018905740865040815,
      "loss": 1.0563,
      "step": 7940
    },
    {
      "epoch": 3.01,
      "learning_rate": 0.00018903034033676533,
      "loss": 1.0779,
      "step": 7950
    },
    {
      "epoch": 3.01,
      "learning_rate": 0.00018900324052816898,
      "loss": 1.069,
      "step": 7960
    },
    {
      "epoch": 3.02,
      "learning_rate": 0.00018897610923420573,
      "loss": 0.9892,
      "step": 7970
    },
    {
      "epoch": 3.02,
      "learning_rate": 0.0001889489464644735,
      "loss": 0.9791,
      "step": 7980
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.00018892175222858117,
      "loss": 1.0376,
      "step": 7990
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.0001888945265361489,
      "loss": 1.0074,
      "step": 8000
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.00018886726939680793,
      "loss": 1.0029,
      "step": 8010
    },
    {
      "epoch": 3.04,
      "learning_rate": 0.00018883998082020058,
      "loss": 1.0319,
      "step": 8020
    },
    {
      "epoch": 3.04,
      "learning_rate": 0.00018881266081598034,
      "loss": 1.088,
      "step": 8030
    },
    {
      "epoch": 3.04,
      "learning_rate": 0.00018878530939381186,
      "loss": 0.9912,
      "step": 8040
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.00018875792656337077,
      "loss": 0.984,
      "step": 8050
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.0001887305123343439,
      "loss": 1.0045,
      "step": 8060
    },
    {
      "epoch": 3.06,
      "learning_rate": 0.00018870306671642926,
      "loss": 1.0038,
      "step": 8070
    },
    {
      "epoch": 3.06,
      "learning_rate": 0.00018867558971933577,
      "loss": 1.035,
      "step": 8080
    },
    {
      "epoch": 3.06,
      "learning_rate": 0.00018864808135278367,
      "loss": 1.0306,
      "step": 8090
    },
    {
      "epoch": 3.07,
      "learning_rate": 0.00018862054162650414,
      "loss": 1.0263,
      "step": 8100
    },
    {
      "epoch": 3.07,
      "learning_rate": 0.00018859297055023947,
      "loss": 1.0652,
      "step": 8110
    },
    {
      "epoch": 3.07,
      "learning_rate": 0.0001885653681337431,
      "loss": 0.9706,
      "step": 8120
    },
    {
      "epoch": 3.08,
      "learning_rate": 0.00018853773438677957,
      "loss": 1.039,
      "step": 8130
    },
    {
      "epoch": 3.08,
      "learning_rate": 0.00018851006931912444,
      "loss": 1.0161,
      "step": 8140
    },
    {
      "epoch": 3.09,
      "learning_rate": 0.00018848237294056435,
      "loss": 0.9746,
      "step": 8150
    },
    {
      "epoch": 3.09,
      "learning_rate": 0.00018845464526089705,
      "loss": 1.0347,
      "step": 8160
    },
    {
      "epoch": 3.09,
      "learning_rate": 0.00018842688628993134,
      "loss": 1.0341,
      "step": 8170
    },
    {
      "epoch": 3.1,
      "learning_rate": 0.00018839909603748716,
      "loss": 1.0049,
      "step": 8180
    },
    {
      "epoch": 3.1,
      "learning_rate": 0.00018837127451339542,
      "loss": 1.0277,
      "step": 8190
    },
    {
      "epoch": 3.1,
      "learning_rate": 0.0001883434217274981,
      "loss": 1.0703,
      "step": 8200
    },
    {
      "epoch": 3.11,
      "learning_rate": 0.00018831553768964833,
      "loss": 0.9714,
      "step": 8210
    },
    {
      "epoch": 3.11,
      "learning_rate": 0.00018828762240971023,
      "loss": 1.0369,
      "step": 8220
    },
    {
      "epoch": 3.12,
      "learning_rate": 0.0001882596758975589,
      "loss": 1.0414,
      "step": 8230
    },
    {
      "epoch": 3.12,
      "learning_rate": 0.00018823169816308067,
      "loss": 0.9916,
      "step": 8240
    },
    {
      "epoch": 3.12,
      "learning_rate": 0.00018820368921617275,
      "loss": 1.0462,
      "step": 8250
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.00018817564906674345,
      "loss": 1.0845,
      "step": 8260
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.00018814757772471214,
      "loss": 1.0185,
      "step": 8270
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.00018811947520000924,
      "loss": 1.0901,
      "step": 8280
    },
    {
      "epoch": 3.14,
      "learning_rate": 0.0001880913415025761,
      "loss": 1.0335,
      "step": 8290
    },
    {
      "epoch": 3.14,
      "learning_rate": 0.00018806317664236518,
      "loss": 1.0297,
      "step": 8300
    },
    {
      "epoch": 3.15,
      "learning_rate": 0.00018803498062934,
      "loss": 1.089,
      "step": 8310
    },
    {
      "epoch": 3.15,
      "learning_rate": 0.000188006753473475,
      "loss": 1.0099,
      "step": 8320
    },
    {
      "epoch": 3.15,
      "learning_rate": 0.0001879784951847557,
      "loss": 1.0891,
      "step": 8330
    },
    {
      "epoch": 3.16,
      "learning_rate": 0.00018795020577317862,
      "loss": 1.0245,
      "step": 8340
    },
    {
      "epoch": 3.16,
      "learning_rate": 0.00018792188524875125,
      "loss": 1.0228,
      "step": 8350
    },
    {
      "epoch": 3.17,
      "learning_rate": 0.0001878935336214922,
      "loss": 1.0724,
      "step": 8360
    },
    {
      "epoch": 3.17,
      "learning_rate": 0.00018786515090143095,
      "loss": 1.0168,
      "step": 8370
    },
    {
      "epoch": 3.17,
      "learning_rate": 0.00018783673709860807,
      "loss": 1.0254,
      "step": 8380
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.00018780829222307506,
      "loss": 1.0946,
      "step": 8390
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.0001877798162848945,
      "loss": 1.0328,
      "step": 8400
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.00018775130929413983,
      "loss": 1.0022,
      "step": 8410
    },
    {
      "epoch": 3.19,
      "learning_rate": 0.0001877227712608956,
      "loss": 1.0127,
      "step": 8420
    },
    {
      "epoch": 3.19,
      "learning_rate": 0.00018769420219525728,
      "loss": 1.0523,
      "step": 8430
    },
    {
      "epoch": 3.2,
      "learning_rate": 0.0001876656021073313,
      "loss": 1.0604,
      "step": 8440
    },
    {
      "epoch": 3.2,
      "learning_rate": 0.00018763697100723515,
      "loss": 1.0557,
      "step": 8450
    },
    {
      "epoch": 3.2,
      "learning_rate": 0.0001876083089050972,
      "loss": 1.0108,
      "step": 8460
    },
    {
      "epoch": 3.21,
      "learning_rate": 0.0001875796158110568,
      "loss": 1.0165,
      "step": 8470
    },
    {
      "epoch": 3.21,
      "learning_rate": 0.0001875508917352643,
      "loss": 1.0717,
      "step": 8480
    },
    {
      "epoch": 3.21,
      "learning_rate": 0.00018752213668788098,
      "loss": 1.0516,
      "step": 8490
    },
    {
      "epoch": 3.22,
      "learning_rate": 0.00018749335067907915,
      "loss": 1.0487,
      "step": 8500
    },
    {
      "epoch": 3.22,
      "learning_rate": 0.00018746453371904198,
      "loss": 1.0419,
      "step": 8510
    },
    {
      "epoch": 3.23,
      "learning_rate": 0.00018743568581796355,
      "loss": 0.9758,
      "step": 8520
    },
    {
      "epoch": 3.23,
      "learning_rate": 0.00018740680698604907,
      "loss": 1.0124,
      "step": 8530
    },
    {
      "epoch": 3.23,
      "learning_rate": 0.00018737789723351453,
      "loss": 1.0495,
      "step": 8540
    },
    {
      "epoch": 3.24,
      "learning_rate": 0.0001873489565705869,
      "loss": 0.9784,
      "step": 8550
    },
    {
      "epoch": 3.24,
      "learning_rate": 0.00018731998500750408,
      "loss": 0.9991,
      "step": 8560
    },
    {
      "epoch": 3.24,
      "learning_rate": 0.00018729098255451497,
      "loss": 1.0321,
      "step": 8570
    },
    {
      "epoch": 3.25,
      "learning_rate": 0.00018726194922187925,
      "loss": 1.0152,
      "step": 8580
    },
    {
      "epoch": 3.25,
      "learning_rate": 0.00018723288501986768,
      "loss": 1.0196,
      "step": 8590
    },
    {
      "epoch": 3.26,
      "learning_rate": 0.00018720378995876191,
      "loss": 1.0372,
      "step": 8600
    },
    {
      "epoch": 3.26,
      "learning_rate": 0.0001871746640488544,
      "loss": 1.0018,
      "step": 8610
    },
    {
      "epoch": 3.26,
      "learning_rate": 0.0001871455073004486,
      "loss": 1.0262,
      "step": 8620
    },
    {
      "epoch": 3.27,
      "learning_rate": 0.00018711631972385894,
      "loss": 1.0887,
      "step": 8630
    },
    {
      "epoch": 3.27,
      "learning_rate": 0.00018708710132941055,
      "loss": 1.0135,
      "step": 8640
    },
    {
      "epoch": 3.27,
      "learning_rate": 0.0001870578521274397,
      "loss": 1.0389,
      "step": 8650
    },
    {
      "epoch": 3.28,
      "learning_rate": 0.00018702857212829344,
      "loss": 1.0232,
      "step": 8660
    },
    {
      "epoch": 3.28,
      "learning_rate": 0.00018699926134232967,
      "loss": 1.0029,
      "step": 8670
    },
    {
      "epoch": 3.29,
      "learning_rate": 0.00018696991977991726,
      "loss": 1.0297,
      "step": 8680
    },
    {
      "epoch": 3.29,
      "learning_rate": 0.00018694054745143596,
      "loss": 1.03,
      "step": 8690
    },
    {
      "epoch": 3.29,
      "learning_rate": 0.00018691114436727638,
      "loss": 1.0595,
      "step": 8700
    },
    {
      "epoch": 3.3,
      "learning_rate": 0.00018688171053784,
      "loss": 1.007,
      "step": 8710
    },
    {
      "epoch": 3.3,
      "learning_rate": 0.00018685224597353922,
      "loss": 1.0118,
      "step": 8720
    },
    {
      "epoch": 3.31,
      "learning_rate": 0.00018682275068479726,
      "loss": 1.0479,
      "step": 8730
    },
    {
      "epoch": 3.31,
      "learning_rate": 0.00018679322468204826,
      "loss": 1.0406,
      "step": 8740
    },
    {
      "epoch": 3.31,
      "learning_rate": 0.00018676366797573714,
      "loss": 1.1108,
      "step": 8750
    },
    {
      "epoch": 3.32,
      "learning_rate": 0.0001867340805763198,
      "loss": 0.9883,
      "step": 8760
    },
    {
      "epoch": 3.32,
      "learning_rate": 0.00018670742568288888,
      "loss": 0.9993,
      "step": 8770
    },
    {
      "epoch": 3.32,
      "learning_rate": 0.00018667777999541442,
      "loss": 1.033,
      "step": 8780
    },
    {
      "epoch": 3.33,
      "learning_rate": 0.00018664810364521706,
      "loss": 0.992,
      "step": 8790
    },
    {
      "epoch": 3.33,
      "learning_rate": 0.00018661839664279496,
      "loss": 0.9855,
      "step": 8800
    },
    {
      "epoch": 3.34,
      "learning_rate": 0.0001865886589986571,
      "loss": 1.0056,
      "step": 8810
    },
    {
      "epoch": 3.34,
      "learning_rate": 0.00018655889072332339,
      "loss": 1.0126,
      "step": 8820
    },
    {
      "epoch": 3.34,
      "learning_rate": 0.00018652909182732445,
      "loss": 1.0151,
      "step": 8830
    },
    {
      "epoch": 3.35,
      "learning_rate": 0.00018649926232120186,
      "loss": 0.9822,
      "step": 8840
    },
    {
      "epoch": 3.35,
      "learning_rate": 0.00018646940221550792,
      "loss": 1.0368,
      "step": 8850
    },
    {
      "epoch": 3.35,
      "learning_rate": 0.0001864395115208058,
      "loss": 1.0,
      "step": 8860
    },
    {
      "epoch": 3.36,
      "learning_rate": 0.00018640959024766952,
      "loss": 1.0438,
      "step": 8870
    },
    {
      "epoch": 3.36,
      "learning_rate": 0.00018637963840668385,
      "loss": 0.9972,
      "step": 8880
    },
    {
      "epoch": 3.37,
      "learning_rate": 0.00018634965600844444,
      "loss": 1.0366,
      "step": 8890
    },
    {
      "epoch": 3.37,
      "learning_rate": 0.00018631964306355773,
      "loss": 1.0254,
      "step": 8900
    },
    {
      "epoch": 3.37,
      "learning_rate": 0.00018628959958264093,
      "loss": 0.9983,
      "step": 8910
    },
    {
      "epoch": 3.38,
      "learning_rate": 0.0001862595255763221,
      "loss": 1.0563,
      "step": 8920
    },
    {
      "epoch": 3.38,
      "learning_rate": 0.0001862294210552401,
      "loss": 1.0249,
      "step": 8930
    },
    {
      "epoch": 3.38,
      "learning_rate": 0.0001861992860300445,
      "loss": 1.0202,
      "step": 8940
    },
    {
      "epoch": 3.39,
      "learning_rate": 0.00018616912051139578,
      "loss": 1.0387,
      "step": 8950
    },
    {
      "epoch": 3.39,
      "learning_rate": 0.00018613892450996514,
      "loss": 1.0866,
      "step": 8960
    },
    {
      "epoch": 3.4,
      "learning_rate": 0.00018610869803643455,
      "loss": 1.0226,
      "step": 8970
    },
    {
      "epoch": 3.4,
      "learning_rate": 0.0001860784411014968,
      "loss": 1.0475,
      "step": 8980
    },
    {
      "epoch": 3.4,
      "learning_rate": 0.00018604815371585544,
      "loss": 1.0305,
      "step": 8990
    },
    {
      "epoch": 3.41,
      "learning_rate": 0.0001860178358902248,
      "loss": 1.0151,
      "step": 9000
    },
    {
      "epoch": 3.41,
      "learning_rate": 0.00018598748763533,
      "loss": 1.0431,
      "step": 9010
    },
    {
      "epoch": 3.42,
      "learning_rate": 0.00018595710896190682,
      "loss": 1.036,
      "step": 9020
    },
    {
      "epoch": 3.42,
      "learning_rate": 0.00018592669988070192,
      "loss": 1.0374,
      "step": 9030
    },
    {
      "epoch": 3.42,
      "learning_rate": 0.0001858962604024727,
      "loss": 1.0885,
      "step": 9040
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.00018586579053798724,
      "loss": 1.0262,
      "step": 9050
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.00018583529029802444,
      "loss": 1.0232,
      "step": 9060
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.0001858047596933739,
      "loss": 1.0104,
      "step": 9070
    },
    {
      "epoch": 3.44,
      "learning_rate": 0.00018577419873483603,
      "loss": 1.0103,
      "step": 9080
    },
    {
      "epoch": 3.44,
      "learning_rate": 0.0001857436074332219,
      "loss": 1.0242,
      "step": 9090
    },
    {
      "epoch": 3.45,
      "learning_rate": 0.00018571298579935332,
      "loss": 1.022,
      "step": 9100
    },
    {
      "epoch": 3.45,
      "learning_rate": 0.00018568233384406288,
      "loss": 1.0341,
      "step": 9110
    },
    {
      "epoch": 3.45,
      "learning_rate": 0.00018565165157819385,
      "loss": 1.105,
      "step": 9120
    },
    {
      "epoch": 3.46,
      "learning_rate": 0.00018562093901260032,
      "loss": 1.0536,
      "step": 9130
    },
    {
      "epoch": 3.46,
      "learning_rate": 0.00018559019615814695,
      "loss": 1.0282,
      "step": 9140
    },
    {
      "epoch": 3.46,
      "learning_rate": 0.00018555942302570918,
      "loss": 0.991,
      "step": 9150
    },
    {
      "epoch": 3.47,
      "learning_rate": 0.0001855286196261732,
      "loss": 1.055,
      "step": 9160
    },
    {
      "epoch": 3.47,
      "learning_rate": 0.00018549778597043586,
      "loss": 0.9817,
      "step": 9170
    },
    {
      "epoch": 3.48,
      "learning_rate": 0.00018546692206940476,
      "loss": 1.0313,
      "step": 9180
    },
    {
      "epoch": 3.48,
      "learning_rate": 0.0001854360279339981,
      "loss": 1.0333,
      "step": 9190
    },
    {
      "epoch": 3.48,
      "learning_rate": 0.0001854051035751449,
      "loss": 1.0469,
      "step": 9200
    },
    {
      "epoch": 3.49,
      "learning_rate": 0.00018537414900378485,
      "loss": 1.0253,
      "step": 9210
    },
    {
      "epoch": 3.49,
      "learning_rate": 0.0001853431642308682,
      "loss": 1.0301,
      "step": 9220
    },
    {
      "epoch": 3.49,
      "learning_rate": 0.00018531214926735605,
      "loss": 1.0021,
      "step": 9230
    },
    {
      "epoch": 3.5,
      "learning_rate": 0.00018528110412422007,
      "loss": 1.0388,
      "step": 9240
    },
    {
      "epoch": 3.5,
      "learning_rate": 0.00018525002881244262,
      "loss": 1.096,
      "step": 9250
    },
    {
      "epoch": 3.51,
      "learning_rate": 0.00018521892334301683,
      "loss": 1.0314,
      "step": 9260
    },
    {
      "epoch": 3.51,
      "learning_rate": 0.00018518778772694638,
      "loss": 1.0467,
      "step": 9270
    },
    {
      "epoch": 3.51,
      "learning_rate": 0.00018515662197524568,
      "loss": 1.0171,
      "step": 9280
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.00018512542609893973,
      "loss": 0.9785,
      "step": 9290
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.0001850942001090643,
      "loss": 1.078,
      "step": 9300
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.00018506294401666567,
      "loss": 0.9996,
      "step": 9310
    },
    {
      "epoch": 3.53,
      "learning_rate": 0.00018503165783280095,
      "loss": 1.051,
      "step": 9320
    },
    {
      "epoch": 3.53,
      "learning_rate": 0.0001850003415685377,
      "loss": 1.0335,
      "step": 9330
    },
    {
      "epoch": 3.54,
      "learning_rate": 0.00018496899523495424,
      "loss": 1.01,
      "step": 9340
    },
    {
      "epoch": 3.54,
      "learning_rate": 0.00018493761884313958,
      "loss": 0.9652,
      "step": 9350
    },
    {
      "epoch": 3.54,
      "learning_rate": 0.00018490621240419315,
      "loss": 0.9972,
      "step": 9360
    },
    {
      "epoch": 3.55,
      "learning_rate": 0.00018487477592922527,
      "loss": 1.0351,
      "step": 9370
    },
    {
      "epoch": 3.55,
      "learning_rate": 0.00018484330942935667,
      "loss": 1.0687,
      "step": 9380
    },
    {
      "epoch": 3.56,
      "learning_rate": 0.00018481181291571882,
      "loss": 1.0377,
      "step": 9390
    },
    {
      "epoch": 3.56,
      "learning_rate": 0.00018478028639945377,
      "loss": 1.0224,
      "step": 9400
    },
    {
      "epoch": 3.56,
      "learning_rate": 0.00018474872989171422,
      "loss": 1.0112,
      "step": 9410
    },
    {
      "epoch": 3.57,
      "learning_rate": 0.00018471714340366344,
      "loss": 1.0255,
      "step": 9420
    },
    {
      "epoch": 3.57,
      "learning_rate": 0.0001846855269464753,
      "loss": 1.0213,
      "step": 9430
    },
    {
      "epoch": 3.57,
      "learning_rate": 0.0001846570465206373,
      "loss": 1.0392,
      "step": 9440
    },
    {
      "epoch": 3.58,
      "learning_rate": 0.0001846253731529102,
      "loss": 0.9993,
      "step": 9450
    },
    {
      "epoch": 3.58,
      "learning_rate": 0.00018459366984851,
      "loss": 1.0214,
      "step": 9460
    },
    {
      "epoch": 3.59,
      "learning_rate": 0.00018456193661865186,
      "loss": 1.0251,
      "step": 9470
    },
    {
      "epoch": 3.59,
      "learning_rate": 0.00018453017347456162,
      "loss": 0.9897,
      "step": 9480
    },
    {
      "epoch": 3.59,
      "learning_rate": 0.00018449838042747558,
      "loss": 1.0083,
      "step": 9490
    },
    {
      "epoch": 3.6,
      "learning_rate": 0.00018446655748864077,
      "loss": 1.0154,
      "step": 9500
    },
    {
      "epoch": 3.6,
      "learning_rate": 0.0001844347046693147,
      "loss": 1.0271,
      "step": 9510
    },
    {
      "epoch": 3.6,
      "learning_rate": 0.00018440282198076548,
      "loss": 1.0837,
      "step": 9520
    },
    {
      "epoch": 3.61,
      "learning_rate": 0.00018437090943427178,
      "loss": 1.072,
      "step": 9530
    },
    {
      "epoch": 3.61,
      "learning_rate": 0.0001843389670411228,
      "loss": 1.0972,
      "step": 9540
    },
    {
      "epoch": 3.62,
      "learning_rate": 0.00018430699481261842,
      "loss": 1.0407,
      "step": 9550
    },
    {
      "epoch": 3.62,
      "learning_rate": 0.00018427499276006887,
      "loss": 1.0484,
      "step": 9560
    },
    {
      "epoch": 3.62,
      "learning_rate": 0.00018424296089479514,
      "loss": 1.001,
      "step": 9570
    },
    {
      "epoch": 3.63,
      "learning_rate": 0.0001842108992281286,
      "loss": 1.0203,
      "step": 9580
    },
    {
      "epoch": 3.63,
      "learning_rate": 0.00018417880777141127,
      "loss": 0.979,
      "step": 9590
    },
    {
      "epoch": 3.63,
      "learning_rate": 0.00018414668653599564,
      "loss": 1.0438,
      "step": 9600
    },
    {
      "epoch": 3.64,
      "learning_rate": 0.00018411453553324484,
      "loss": 0.9907,
      "step": 9610
    },
    {
      "epoch": 3.64,
      "learning_rate": 0.00018408235477453236,
      "loss": 1.0295,
      "step": 9620
    },
    {
      "epoch": 3.65,
      "learning_rate": 0.00018405014427124244,
      "loss": 1.0294,
      "step": 9630
    },
    {
      "epoch": 3.65,
      "learning_rate": 0.00018401790403476957,
      "loss": 1.0904,
      "step": 9640
    },
    {
      "epoch": 3.65,
      "learning_rate": 0.000183985634076519,
      "loss": 1.0178,
      "step": 9650
    },
    {
      "epoch": 3.66,
      "learning_rate": 0.00018395333440790636,
      "loss": 1.0388,
      "step": 9660
    },
    {
      "epoch": 3.66,
      "learning_rate": 0.00018392100504035786,
      "loss": 1.0104,
      "step": 9670
    },
    {
      "epoch": 3.66,
      "learning_rate": 0.00018388864598531014,
      "loss": 1.0705,
      "step": 9680
    },
    {
      "epoch": 3.67,
      "learning_rate": 0.00018385625725421046,
      "loss": 1.0347,
      "step": 9690
    },
    {
      "epoch": 3.67,
      "learning_rate": 0.00018382383885851643,
      "loss": 1.0432,
      "step": 9700
    },
    {
      "epoch": 3.68,
      "learning_rate": 0.00018379139080969625,
      "loss": 0.9494,
      "step": 9710
    },
    {
      "epoch": 3.68,
      "learning_rate": 0.0001837589131192286,
      "loss": 1.003,
      "step": 9720
    },
    {
      "epoch": 3.68,
      "learning_rate": 0.00018372640579860262,
      "loss": 1.0054,
      "step": 9730
    },
    {
      "epoch": 3.69,
      "learning_rate": 0.00018369386885931795,
      "loss": 0.9961,
      "step": 9740
    },
    {
      "epoch": 3.69,
      "learning_rate": 0.00018366130231288472,
      "loss": 1.0096,
      "step": 9750
    },
    {
      "epoch": 3.7,
      "learning_rate": 0.0001836287061708235,
      "loss": 1.013,
      "step": 9760
    },
    {
      "epoch": 3.7,
      "learning_rate": 0.0001835960804446654,
      "loss": 0.9681,
      "step": 9770
    },
    {
      "epoch": 3.7,
      "learning_rate": 0.00018356342514595187,
      "loss": 0.9955,
      "step": 9780
    },
    {
      "epoch": 3.71,
      "learning_rate": 0.00018353074028623493,
      "loss": 1.0381,
      "step": 9790
    },
    {
      "epoch": 3.71,
      "learning_rate": 0.000183498025877077,
      "loss": 1.0471,
      "step": 9800
    },
    {
      "epoch": 3.71,
      "learning_rate": 0.00018346528193005098,
      "loss": 1.0195,
      "step": 9810
    },
    {
      "epoch": 3.72,
      "learning_rate": 0.00018343250845674025,
      "loss": 1.0628,
      "step": 9820
    },
    {
      "epoch": 3.72,
      "learning_rate": 0.00018339970546873855,
      "loss": 1.0245,
      "step": 9830
    },
    {
      "epoch": 3.73,
      "learning_rate": 0.00018336687297765015,
      "loss": 1.0154,
      "step": 9840
    },
    {
      "epoch": 3.73,
      "learning_rate": 0.00018333401099508972,
      "loss": 1.0035,
      "step": 9850
    },
    {
      "epoch": 3.73,
      "learning_rate": 0.0001833011195326823,
      "loss": 0.9689,
      "step": 9860
    },
    {
      "epoch": 3.74,
      "learning_rate": 0.0001832681986020635,
      "loss": 1.0488,
      "step": 9870
    },
    {
      "epoch": 3.74,
      "learning_rate": 0.00018323524821487922,
      "loss": 1.0856,
      "step": 9880
    },
    {
      "epoch": 3.74,
      "learning_rate": 0.00018320226838278587,
      "loss": 1.0132,
      "step": 9890
    },
    {
      "epoch": 3.75,
      "learning_rate": 0.0001831692591174502,
      "loss": 1.063,
      "step": 9900
    },
    {
      "epoch": 3.75,
      "learning_rate": 0.00018313622043054944,
      "loss": 1.0299,
      "step": 9910
    },
    {
      "epoch": 3.76,
      "learning_rate": 0.00018310315233377117,
      "loss": 1.0918,
      "step": 9920
    },
    {
      "epoch": 3.76,
      "learning_rate": 0.00018307005483881344,
      "loss": 1.0485,
      "step": 9930
    },
    {
      "epoch": 3.76,
      "learning_rate": 0.00018303692795738463,
      "loss": 1.0413,
      "step": 9940
    },
    {
      "epoch": 3.77,
      "learning_rate": 0.00018300377170120359,
      "loss": 0.99,
      "step": 9950
    },
    {
      "epoch": 3.77,
      "learning_rate": 0.00018297058608199947,
      "loss": 1.0296,
      "step": 9960
    },
    {
      "epoch": 3.77,
      "learning_rate": 0.00018293737111151192,
      "loss": 1.041,
      "step": 9970
    },
    {
      "epoch": 3.78,
      "learning_rate": 0.00018290412680149084,
      "loss": 1.0652,
      "step": 9980
    },
    {
      "epoch": 3.78,
      "learning_rate": 0.00018287085316369666,
      "loss": 1.0658,
      "step": 9990
    },
    {
      "epoch": 3.79,
      "learning_rate": 0.00018283755020990003,
      "loss": 1.026,
      "step": 10000
    },
    {
      "epoch": 3.79,
      "learning_rate": 0.0001828042179518821,
      "loss": 1.0047,
      "step": 10010
    },
    {
      "epoch": 3.79,
      "learning_rate": 0.00018277085640143432,
      "loss": 0.9974,
      "step": 10020
    },
    {
      "epoch": 3.8,
      "learning_rate": 0.00018273746557035848,
      "loss": 1.0411,
      "step": 10030
    },
    {
      "epoch": 3.8,
      "learning_rate": 0.0001827040454704668,
      "loss": 1.0951,
      "step": 10040
    },
    {
      "epoch": 3.81,
      "learning_rate": 0.00018267059611358182,
      "loss": 1.0457,
      "step": 10050
    },
    {
      "epoch": 3.81,
      "learning_rate": 0.0001826371175115364,
      "loss": 0.9991,
      "step": 10060
    },
    {
      "epoch": 3.81,
      "learning_rate": 0.0001826036096761738,
      "loss": 1.0414,
      "step": 10070
    },
    {
      "epoch": 3.82,
      "learning_rate": 0.00018257007261934756,
      "loss": 1.008,
      "step": 10080
    },
    {
      "epoch": 3.82,
      "learning_rate": 0.00018253650635292163,
      "loss": 0.9808,
      "step": 10090
    },
    {
      "epoch": 3.82,
      "learning_rate": 0.00018250291088877022,
      "loss": 1.0075,
      "step": 10100
    },
    {
      "epoch": 3.83,
      "learning_rate": 0.00018246928623877792,
      "loss": 1.014,
      "step": 10110
    },
    {
      "epoch": 3.83,
      "learning_rate": 0.00018243563241483965,
      "loss": 1.0305,
      "step": 10120
    },
    {
      "epoch": 3.84,
      "learning_rate": 0.0001824019494288606,
      "loss": 1.0514,
      "step": 10130
    },
    {
      "epoch": 3.84,
      "learning_rate": 0.0001823682372927563,
      "loss": 1.0441,
      "step": 10140
    },
    {
      "epoch": 3.84,
      "learning_rate": 0.00018233449601845258,
      "loss": 1.0213,
      "step": 10150
    },
    {
      "epoch": 3.85,
      "learning_rate": 0.00018230072561788564,
      "loss": 1.0364,
      "step": 10160
    },
    {
      "epoch": 3.85,
      "learning_rate": 0.00018226692610300192,
      "loss": 1.096,
      "step": 10170
    },
    {
      "epoch": 3.85,
      "learning_rate": 0.0001822330974857582,
      "loss": 1.0513,
      "step": 10180
    },
    {
      "epoch": 3.86,
      "learning_rate": 0.00018219923977812145,
      "loss": 0.9857,
      "step": 10190
    },
    {
      "epoch": 3.86,
      "learning_rate": 0.0001821653529920691,
      "loss": 1.048,
      "step": 10200
    },
    {
      "epoch": 3.87,
      "learning_rate": 0.00018213143713958875,
      "loss": 1.0703,
      "step": 10210
    },
    {
      "epoch": 3.87,
      "learning_rate": 0.00018209749223267833,
      "loss": 1.1098,
      "step": 10220
    },
    {
      "epoch": 3.87,
      "learning_rate": 0.00018206351828334598,
      "loss": 1.0393,
      "step": 10230
    },
    {
      "epoch": 3.88,
      "learning_rate": 0.0001820295153036102,
      "loss": 1.0457,
      "step": 10240
    },
    {
      "epoch": 3.88,
      "learning_rate": 0.00018199548330549974,
      "loss": 1.0171,
      "step": 10250
    },
    {
      "epoch": 3.88,
      "learning_rate": 0.00018196142230105354,
      "loss": 1.0288,
      "step": 10260
    },
    {
      "epoch": 3.89,
      "learning_rate": 0.00018192733230232096,
      "loss": 1.0011,
      "step": 10270
    },
    {
      "epoch": 3.89,
      "learning_rate": 0.0001818932133213614,
      "loss": 1.0693,
      "step": 10280
    },
    {
      "epoch": 3.9,
      "learning_rate": 0.00018185906537024473,
      "loss": 1.0622,
      "step": 10290
    },
    {
      "epoch": 3.9,
      "learning_rate": 0.00018182488846105088,
      "loss": 1.0224,
      "step": 10300
    },
    {
      "epoch": 3.9,
      "learning_rate": 0.0001817906826058702,
      "loss": 1.0205,
      "step": 10310
    },
    {
      "epoch": 3.91,
      "learning_rate": 0.0001817564478168031,
      "loss": 1.0006,
      "step": 10320
    },
    {
      "epoch": 3.91,
      "learning_rate": 0.0001817221841059604,
      "loss": 1.0509,
      "step": 10330
    },
    {
      "epoch": 3.91,
      "learning_rate": 0.00018168789148546304,
      "loss": 1.0419,
      "step": 10340
    },
    {
      "epoch": 3.92,
      "learning_rate": 0.0001816535699674422,
      "loss": 1.0258,
      "step": 10350
    },
    {
      "epoch": 3.92,
      "learning_rate": 0.00018161921956403934,
      "loss": 0.949,
      "step": 10360
    },
    {
      "epoch": 3.93,
      "learning_rate": 0.00018158484028740602,
      "loss": 0.9858,
      "step": 10370
    },
    {
      "epoch": 3.93,
      "learning_rate": 0.00018155043214970415,
      "loss": 1.0234,
      "step": 10380
    },
    {
      "epoch": 3.93,
      "learning_rate": 0.0001815159951631058,
      "loss": 1.0095,
      "step": 10390
    },
    {
      "epoch": 3.94,
      "learning_rate": 0.00018148152933979318,
      "loss": 0.9982,
      "step": 10400
    },
    {
      "epoch": 3.94,
      "learning_rate": 0.00018144703469195883,
      "loss": 1.0151,
      "step": 10410
    },
    {
      "epoch": 3.95,
      "learning_rate": 0.00018141251123180533,
      "loss": 1.0356,
      "step": 10420
    },
    {
      "epoch": 3.95,
      "learning_rate": 0.00018137795897154563,
      "loss": 1.0858,
      "step": 10430
    },
    {
      "epoch": 3.95,
      "learning_rate": 0.0001813433779234027,
      "loss": 1.0213,
      "step": 10440
    },
    {
      "epoch": 3.96,
      "learning_rate": 0.0001813087680996098,
      "loss": 1.0099,
      "step": 10450
    },
    {
      "epoch": 3.96,
      "learning_rate": 0.00018127412951241033,
      "loss": 1.0455,
      "step": 10460
    },
    {
      "epoch": 3.96,
      "learning_rate": 0.0001812394621740579,
      "loss": 1.0198,
      "step": 10470
    },
    {
      "epoch": 3.97,
      "learning_rate": 0.00018120476609681622,
      "loss": 1.0198,
      "step": 10480
    },
    {
      "epoch": 3.97,
      "learning_rate": 0.0001811700412929592,
      "loss": 1.0531,
      "step": 10490
    },
    {
      "epoch": 3.98,
      "learning_rate": 0.000181135287774771,
      "loss": 0.9897,
      "step": 10500
    },
    {
      "epoch": 3.98,
      "learning_rate": 0.0001811005055545458,
      "loss": 1.0253,
      "step": 10510
    },
    {
      "epoch": 3.98,
      "learning_rate": 0.00018106569464458803,
      "loss": 1.0425,
      "step": 10520
    },
    {
      "epoch": 3.99,
      "learning_rate": 0.00018103085505721217,
      "loss": 0.9916,
      "step": 10530
    },
    {
      "epoch": 3.99,
      "learning_rate": 0.000180995986804743,
      "loss": 1.0347,
      "step": 10540
    },
    {
      "epoch": 3.99,
      "learning_rate": 0.00018096108989951529,
      "loss": 1.0255,
      "step": 10550
    },
    {
      "epoch": 4.0,
      "learning_rate": 0.00018092616435387397,
      "loss": 1.0712,
      "step": 10560
    },
    {
      "epoch": 4.0,
      "learning_rate": 0.00018089121018017424,
      "loss": 0.9892,
      "step": 10570
    },
    {
      "epoch": 4.01,
      "learning_rate": 0.00018085622739078122,
      "loss": 1.0276,
      "step": 10580
    },
    {
      "epoch": 4.01,
      "learning_rate": 0.00018082121599807032,
      "loss": 0.9864,
      "step": 10590
    },
    {
      "epoch": 4.01,
      "learning_rate": 0.00018078617601442696,
      "loss": 1.0253,
      "step": 10600
    },
    {
      "epoch": 4.02,
      "learning_rate": 0.0001807511074522468,
      "loss": 0.9966,
      "step": 10610
    },
    {
      "epoch": 4.02,
      "learning_rate": 0.00018071601032393545,
      "loss": 0.9811,
      "step": 10620
    },
    {
      "epoch": 4.02,
      "learning_rate": 0.0001806808846419087,
      "loss": 1.0169,
      "step": 10630
    },
    {
      "epoch": 4.03,
      "learning_rate": 0.00018064573041859253,
      "loss": 1.0347,
      "step": 10640
    },
    {
      "epoch": 4.03,
      "learning_rate": 0.00018061054766642284,
      "loss": 1.0365,
      "step": 10650
    },
    {
      "epoch": 4.04,
      "learning_rate": 0.0001805753363978458,
      "loss": 1.0459,
      "step": 10660
    },
    {
      "epoch": 4.04,
      "learning_rate": 0.00018054009662531748,
      "loss": 1.003,
      "step": 10670
    },
    {
      "epoch": 4.04,
      "learning_rate": 0.00018050482836130422,
      "loss": 0.9718,
      "step": 10680
    },
    {
      "epoch": 4.05,
      "learning_rate": 0.0001804695316182823,
      "loss": 0.9808,
      "step": 10690
    },
    {
      "epoch": 4.05,
      "learning_rate": 0.00018043420640873818,
      "loss": 1.0421,
      "step": 10700
    },
    {
      "epoch": 4.05,
      "learning_rate": 0.00018039885274516833,
      "loss": 0.9959,
      "step": 10710
    },
    {
      "epoch": 4.06,
      "learning_rate": 0.00018036347064007924,
      "loss": 1.0135,
      "step": 10720
    },
    {
      "epoch": 4.06,
      "learning_rate": 0.00018032806010598757,
      "loss": 0.9756,
      "step": 10730
    },
    {
      "epoch": 4.07,
      "learning_rate": 0.00018029262115542,
      "loss": 0.9796,
      "step": 10740
    },
    {
      "epoch": 4.07,
      "learning_rate": 0.0001802571538009132,
      "loss": 0.9854,
      "step": 10750
    },
    {
      "epoch": 4.07,
      "learning_rate": 0.00018022165805501393,
      "loss": 0.986,
      "step": 10760
    },
    {
      "epoch": 4.08,
      "learning_rate": 0.00018018613393027904,
      "loss": 1.0448,
      "step": 10770
    },
    {
      "epoch": 4.08,
      "learning_rate": 0.00018015058143927535,
      "loss": 0.9623,
      "step": 10780
    },
    {
      "epoch": 4.09,
      "learning_rate": 0.00018011500059457973,
      "loss": 1.0446,
      "step": 10790
    },
    {
      "epoch": 4.09,
      "learning_rate": 0.00018007939140877915,
      "loss": 0.9655,
      "step": 10800
    },
    {
      "epoch": 4.09,
      "learning_rate": 0.00018004375389447046,
      "loss": 1.0211,
      "step": 10810
    },
    {
      "epoch": 4.1,
      "learning_rate": 0.0001800080880642607,
      "loss": 1.0076,
      "step": 10820
    },
    {
      "epoch": 4.1,
      "learning_rate": 0.00017997239393076678,
      "loss": 0.9779,
      "step": 10830
    },
    {
      "epoch": 4.1,
      "learning_rate": 0.00017993667150661575,
      "loss": 1.0191,
      "step": 10840
    },
    {
      "epoch": 4.11,
      "learning_rate": 0.00017990092080444458,
      "loss": 0.9828,
      "step": 10850
    },
    {
      "epoch": 4.11,
      "learning_rate": 0.00017986514183690027,
      "loss": 0.9724,
      "step": 10860
    },
    {
      "epoch": 4.12,
      "learning_rate": 0.0001798293346166398,
      "loss": 1.0275,
      "step": 10870
    },
    {
      "epoch": 4.12,
      "learning_rate": 0.00017979349915633018,
      "loss": 1.0412,
      "step": 10880
    },
    {
      "epoch": 4.12,
      "learning_rate": 0.00017975763546864839,
      "loss": 0.999,
      "step": 10890
    },
    {
      "epoch": 4.13,
      "learning_rate": 0.00017972174356628142,
      "loss": 1.013,
      "step": 10900
    },
    {
      "epoch": 4.13,
      "learning_rate": 0.00017968582346192618,
      "loss": 0.9733,
      "step": 10910
    },
    {
      "epoch": 4.13,
      "learning_rate": 0.0001796498751682896,
      "loss": 0.979,
      "step": 10920
    },
    {
      "epoch": 4.14,
      "learning_rate": 0.00017961389869808865,
      "loss": 1.0121,
      "step": 10930
    },
    {
      "epoch": 4.14,
      "learning_rate": 0.00017957789406405014,
      "loss": 1.0227,
      "step": 10940
    },
    {
      "epoch": 4.15,
      "learning_rate": 0.00017954186127891087,
      "loss": 1.0279,
      "step": 10950
    },
    {
      "epoch": 4.15,
      "learning_rate": 0.00017950580035541765,
      "loss": 0.999,
      "step": 10960
    },
    {
      "epoch": 4.15,
      "learning_rate": 0.0001794697113063273,
      "loss": 1.032,
      "step": 10970
    },
    {
      "epoch": 4.16,
      "learning_rate": 0.0001794335941444064,
      "loss": 0.9819,
      "step": 10980
    },
    {
      "epoch": 4.16,
      "learning_rate": 0.0001793974488824316,
      "loss": 0.9894,
      "step": 10990
    },
    {
      "epoch": 4.16,
      "learning_rate": 0.00017936127553318959,
      "loss": 0.9942,
      "step": 11000
    },
    {
      "epoch": 4.17,
      "learning_rate": 0.00017932507410947676,
      "loss": 1.0335,
      "step": 11010
    },
    {
      "epoch": 4.17,
      "learning_rate": 0.00017928884462409958,
      "loss": 1.0249,
      "step": 11020
    },
    {
      "epoch": 4.18,
      "learning_rate": 0.0001792525870898745,
      "loss": 1.0371,
      "step": 11030
    },
    {
      "epoch": 4.18,
      "learning_rate": 0.0001792163015196277,
      "loss": 1.0088,
      "step": 11040
    },
    {
      "epoch": 4.18,
      "learning_rate": 0.00017917998792619548,
      "loss": 1.0505,
      "step": 11050
    },
    {
      "epoch": 4.19,
      "learning_rate": 0.00017914364632242393,
      "loss": 0.9785,
      "step": 11060
    },
    {
      "epoch": 4.19,
      "learning_rate": 0.00017910727672116908,
      "loss": 1.0482,
      "step": 11070
    },
    {
      "epoch": 4.19,
      "learning_rate": 0.0001790708791352969,
      "loss": 0.9636,
      "step": 11080
    },
    {
      "epoch": 4.2,
      "learning_rate": 0.00017903445357768315,
      "loss": 1.045,
      "step": 11090
    },
    {
      "epoch": 4.2,
      "learning_rate": 0.00017899800006121366,
      "loss": 0.9537,
      "step": 11100
    },
    {
      "epoch": 4.21,
      "learning_rate": 0.00017896151859878403,
      "loss": 0.9446,
      "step": 11110
    },
    {
      "epoch": 4.21,
      "learning_rate": 0.00017892500920329974,
      "loss": 1.0096,
      "step": 11120
    },
    {
      "epoch": 4.21,
      "learning_rate": 0.00017888847188767616,
      "loss": 0.9814,
      "step": 11130
    },
    {
      "epoch": 4.22,
      "learning_rate": 0.00017885190666483864,
      "loss": 1.0299,
      "step": 11140
    },
    {
      "epoch": 4.22,
      "learning_rate": 0.00017881531354772224,
      "loss": 0.9816,
      "step": 11150
    },
    {
      "epoch": 4.23,
      "learning_rate": 0.00017877869254927204,
      "loss": 1.0436,
      "step": 11160
    },
    {
      "epoch": 4.23,
      "learning_rate": 0.00017874204368244283,
      "loss": 1.0459,
      "step": 11170
    },
    {
      "epoch": 4.23,
      "learning_rate": 0.00017870536696019943,
      "loss": 1.0117,
      "step": 11180
    },
    {
      "epoch": 4.24,
      "learning_rate": 0.00017866866239551633,
      "loss": 1.0327,
      "step": 11190
    },
    {
      "epoch": 4.24,
      "learning_rate": 0.00017863193000137805,
      "loss": 1.0067,
      "step": 11200
    },
    {
      "epoch": 4.24,
      "learning_rate": 0.00017859516979077883,
      "loss": 1.0307,
      "step": 11210
    },
    {
      "epoch": 4.25,
      "learning_rate": 0.00017855838177672278,
      "loss": 1.0172,
      "step": 11220
    },
    {
      "epoch": 4.25,
      "learning_rate": 0.00017852156597222387,
      "loss": 0.9859,
      "step": 11230
    },
    {
      "epoch": 4.26,
      "learning_rate": 0.00017848472239030588,
      "loss": 1.0384,
      "step": 11240
    },
    {
      "epoch": 4.26,
      "learning_rate": 0.00017844785104400242,
      "loss": 0.9612,
      "step": 11250
    },
    {
      "epoch": 4.26,
      "learning_rate": 0.00017841095194635694,
      "loss": 0.9715,
      "step": 11260
    },
    {
      "epoch": 4.27,
      "learning_rate": 0.00017837402511042266,
      "loss": 1.0,
      "step": 11270
    },
    {
      "epoch": 4.27,
      "learning_rate": 0.00017833707054926268,
      "loss": 1.0271,
      "step": 11280
    },
    {
      "epoch": 4.27,
      "learning_rate": 0.00017830008827594983,
      "loss": 1.0215,
      "step": 11290
    },
    {
      "epoch": 4.28,
      "learning_rate": 0.00017826307830356682,
      "loss": 0.9987,
      "step": 11300
    },
    {
      "epoch": 4.28,
      "learning_rate": 0.00017822604064520614,
      "loss": 1.0223,
      "step": 11310
    },
    {
      "epoch": 4.29,
      "learning_rate": 0.00017818897531396996,
      "loss": 1.0277,
      "step": 11320
    },
    {
      "epoch": 4.29,
      "learning_rate": 0.00017815188232297047,
      "loss": 0.9922,
      "step": 11330
    },
    {
      "epoch": 4.29,
      "learning_rate": 0.00017811476168532942,
      "loss": 1.0217,
      "step": 11340
    },
    {
      "epoch": 4.3,
      "learning_rate": 0.00017807761341417843,
      "loss": 1.0017,
      "step": 11350
    },
    {
      "epoch": 4.3,
      "learning_rate": 0.00017804043752265897,
      "loss": 0.9765,
      "step": 11360
    },
    {
      "epoch": 4.3,
      "learning_rate": 0.00017800323402392213,
      "loss": 1.0028,
      "step": 11370
    },
    {
      "epoch": 4.31,
      "learning_rate": 0.00017796600293112891,
      "loss": 1.0964,
      "step": 11380
    },
    {
      "epoch": 4.31,
      "learning_rate": 0.00017792874425744993,
      "loss": 1.0131,
      "step": 11390
    },
    {
      "epoch": 4.32,
      "learning_rate": 0.00017789145801606573,
      "loss": 0.9893,
      "step": 11400
    },
    {
      "epoch": 4.32,
      "learning_rate": 0.00017785414422016643,
      "loss": 0.9881,
      "step": 11410
    },
    {
      "epoch": 4.32,
      "learning_rate": 0.00017781680288295206,
      "loss": 1.024,
      "step": 11420
    },
    {
      "epoch": 4.33,
      "learning_rate": 0.00017777943401763228,
      "loss": 1.0122,
      "step": 11430
    },
    {
      "epoch": 4.33,
      "learning_rate": 0.0001777420376374265,
      "loss": 1.0748,
      "step": 11440
    },
    {
      "epoch": 4.34,
      "learning_rate": 0.00017770461375556394,
      "loss": 1.0096,
      "step": 11450
    },
    {
      "epoch": 4.34,
      "learning_rate": 0.00017766716238528345,
      "loss": 1.0205,
      "step": 11460
    },
    {
      "epoch": 4.34,
      "learning_rate": 0.00017762968353983365,
      "loss": 0.9888,
      "step": 11470
    },
    {
      "epoch": 4.35,
      "learning_rate": 0.0001775921772324729,
      "loss": 1.0285,
      "step": 11480
    },
    {
      "epoch": 4.35,
      "learning_rate": 0.00017755464347646928,
      "loss": 1.0117,
      "step": 11490
    },
    {
      "epoch": 4.35,
      "learning_rate": 0.0001775170822851005,
      "loss": 1.0045,
      "step": 11500
    },
    {
      "epoch": 4.36,
      "learning_rate": 0.0001774794936716541,
      "loss": 1.006,
      "step": 11510
    },
    {
      "epoch": 4.36,
      "learning_rate": 0.00017744187764942714,
      "loss": 1.0456,
      "step": 11520
    },
    {
      "epoch": 4.37,
      "learning_rate": 0.00017740423423172658,
      "loss": 0.9518,
      "step": 11530
    },
    {
      "epoch": 4.37,
      "learning_rate": 0.00017736656343186896,
      "loss": 1.0226,
      "step": 11540
    },
    {
      "epoch": 4.37,
      "learning_rate": 0.0001773288652631805,
      "loss": 1.0655,
      "step": 11550
    },
    {
      "epoch": 4.38,
      "learning_rate": 0.00017729113973899717,
      "loss": 1.0379,
      "step": 11560
    },
    {
      "epoch": 4.38,
      "learning_rate": 0.0001772533868726645,
      "loss": 0.9497,
      "step": 11570
    },
    {
      "epoch": 4.38,
      "learning_rate": 0.00017721560667753784,
      "loss": 1.0092,
      "step": 11580
    },
    {
      "epoch": 4.39,
      "learning_rate": 0.00017717779916698212,
      "loss": 0.9988,
      "step": 11590
    },
    {
      "epoch": 4.39,
      "learning_rate": 0.00017713996435437192,
      "loss": 0.9788,
      "step": 11600
    },
    {
      "epoch": 4.4,
      "learning_rate": 0.00017710210225309152,
      "loss": 1.0347,
      "step": 11610
    },
    {
      "epoch": 4.4,
      "learning_rate": 0.00017706421287653484,
      "loss": 1.0052,
      "step": 11620
    },
    {
      "epoch": 4.4,
      "learning_rate": 0.00017702629623810544,
      "loss": 1.0038,
      "step": 11630
    },
    {
      "epoch": 4.41,
      "learning_rate": 0.0001769883523512165,
      "loss": 0.9936,
      "step": 11640
    },
    {
      "epoch": 4.41,
      "learning_rate": 0.00017695038122929094,
      "loss": 1.0357,
      "step": 11650
    },
    {
      "epoch": 4.41,
      "learning_rate": 0.0001769123828857612,
      "loss": 0.9723,
      "step": 11660
    },
    {
      "epoch": 4.42,
      "learning_rate": 0.00017687435733406944,
      "loss": 1.0432,
      "step": 11670
    },
    {
      "epoch": 4.42,
      "learning_rate": 0.0001768363045876673,
      "loss": 0.9905,
      "step": 11680
    },
    {
      "epoch": 4.43,
      "learning_rate": 0.00017679822466001624,
      "loss": 1.0325,
      "step": 11690
    },
    {
      "epoch": 4.43,
      "learning_rate": 0.00017676011756458722,
      "loss": 1.0321,
      "step": 11700
    },
    {
      "epoch": 4.43,
      "learning_rate": 0.0001767219833148608,
      "loss": 1.0449,
      "step": 11710
    },
    {
      "epoch": 4.44,
      "learning_rate": 0.00017668382192432714,
      "loss": 0.9908,
      "step": 11720
    },
    {
      "epoch": 4.44,
      "learning_rate": 0.0001766456334064861,
      "loss": 1.0079,
      "step": 11730
    },
    {
      "epoch": 4.44,
      "learning_rate": 0.00017660741777484704,
      "loss": 1.0774,
      "step": 11740
    },
    {
      "epoch": 4.45,
      "learning_rate": 0.00017656917504292895,
      "loss": 1.0139,
      "step": 11750
    },
    {
      "epoch": 4.45,
      "learning_rate": 0.0001765309052242604,
      "loss": 1.0802,
      "step": 11760
    },
    {
      "epoch": 4.46,
      "learning_rate": 0.0001764926083323795,
      "loss": 1.0508,
      "step": 11770
    },
    {
      "epoch": 4.46,
      "learning_rate": 0.00017645428438083405,
      "loss": 1.013,
      "step": 11780
    },
    {
      "epoch": 4.46,
      "learning_rate": 0.00017641593338318132,
      "loss": 0.9957,
      "step": 11790
    },
    {
      "epoch": 4.47,
      "learning_rate": 0.00017637755535298815,
      "loss": 1.0219,
      "step": 11800
    },
    {
      "epoch": 4.47,
      "learning_rate": 0.00017633915030383098,
      "loss": 1.0103,
      "step": 11810
    },
    {
      "epoch": 4.48,
      "learning_rate": 0.00017630071824929584,
      "loss": 0.9862,
      "step": 11820
    },
    {
      "epoch": 4.48,
      "learning_rate": 0.00017626225920297823,
      "loss": 1.0543,
      "step": 11830
    },
    {
      "epoch": 4.48,
      "learning_rate": 0.00017622377317848327,
      "loss": 1.011,
      "step": 11840
    },
    {
      "epoch": 4.49,
      "learning_rate": 0.00017618526018942557,
      "loss": 0.9993,
      "step": 11850
    },
    {
      "epoch": 4.49,
      "learning_rate": 0.0001761467202494293,
      "loss": 0.9707,
      "step": 11860
    },
    {
      "epoch": 4.49,
      "learning_rate": 0.0001761081533721282,
      "loss": 0.9786,
      "step": 11870
    },
    {
      "epoch": 4.5,
      "learning_rate": 0.00017606955957116544,
      "loss": 0.9996,
      "step": 11880
    },
    {
      "epoch": 4.5,
      "learning_rate": 0.0001760309388601939,
      "loss": 1.0247,
      "step": 11890
    },
    {
      "epoch": 4.51,
      "learning_rate": 0.00017599229125287572,
      "loss": 1.0546,
      "step": 11900
    },
    {
      "epoch": 4.51,
      "learning_rate": 0.0001759536167628828,
      "loss": 0.965,
      "step": 11910
    },
    {
      "epoch": 4.51,
      "learning_rate": 0.00017591491540389643,
      "loss": 1.076,
      "step": 11920
    },
    {
      "epoch": 4.52,
      "learning_rate": 0.00017587618718960734,
      "loss": 0.9857,
      "step": 11930
    },
    {
      "epoch": 4.52,
      "learning_rate": 0.00017583743213371594,
      "loss": 1.0289,
      "step": 11940
    },
    {
      "epoch": 4.52,
      "learning_rate": 0.00017579865024993198,
      "loss": 0.9881,
      "step": 11950
    },
    {
      "epoch": 4.53,
      "learning_rate": 0.00017575984155197483,
      "loss": 0.9874,
      "step": 11960
    },
    {
      "epoch": 4.53,
      "learning_rate": 0.00017572100605357314,
      "loss": 1.0386,
      "step": 11970
    },
    {
      "epoch": 4.54,
      "learning_rate": 0.0001756821437684653,
      "loss": 1.0773,
      "step": 11980
    },
    {
      "epoch": 4.54,
      "learning_rate": 0.00017564325471039894,
      "loss": 0.9992,
      "step": 11990
    },
    {
      "epoch": 4.54,
      "learning_rate": 0.00017560433889313138,
      "loss": 1.0473,
      "step": 12000
    },
    {
      "epoch": 4.55,
      "learning_rate": 0.00017556539633042923,
      "loss": 0.9952,
      "step": 12010
    },
    {
      "epoch": 4.55,
      "learning_rate": 0.00017552642703606863,
      "loss": 1.0296,
      "step": 12020
    },
    {
      "epoch": 4.55,
      "learning_rate": 0.0001754874310238352,
      "loss": 1.0294,
      "step": 12030
    },
    {
      "epoch": 4.56,
      "learning_rate": 0.00017544840830752395,
      "loss": 1.078,
      "step": 12040
    },
    {
      "epoch": 4.56,
      "learning_rate": 0.0001754093589009394,
      "loss": 1.0101,
      "step": 12050
    },
    {
      "epoch": 4.57,
      "learning_rate": 0.00017537028281789548,
      "loss": 0.9828,
      "step": 12060
    },
    {
      "epoch": 4.57,
      "learning_rate": 0.00017533118007221553,
      "loss": 1.0563,
      "step": 12070
    },
    {
      "epoch": 4.57,
      "learning_rate": 0.00017529205067773242,
      "loss": 1.0776,
      "step": 12080
    },
    {
      "epoch": 4.58,
      "learning_rate": 0.00017525289464828832,
      "loss": 0.9791,
      "step": 12090
    },
    {
      "epoch": 4.58,
      "learning_rate": 0.00017521371199773488,
      "loss": 1.0359,
      "step": 12100
    },
    {
      "epoch": 4.58,
      "learning_rate": 0.00017517450273993323,
      "loss": 0.9645,
      "step": 12110
    },
    {
      "epoch": 4.59,
      "learning_rate": 0.0001751352668887538,
      "loss": 1.0367,
      "step": 12120
    },
    {
      "epoch": 4.59,
      "learning_rate": 0.0001750960044580765,
      "loss": 1.044,
      "step": 12130
    },
    {
      "epoch": 4.6,
      "learning_rate": 0.0001750567154617906,
      "loss": 1.0302,
      "step": 12140
    },
    {
      "epoch": 4.6,
      "learning_rate": 0.0001750173999137948,
      "loss": 0.9512,
      "step": 12150
    },
    {
      "epoch": 4.6,
      "learning_rate": 0.00017497805782799722,
      "loss": 0.9829,
      "step": 12160
    },
    {
      "epoch": 4.61,
      "learning_rate": 0.00017493868921831528,
      "loss": 1.0622,
      "step": 12170
    },
    {
      "epoch": 4.61,
      "learning_rate": 0.00017489929409867587,
      "loss": 0.9551,
      "step": 12180
    },
    {
      "epoch": 4.62,
      "learning_rate": 0.0001748598724830152,
      "loss": 1.0205,
      "step": 12190
    },
    {
      "epoch": 4.62,
      "learning_rate": 0.00017482042438527885,
      "loss": 1.0296,
      "step": 12200
    },
    {
      "epoch": 4.62,
      "learning_rate": 0.00017478094981942185,
      "loss": 1.0214,
      "step": 12210
    },
    {
      "epoch": 4.63,
      "learning_rate": 0.0001747414487994085,
      "loss": 0.9815,
      "step": 12220
    },
    {
      "epoch": 4.63,
      "learning_rate": 0.00017470192133921253,
      "loss": 1.0396,
      "step": 12230
    },
    {
      "epoch": 4.63,
      "learning_rate": 0.00017466236745281697,
      "loss": 1.0227,
      "step": 12240
    },
    {
      "epoch": 4.64,
      "learning_rate": 0.0001746227871542142,
      "loss": 1.0449,
      "step": 12250
    },
    {
      "epoch": 4.64,
      "learning_rate": 0.00017458318045740593,
      "loss": 1.0023,
      "step": 12260
    },
    {
      "epoch": 4.65,
      "learning_rate": 0.0001745435473764033,
      "loss": 1.0296,
      "step": 12270
    },
    {
      "epoch": 4.65,
      "learning_rate": 0.0001745038879252267,
      "loss": 0.9889,
      "step": 12280
    },
    {
      "epoch": 4.65,
      "learning_rate": 0.0001744642021179059,
      "loss": 1.0507,
      "step": 12290
    },
    {
      "epoch": 4.66,
      "learning_rate": 0.0001744244899684799,
      "loss": 1.021,
      "step": 12300
    },
    {
      "epoch": 4.66,
      "learning_rate": 0.00017438475149099715,
      "loss": 1.0066,
      "step": 12310
    },
    {
      "epoch": 4.66,
      "learning_rate": 0.00017434498669951528,
      "loss": 1.0102,
      "step": 12320
    },
    {
      "epoch": 4.67,
      "learning_rate": 0.00017430519560810134,
      "loss": 0.9879,
      "step": 12330
    },
    {
      "epoch": 4.67,
      "learning_rate": 0.0001742653782308316,
      "loss": 0.9733,
      "step": 12340
    },
    {
      "epoch": 4.68,
      "learning_rate": 0.00017422553458179172,
      "loss": 1.0608,
      "step": 12350
    },
    {
      "epoch": 4.68,
      "learning_rate": 0.00017418566467507657,
      "loss": 1.0174,
      "step": 12360
    },
    {
      "epoch": 4.68,
      "learning_rate": 0.00017414576852479036,
      "loss": 0.9713,
      "step": 12370
    },
    {
      "epoch": 4.69,
      "learning_rate": 0.00017410584614504658,
      "loss": 0.9794,
      "step": 12380
    },
    {
      "epoch": 4.69,
      "learning_rate": 0.0001740658975499679,
      "loss": 0.981,
      "step": 12390
    },
    {
      "epoch": 4.69,
      "learning_rate": 0.0001740259227536864,
      "loss": 1.0737,
      "step": 12400
    },
    {
      "epoch": 4.7,
      "learning_rate": 0.0001739859217703434,
      "loss": 1.0106,
      "step": 12410
    },
    {
      "epoch": 4.7,
      "learning_rate": 0.00017394589461408946,
      "loss": 1.0061,
      "step": 12420
    },
    {
      "epoch": 4.71,
      "learning_rate": 0.00017390584129908435,
      "loss": 0.95,
      "step": 12430
    },
    {
      "epoch": 4.71,
      "learning_rate": 0.00017386576183949716,
      "loss": 1.0123,
      "step": 12440
    },
    {
      "epoch": 4.71,
      "learning_rate": 0.00017382565624950624,
      "loss": 0.9558,
      "step": 12450
    },
    {
      "epoch": 4.72,
      "learning_rate": 0.0001737855245432991,
      "loss": 1.0417,
      "step": 12460
    },
    {
      "epoch": 4.72,
      "learning_rate": 0.0001737453667350726,
      "loss": 1.0048,
      "step": 12470
    },
    {
      "epoch": 4.73,
      "learning_rate": 0.00017370518283903272,
      "loss": 0.993,
      "step": 12480
    },
    {
      "epoch": 4.73,
      "learning_rate": 0.0001736649728693948,
      "loss": 1.0139,
      "step": 12490
    },
    {
      "epoch": 4.73,
      "learning_rate": 0.00017362473684038324,
      "loss": 1.0066,
      "step": 12500
    },
    {
      "epoch": 4.74,
      "learning_rate": 0.00017358447476623182,
      "loss": 1.0015,
      "step": 12510
    },
    {
      "epoch": 4.74,
      "learning_rate": 0.00017354418666118342,
      "loss": 1.0109,
      "step": 12520
    },
    {
      "epoch": 4.74,
      "learning_rate": 0.00017350387253949019,
      "loss": 1.0672,
      "step": 12530
    },
    {
      "epoch": 4.75,
      "learning_rate": 0.00017346353241541346,
      "loss": 1.0586,
      "step": 12540
    },
    {
      "epoch": 4.75,
      "learning_rate": 0.00017342316630322377,
      "loss": 1.0726,
      "step": 12550
    },
    {
      "epoch": 4.76,
      "learning_rate": 0.00017338277421720085,
      "loss": 1.011,
      "step": 12560
    },
    {
      "epoch": 4.76,
      "learning_rate": 0.00017334235617163358,
      "loss": 1.0549,
      "step": 12570
    },
    {
      "epoch": 4.76,
      "learning_rate": 0.00017330191218082008,
      "loss": 0.9922,
      "step": 12580
    },
    {
      "epoch": 4.77,
      "learning_rate": 0.00017326144225906763,
      "loss": 0.956,
      "step": 12590
    },
    {
      "epoch": 4.77,
      "learning_rate": 0.00017322094642069265,
      "loss": 0.995,
      "step": 12600
    },
    {
      "epoch": 4.77,
      "learning_rate": 0.00017318042468002082,
      "loss": 1.0317,
      "step": 12610
    },
    {
      "epoch": 4.78,
      "learning_rate": 0.00017313987705138686,
      "loss": 0.9971,
      "step": 12620
    },
    {
      "epoch": 4.78,
      "learning_rate": 0.00017309930354913474,
      "loss": 0.997,
      "step": 12630
    },
    {
      "epoch": 4.79,
      "learning_rate": 0.00017306276528702692,
      "loss": 1.0347,
      "step": 12640
    },
    {
      "epoch": 4.79,
      "learning_rate": 0.0001730221426644506,
      "loss": 0.9964,
      "step": 12650
    },
    {
      "epoch": 4.79,
      "learning_rate": 0.00017298149420990523,
      "loss": 1.0394,
      "step": 12660
    },
    {
      "epoch": 4.8,
      "learning_rate": 0.0001729408199377705,
      "loss": 0.9743,
      "step": 12670
    },
    {
      "epoch": 4.8,
      "learning_rate": 0.00017290011986243508,
      "loss": 1.0521,
      "step": 12680
    },
    {
      "epoch": 4.8,
      "learning_rate": 0.00017285939399829686,
      "loss": 1.0353,
      "step": 12690
    },
    {
      "epoch": 4.81,
      "learning_rate": 0.00017281864235976286,
      "loss": 1.0032,
      "step": 12700
    },
    {
      "epoch": 4.81,
      "learning_rate": 0.00017277786496124913,
      "loss": 1.0433,
      "step": 12710
    },
    {
      "epoch": 4.82,
      "learning_rate": 0.00017273706181718091,
      "loss": 0.9573,
      "step": 12720
    },
    {
      "epoch": 4.82,
      "learning_rate": 0.00017269623294199256,
      "loss": 1.0874,
      "step": 12730
    },
    {
      "epoch": 4.82,
      "learning_rate": 0.00017265537835012748,
      "loss": 1.01,
      "step": 12740
    },
    {
      "epoch": 4.83,
      "learning_rate": 0.0001726144980560382,
      "loss": 1.0061,
      "step": 12750
    },
    {
      "epoch": 4.83,
      "learning_rate": 0.00017257359207418634,
      "loss": 1.044,
      "step": 12760
    },
    {
      "epoch": 4.83,
      "learning_rate": 0.00017253266041904265,
      "loss": 1.0037,
      "step": 12770
    },
    {
      "epoch": 4.84,
      "learning_rate": 0.00017249170310508683,
      "loss": 0.9817,
      "step": 12780
    },
    {
      "epoch": 4.84,
      "learning_rate": 0.00017245072014680782,
      "loss": 1.0147,
      "step": 12790
    },
    {
      "epoch": 4.85,
      "learning_rate": 0.00017240971155870356,
      "loss": 0.9976,
      "step": 12800
    },
    {
      "epoch": 4.85,
      "learning_rate": 0.000172368677355281,
      "loss": 0.9905,
      "step": 12810
    },
    {
      "epoch": 4.85,
      "learning_rate": 0.00017232761755105625,
      "loss": 0.9855,
      "step": 12820
    },
    {
      "epoch": 4.86,
      "learning_rate": 0.0001722865321605544,
      "loss": 0.9589,
      "step": 12830
    },
    {
      "epoch": 4.86,
      "learning_rate": 0.00017224542119830967,
      "loss": 0.9944,
      "step": 12840
    },
    {
      "epoch": 4.87,
      "learning_rate": 0.00017220428467886522,
      "loss": 1.0893,
      "step": 12850
    },
    {
      "epoch": 4.87,
      "learning_rate": 0.0001721631226167734,
      "loss": 0.9894,
      "step": 12860
    },
    {
      "epoch": 4.87,
      "learning_rate": 0.00017212193502659542,
      "loss": 1.0064,
      "step": 12870
    },
    {
      "epoch": 4.88,
      "learning_rate": 0.00017208072192290166,
      "loss": 0.9915,
      "step": 12880
    },
    {
      "epoch": 4.88,
      "learning_rate": 0.00017203948332027142,
      "loss": 0.9834,
      "step": 12890
    },
    {
      "epoch": 4.88,
      "learning_rate": 0.00017199821923329314,
      "loss": 1.0218,
      "step": 12900
    },
    {
      "epoch": 4.89,
      "learning_rate": 0.00017195692967656413,
      "loss": 1.0188,
      "step": 12910
    },
    {
      "epoch": 4.89,
      "learning_rate": 0.0001719156146646909,
      "loss": 1.0691,
      "step": 12920
    },
    {
      "epoch": 4.9,
      "learning_rate": 0.00017187427421228875,
      "loss": 1.0425,
      "step": 12930
    },
    {
      "epoch": 4.9,
      "learning_rate": 0.0001718329083339821,
      "loss": 1.0243,
      "step": 12940
    },
    {
      "epoch": 4.9,
      "learning_rate": 0.0001717915170444044,
      "loss": 1.0474,
      "step": 12950
    },
    {
      "epoch": 4.91,
      "learning_rate": 0.00017175010035819802,
      "loss": 0.9874,
      "step": 12960
    },
    {
      "epoch": 4.91,
      "learning_rate": 0.0001717086582900143,
      "loss": 1.0403,
      "step": 12970
    },
    {
      "epoch": 4.91,
      "learning_rate": 0.00017166719085451364,
      "loss": 1.001,
      "step": 12980
    },
    {
      "epoch": 4.92,
      "learning_rate": 0.0001716256980663653,
      "loss": 1.0261,
      "step": 12990
    },
    {
      "epoch": 4.92,
      "learning_rate": 0.00017158417994024764,
      "loss": 0.9898,
      "step": 13000
    },
    {
      "epoch": 4.93,
      "learning_rate": 0.00017154263649084785,
      "loss": 1.0002,
      "step": 13010
    },
    {
      "epoch": 4.93,
      "learning_rate": 0.00017150106773286222,
      "loss": 1.0457,
      "step": 13020
    },
    {
      "epoch": 4.93,
      "learning_rate": 0.00017145947368099588,
      "loss": 1.0308,
      "step": 13030
    },
    {
      "epoch": 4.94,
      "learning_rate": 0.0001714178543499629,
      "loss": 0.9958,
      "step": 13040
    },
    {
      "epoch": 4.94,
      "learning_rate": 0.0001713762097544864,
      "loss": 1.0539,
      "step": 13050
    },
    {
      "epoch": 4.94,
      "learning_rate": 0.00017133453990929835,
      "loss": 0.9911,
      "step": 13060
    },
    {
      "epoch": 4.95,
      "learning_rate": 0.00017129284482913972,
      "loss": 0.9917,
      "step": 13070
    },
    {
      "epoch": 4.95,
      "learning_rate": 0.0001712511245287603,
      "loss": 1.0188,
      "step": 13080
    },
    {
      "epoch": 4.96,
      "learning_rate": 0.00017120937902291892,
      "loss": 1.0793,
      "step": 13090
    },
    {
      "epoch": 4.96,
      "learning_rate": 0.00017116760832638323,
      "loss": 0.9994,
      "step": 13100
    },
    {
      "epoch": 4.96,
      "learning_rate": 0.00017112581245392987,
      "loss": 0.9973,
      "step": 13110
    },
    {
      "epoch": 4.97,
      "learning_rate": 0.00017108399142034433,
      "loss": 0.9497,
      "step": 13120
    },
    {
      "epoch": 4.97,
      "learning_rate": 0.00017104214524042103,
      "loss": 1.0168,
      "step": 13130
    },
    {
      "epoch": 4.97,
      "learning_rate": 0.00017100027392896326,
      "loss": 1.014,
      "step": 13140
    },
    {
      "epoch": 4.98,
      "learning_rate": 0.00017095837750078326,
      "loss": 1.0095,
      "step": 13150
    },
    {
      "epoch": 4.98,
      "learning_rate": 0.00017091645597070207,
      "loss": 0.9877,
      "step": 13160
    },
    {
      "epoch": 4.99,
      "learning_rate": 0.00017087450935354969,
      "loss": 1.013,
      "step": 13170
    },
    {
      "epoch": 4.99,
      "learning_rate": 0.00017083253766416495,
      "loss": 1.0494,
      "step": 13180
    },
    {
      "epoch": 4.99,
      "learning_rate": 0.0001707905409173955,
      "loss": 1.0641,
      "step": 13190
    },
    {
      "epoch": 5.0,
      "learning_rate": 0.00017074851912809798,
      "loss": 1.0613,
      "step": 13200
    },
    {
      "epoch": 5.0,
      "learning_rate": 0.00017070647231113778,
      "loss": 0.9626,
      "step": 13210
    },
    {
      "epoch": 5.01,
      "learning_rate": 0.00017066440048138919,
      "loss": 0.9775,
      "step": 13220
    },
    {
      "epoch": 5.01,
      "learning_rate": 0.00017062230365373537,
      "loss": 0.9403,
      "step": 13230
    },
    {
      "epoch": 5.01,
      "learning_rate": 0.00017058018184306828,
      "loss": 1.0163,
      "step": 13240
    },
    {
      "epoch": 5.02,
      "learning_rate": 0.0001705380350642887,
      "loss": 0.9484,
      "step": 13250
    },
    {
      "epoch": 5.02,
      "learning_rate": 0.00017049586333230636,
      "loss": 1.024,
      "step": 13260
    },
    {
      "epoch": 5.02,
      "learning_rate": 0.00017045366666203963,
      "loss": 1.0292,
      "step": 13270
    },
    {
      "epoch": 5.03,
      "learning_rate": 0.0001704114450684159,
      "loss": 1.0122,
      "step": 13280
    },
    {
      "epoch": 5.03,
      "learning_rate": 0.0001703691985663712,
      "loss": 0.9934,
      "step": 13290
    },
    {
      "epoch": 5.04,
      "learning_rate": 0.0001703269271708505,
      "loss": 1.0197,
      "step": 13300
    },
    {
      "epoch": 5.04,
      "learning_rate": 0.00017028463089680752,
      "loss": 0.9872,
      "step": 13310
    },
    {
      "epoch": 5.04,
      "learning_rate": 0.00017024230975920478,
      "loss": 0.9616,
      "step": 13320
    },
    {
      "epoch": 5.05,
      "learning_rate": 0.00017019996377301363,
      "loss": 1.0086,
      "step": 13330
    },
    {
      "epoch": 5.05,
      "learning_rate": 0.00017015759295321416,
      "loss": 1.0047,
      "step": 13340
    },
    {
      "epoch": 5.05,
      "learning_rate": 0.00017011519731479531,
      "loss": 0.9598,
      "step": 13350
    },
    {
      "epoch": 5.06,
      "learning_rate": 0.00017007277687275472,
      "loss": 0.9429,
      "step": 13360
    },
    {
      "epoch": 5.06,
      "learning_rate": 0.00017003033164209884,
      "loss": 1.0025,
      "step": 13370
    },
    {
      "epoch": 5.07,
      "learning_rate": 0.00016998786163784294,
      "loss": 1.0197,
      "step": 13380
    },
    {
      "epoch": 5.07,
      "learning_rate": 0.000169945366875011,
      "loss": 0.9789,
      "step": 13390
    },
    {
      "epoch": 5.07,
      "learning_rate": 0.00016990284736863572,
      "loss": 0.9795,
      "step": 13400
    },
    {
      "epoch": 5.08,
      "learning_rate": 0.00016986030313375863,
      "loss": 1.0037,
      "step": 13410
    },
    {
      "epoch": 5.08,
      "learning_rate": 0.00016981773418542998,
      "loss": 0.9811,
      "step": 13420
    },
    {
      "epoch": 5.08,
      "learning_rate": 0.00016977514053870878,
      "loss": 0.98,
      "step": 13430
    },
    {
      "epoch": 5.09,
      "learning_rate": 0.00016973252220866273,
      "loss": 0.9987,
      "step": 13440
    },
    {
      "epoch": 5.09,
      "learning_rate": 0.00016968987921036827,
      "loss": 0.9665,
      "step": 13450
    },
    {
      "epoch": 5.1,
      "learning_rate": 0.00016964721155891065,
      "loss": 0.9649,
      "step": 13460
    },
    {
      "epoch": 5.1,
      "learning_rate": 0.00016960451926938372,
      "loss": 1.0098,
      "step": 13470
    },
    {
      "epoch": 5.1,
      "learning_rate": 0.00016956180235689011,
      "loss": 0.9753,
      "step": 13480
    },
    {
      "epoch": 5.11,
      "learning_rate": 0.0001695190608365412,
      "loss": 0.9987,
      "step": 13490
    },
    {
      "epoch": 5.11,
      "learning_rate": 0.00016947629472345699,
      "loss": 0.9402,
      "step": 13500
    },
    {
      "epoch": 5.12,
      "learning_rate": 0.0001694335040327662,
      "loss": 0.9616,
      "step": 13510
    },
    {
      "epoch": 5.12,
      "learning_rate": 0.0001693906887796063,
      "loss": 0.964,
      "step": 13520
    },
    {
      "epoch": 5.12,
      "learning_rate": 0.00016934784897912342,
      "loss": 1.0279,
      "step": 13530
    },
    {
      "epoch": 5.13,
      "learning_rate": 0.00016930498464647233,
      "loss": 1.0201,
      "step": 13540
    },
    {
      "epoch": 5.13,
      "learning_rate": 0.00016926209579681652,
      "loss": 0.9687,
      "step": 13550
    },
    {
      "epoch": 5.13,
      "learning_rate": 0.00016921918244532818,
      "loss": 0.9862,
      "step": 13560
    },
    {
      "epoch": 5.14,
      "learning_rate": 0.0001691762446071881,
      "loss": 0.9751,
      "step": 13570
    },
    {
      "epoch": 5.14,
      "learning_rate": 0.00016913328229758575,
      "loss": 0.9583,
      "step": 13580
    },
    {
      "epoch": 5.15,
      "learning_rate": 0.00016909029553171934,
      "loss": 1.051,
      "step": 13590
    },
    {
      "epoch": 5.15,
      "learning_rate": 0.0001690472843247956,
      "loss": 0.9768,
      "step": 13600
    },
    {
      "epoch": 5.15,
      "learning_rate": 0.00016900424869203005,
      "loss": 0.982,
      "step": 13610
    },
    {
      "epoch": 5.16,
      "learning_rate": 0.0001689611886486467,
      "loss": 0.9311,
      "step": 13620
    },
    {
      "epoch": 5.16,
      "learning_rate": 0.00016891810420987827,
      "loss": 1.0054,
      "step": 13630
    },
    {
      "epoch": 5.16,
      "learning_rate": 0.00016887499539096617,
      "loss": 0.9666,
      "step": 13640
    },
    {
      "epoch": 5.17,
      "learning_rate": 0.0001688318622071603,
      "loss": 1.0478,
      "step": 13650
    },
    {
      "epoch": 5.17,
      "learning_rate": 0.0001687887046737193,
      "loss": 0.9941,
      "step": 13660
    },
    {
      "epoch": 5.18,
      "learning_rate": 0.00016874552280591034,
      "loss": 0.9657,
      "step": 13670
    },
    {
      "epoch": 5.18,
      "learning_rate": 0.00016870231661900926,
      "loss": 1.0392,
      "step": 13680
    },
    {
      "epoch": 5.18,
      "learning_rate": 0.00016865908612830047,
      "loss": 0.9796,
      "step": 13690
    },
    {
      "epoch": 5.19,
      "learning_rate": 0.00016861583134907698,
      "loss": 0.9513,
      "step": 13700
    },
    {
      "epoch": 5.19,
      "learning_rate": 0.0001685725522966404,
      "loss": 0.9678,
      "step": 13710
    },
    {
      "epoch": 5.19,
      "learning_rate": 0.00016852924898630095,
      "loss": 1.0907,
      "step": 13720
    },
    {
      "epoch": 5.2,
      "learning_rate": 0.0001684859214333774,
      "loss": 0.9908,
      "step": 13730
    },
    {
      "epoch": 5.2,
      "learning_rate": 0.00016844256965319705,
      "loss": 1.0167,
      "step": 13740
    },
    {
      "epoch": 5.21,
      "learning_rate": 0.00016839919366109585,
      "loss": 0.9716,
      "step": 13750
    },
    {
      "epoch": 5.21,
      "learning_rate": 0.00016835579347241827,
      "loss": 0.9906,
      "step": 13760
    },
    {
      "epoch": 5.21,
      "learning_rate": 0.00016831236910251743,
      "loss": 0.9866,
      "step": 13770
    },
    {
      "epoch": 5.22,
      "learning_rate": 0.00016826892056675483,
      "loss": 0.9767,
      "step": 13780
    },
    {
      "epoch": 5.22,
      "learning_rate": 0.00016822544788050068,
      "loss": 1.0521,
      "step": 13790
    },
    {
      "epoch": 5.22,
      "learning_rate": 0.00016818195105913362,
      "loss": 1.0124,
      "step": 13800
    },
    {
      "epoch": 5.23,
      "learning_rate": 0.000168138430118041,
      "loss": 0.9427,
      "step": 13810
    },
    {
      "epoch": 5.23,
      "learning_rate": 0.00016809488507261845,
      "loss": 1.003,
      "step": 13820
    },
    {
      "epoch": 5.24,
      "learning_rate": 0.0001680513159382703,
      "loss": 0.9645,
      "step": 13830
    },
    {
      "epoch": 5.24,
      "learning_rate": 0.00016800772273040942,
      "loss": 1.0051,
      "step": 13840
    },
    {
      "epoch": 5.24,
      "learning_rate": 0.00016796410546445704,
      "loss": 0.9876,
      "step": 13850
    },
    {
      "epoch": 5.25,
      "learning_rate": 0.00016792046415584308,
      "loss": 0.9581,
      "step": 13860
    },
    {
      "epoch": 5.25,
      "learning_rate": 0.00016787679882000585,
      "loss": 1.0129,
      "step": 13870
    },
    {
      "epoch": 5.26,
      "learning_rate": 0.0001678331094723922,
      "loss": 1.0144,
      "step": 13880
    },
    {
      "epoch": 5.26,
      "learning_rate": 0.00016778939612845746,
      "loss": 1.0326,
      "step": 13890
    },
    {
      "epoch": 5.26,
      "learning_rate": 0.00016774565880366544,
      "loss": 1.0232,
      "step": 13900
    },
    {
      "epoch": 5.27,
      "learning_rate": 0.00016770189751348847,
      "loss": 0.9873,
      "step": 13910
    },
    {
      "epoch": 5.27,
      "learning_rate": 0.00016765811227340737,
      "loss": 0.9938,
      "step": 13920
    },
    {
      "epoch": 5.27,
      "learning_rate": 0.00016761430309891132,
      "loss": 0.974,
      "step": 13930
    },
    {
      "epoch": 5.28,
      "learning_rate": 0.00016757047000549817,
      "loss": 1.0041,
      "step": 13940
    },
    {
      "epoch": 5.28,
      "learning_rate": 0.000167526613008674,
      "loss": 0.9911,
      "step": 13950
    },
    {
      "epoch": 5.29,
      "learning_rate": 0.00016748273212395347,
      "loss": 1.0017,
      "step": 13960
    },
    {
      "epoch": 5.29,
      "learning_rate": 0.00016743882736685968,
      "loss": 0.9894,
      "step": 13970
    },
    {
      "epoch": 5.29,
      "learning_rate": 0.00016739489875292423,
      "loss": 0.9745,
      "step": 13980
    },
    {
      "epoch": 5.3,
      "learning_rate": 0.00016735094629768705,
      "loss": 0.9189,
      "step": 13990
    },
    {
      "epoch": 5.3,
      "learning_rate": 0.00016730697001669648,
      "loss": 0.9756,
      "step": 14000
    },
    {
      "epoch": 5.3,
      "learning_rate": 0.0001672629699255095,
      "loss": 0.989,
      "step": 14010
    },
    {
      "epoch": 5.31,
      "learning_rate": 0.00016721894603969134,
      "loss": 1.0063,
      "step": 14020
    },
    {
      "epoch": 5.31,
      "learning_rate": 0.00016717489837481562,
      "loss": 0.9928,
      "step": 14030
    },
    {
      "epoch": 5.32,
      "learning_rate": 0.00016713082694646446,
      "loss": 0.977,
      "step": 14040
    },
    {
      "epoch": 5.32,
      "learning_rate": 0.0001670867317702284,
      "loss": 0.9477,
      "step": 14050
    },
    {
      "epoch": 5.32,
      "learning_rate": 0.0001670426128617063,
      "loss": 0.9693,
      "step": 14060
    },
    {
      "epoch": 5.33,
      "learning_rate": 0.00016699847023650543,
      "loss": 1.0233,
      "step": 14070
    },
    {
      "epoch": 5.33,
      "learning_rate": 0.00016695430391024156,
      "loss": 0.9974,
      "step": 14080
    },
    {
      "epoch": 5.33,
      "learning_rate": 0.0001669101138985387,
      "loss": 1.0041,
      "step": 14090
    },
    {
      "epoch": 5.34,
      "learning_rate": 0.00016686590021702932,
      "loss": 1.0075,
      "step": 14100
    },
    {
      "epoch": 5.34,
      "learning_rate": 0.00016682166288135424,
      "loss": 0.9866,
      "step": 14110
    },
    {
      "epoch": 5.35,
      "learning_rate": 0.00016677740190716267,
      "loss": 0.9923,
      "step": 14120
    },
    {
      "epoch": 5.35,
      "learning_rate": 0.0001667331173101121,
      "loss": 1.0594,
      "step": 14130
    },
    {
      "epoch": 5.35,
      "learning_rate": 0.00016668880910586853,
      "loss": 1.0566,
      "step": 14140
    },
    {
      "epoch": 5.36,
      "learning_rate": 0.00016664447731010618,
      "loss": 0.9918,
      "step": 14150
    },
    {
      "epoch": 5.36,
      "learning_rate": 0.00016660012193850764,
      "loss": 0.9934,
      "step": 14160
    },
    {
      "epoch": 5.36,
      "learning_rate": 0.0001665557430067639,
      "loss": 1.0198,
      "step": 14170
    },
    {
      "epoch": 5.37,
      "learning_rate": 0.0001665113405305742,
      "loss": 1.0277,
      "step": 14180
    },
    {
      "epoch": 5.37,
      "learning_rate": 0.00016646691452564612,
      "loss": 1.0772,
      "step": 14190
    },
    {
      "epoch": 5.38,
      "learning_rate": 0.00016642246500769568,
      "loss": 1.0115,
      "step": 14200
    },
    {
      "epoch": 5.38,
      "learning_rate": 0.00016637799199244709,
      "loss": 0.9614,
      "step": 14210
    },
    {
      "epoch": 5.38,
      "learning_rate": 0.0001663334954956329,
      "loss": 1.0002,
      "step": 14220
    },
    {
      "epoch": 5.39,
      "learning_rate": 0.00016628897553299402,
      "loss": 0.9289,
      "step": 14230
    },
    {
      "epoch": 5.39,
      "learning_rate": 0.00016624443212027957,
      "loss": 0.9692,
      "step": 14240
    },
    {
      "epoch": 5.4,
      "learning_rate": 0.00016619986527324705,
      "loss": 0.9857,
      "step": 14250
    },
    {
      "epoch": 5.4,
      "learning_rate": 0.00016615527500766223,
      "loss": 0.9549,
      "step": 14260
    },
    {
      "epoch": 5.4,
      "learning_rate": 0.00016611066133929913,
      "loss": 0.9789,
      "step": 14270
    },
    {
      "epoch": 5.41,
      "learning_rate": 0.00016606602428394007,
      "loss": 0.9648,
      "step": 14280
    },
    {
      "epoch": 5.41,
      "learning_rate": 0.00016602136385737568,
      "loss": 0.927,
      "step": 14290
    },
    {
      "epoch": 5.41,
      "learning_rate": 0.00016597668007540476,
      "loss": 0.9668,
      "step": 14300
    },
    {
      "epoch": 5.42,
      "learning_rate": 0.0001659319729538345,
      "loss": 1.0075,
      "step": 14310
    },
    {
      "epoch": 5.42,
      "learning_rate": 0.0001658872425084802,
      "loss": 0.9862,
      "step": 14320
    },
    {
      "epoch": 5.43,
      "learning_rate": 0.00016584248875516557,
      "loss": 0.975,
      "step": 14330
    },
    {
      "epoch": 5.43,
      "learning_rate": 0.00016579771170972246,
      "loss": 0.9989,
      "step": 14340
    },
    {
      "epoch": 5.43,
      "learning_rate": 0.00016575291138799098,
      "loss": 0.9899,
      "step": 14350
    },
    {
      "epoch": 5.44,
      "learning_rate": 0.00016570808780581948,
      "loss": 0.985,
      "step": 14360
    },
    {
      "epoch": 5.44,
      "learning_rate": 0.00016566324097906453,
      "loss": 0.9733,
      "step": 14370
    },
    {
      "epoch": 5.44,
      "learning_rate": 0.00016561837092359097,
      "loss": 1.005,
      "step": 14380
    },
    {
      "epoch": 5.45,
      "learning_rate": 0.00016557347765527175,
      "loss": 1.0094,
      "step": 14390
    },
    {
      "epoch": 5.45,
      "learning_rate": 0.00016552856118998822,
      "loss": 1.0302,
      "step": 14400
    },
    {
      "epoch": 5.46,
      "learning_rate": 0.00016548362154362968,
      "loss": 1.0103,
      "step": 14410
    },
    {
      "epoch": 5.46,
      "learning_rate": 0.00016543865873209384,
      "loss": 0.9962,
      "step": 14420
    },
    {
      "epoch": 5.46,
      "learning_rate": 0.00016539367277128655,
      "loss": 0.982,
      "step": 14430
    },
    {
      "epoch": 5.47,
      "learning_rate": 0.00016534866367712175,
      "loss": 0.9851,
      "step": 14440
    },
    {
      "epoch": 5.47,
      "learning_rate": 0.00016530363146552177,
      "loss": 1.0052,
      "step": 14450
    },
    {
      "epoch": 5.47,
      "learning_rate": 0.00016525857615241687,
      "loss": 0.9798,
      "step": 14460
    },
    {
      "epoch": 5.48,
      "learning_rate": 0.00016521349775374566,
      "loss": 0.9629,
      "step": 14470
    },
    {
      "epoch": 5.48,
      "learning_rate": 0.00016516839628545488,
      "loss": 0.9705,
      "step": 14480
    },
    {
      "epoch": 5.49,
      "learning_rate": 0.00016512327176349936,
      "loss": 1.0105,
      "step": 14490
    },
    {
      "epoch": 5.49,
      "learning_rate": 0.0001650781242038422,
      "loss": 1.0243,
      "step": 14500
    },
    {
      "epoch": 5.49,
      "learning_rate": 0.00016503295362245454,
      "loss": 1.0128,
      "step": 14510
    },
    {
      "epoch": 5.5,
      "learning_rate": 0.00016498776003531575,
      "loss": 1.0322,
      "step": 14520
    },
    {
      "epoch": 5.5,
      "learning_rate": 0.00016494254345841326,
      "loss": 0.9991,
      "step": 14530
    },
    {
      "epoch": 5.5,
      "learning_rate": 0.0001648973039077427,
      "loss": 0.9842,
      "step": 14540
    },
    {
      "epoch": 5.51,
      "learning_rate": 0.0001648520413993078,
      "loss": 0.9956,
      "step": 14550
    },
    {
      "epoch": 5.51,
      "learning_rate": 0.0001648067559491204,
      "loss": 0.9952,
      "step": 14560
    },
    {
      "epoch": 5.52,
      "learning_rate": 0.00016476144757320046,
      "loss": 1.0136,
      "step": 14570
    },
    {
      "epoch": 5.52,
      "learning_rate": 0.00016471611628757606,
      "loss": 0.9814,
      "step": 14580
    },
    {
      "epoch": 5.52,
      "learning_rate": 0.00016467076210828342,
      "loss": 1.0285,
      "step": 14590
    },
    {
      "epoch": 5.53,
      "learning_rate": 0.00016462538505136677,
      "loss": 1.0099,
      "step": 14600
    },
    {
      "epoch": 5.53,
      "learning_rate": 0.00016457998513287852,
      "loss": 1.0132,
      "step": 14610
    },
    {
      "epoch": 5.54,
      "learning_rate": 0.00016453456236887912,
      "loss": 1.0067,
      "step": 14620
    },
    {
      "epoch": 5.54,
      "learning_rate": 0.00016448911677543712,
      "loss": 0.9959,
      "step": 14630
    },
    {
      "epoch": 5.54,
      "learning_rate": 0.00016444364836862911,
      "loss": 1.0343,
      "step": 14640
    },
    {
      "epoch": 5.55,
      "learning_rate": 0.0001643981571645398,
      "loss": 1.0359,
      "step": 14650
    },
    {
      "epoch": 5.55,
      "learning_rate": 0.00016435264317926195,
      "loss": 0.9466,
      "step": 14660
    },
    {
      "epoch": 5.55,
      "learning_rate": 0.00016430710642889636,
      "loss": 1.0327,
      "step": 14670
    },
    {
      "epoch": 5.56,
      "learning_rate": 0.00016426154692955188,
      "loss": 0.9716,
      "step": 14680
    },
    {
      "epoch": 5.56,
      "learning_rate": 0.00016421596469734547,
      "loss": 1.0465,
      "step": 14690
    },
    {
      "epoch": 5.57,
      "learning_rate": 0.00016417035974840207,
      "loss": 1.0495,
      "step": 14700
    },
    {
      "epoch": 5.57,
      "learning_rate": 0.00016412473209885463,
      "loss": 0.9973,
      "step": 14710
    },
    {
      "epoch": 5.57,
      "learning_rate": 0.00016407908176484424,
      "loss": 0.9747,
      "step": 14720
    },
    {
      "epoch": 5.58,
      "learning_rate": 0.00016403340876251988,
      "loss": 0.998,
      "step": 14730
    },
    {
      "epoch": 5.58,
      "learning_rate": 0.0001639877131080387,
      "loss": 1.0168,
      "step": 14740
    },
    {
      "epoch": 5.58,
      "learning_rate": 0.00016394199481756567,
      "loss": 0.9645,
      "step": 14750
    },
    {
      "epoch": 5.59,
      "learning_rate": 0.00016389625390727397,
      "loss": 0.9521,
      "step": 14760
    },
    {
      "epoch": 5.59,
      "learning_rate": 0.0001638504903933446,
      "loss": 1.0275,
      "step": 14770
    },
    {
      "epoch": 5.6,
      "learning_rate": 0.00016380470429196674,
      "loss": 0.9705,
      "step": 14780
    },
    {
      "epoch": 5.6,
      "learning_rate": 0.00016375889561933744,
      "loss": 0.9679,
      "step": 14790
    },
    {
      "epoch": 5.6,
      "learning_rate": 0.00016371306439166172,
      "loss": 0.998,
      "step": 14800
    },
    {
      "epoch": 5.61,
      "learning_rate": 0.00016366721062515262,
      "loss": 0.9655,
      "step": 14810
    },
    {
      "epoch": 5.61,
      "learning_rate": 0.00016362133433603122,
      "loss": 0.9937,
      "step": 14820
    },
    {
      "epoch": 5.61,
      "learning_rate": 0.00016357543554052645,
      "loss": 0.998,
      "step": 14830
    },
    {
      "epoch": 5.62,
      "learning_rate": 0.00016352951425487524,
      "loss": 1.0169,
      "step": 14840
    },
    {
      "epoch": 5.62,
      "learning_rate": 0.00016348357049532247,
      "loss": 1.0283,
      "step": 14850
    },
    {
      "epoch": 5.63,
      "learning_rate": 0.00016343760427812106,
      "loss": 0.944,
      "step": 14860
    },
    {
      "epoch": 5.63,
      "learning_rate": 0.0001633916156195318,
      "loss": 0.9743,
      "step": 14870
    },
    {
      "epoch": 5.63,
      "learning_rate": 0.0001633456045358233,
      "loss": 0.9594,
      "step": 14880
    },
    {
      "epoch": 5.64,
      "learning_rate": 0.00016329957104327237,
      "loss": 0.9865,
      "step": 14890
    },
    {
      "epoch": 5.64,
      "learning_rate": 0.00016325351515816353,
      "loss": 0.9432,
      "step": 14900
    },
    {
      "epoch": 5.65,
      "learning_rate": 0.0001632074368967893,
      "loss": 1.0025,
      "step": 14910
    },
    {
      "epoch": 5.65,
      "learning_rate": 0.0001631613362754501,
      "loss": 0.9748,
      "step": 14920
    },
    {
      "epoch": 5.65,
      "learning_rate": 0.00016311521331045426,
      "loss": 0.9904,
      "step": 14930
    },
    {
      "epoch": 5.66,
      "learning_rate": 0.0001630690680181181,
      "loss": 1.0135,
      "step": 14940
    },
    {
      "epoch": 5.66,
      "learning_rate": 0.0001630229004147657,
      "loss": 0.9957,
      "step": 14950
    },
    {
      "epoch": 5.66,
      "learning_rate": 0.00016297671051672904,
      "loss": 0.9686,
      "step": 14960
    },
    {
      "epoch": 5.67,
      "learning_rate": 0.00016293049834034817,
      "loss": 0.9752,
      "step": 14970
    },
    {
      "epoch": 5.67,
      "learning_rate": 0.00016288426390197075,
      "loss": 1.0465,
      "step": 14980
    },
    {
      "epoch": 5.68,
      "learning_rate": 0.00016283800721795258,
      "loss": 0.9882,
      "step": 14990
    },
    {
      "epoch": 5.68,
      "learning_rate": 0.0001627917283046571,
      "loss": 0.9785,
      "step": 15000
    },
    {
      "epoch": 5.68,
      "learning_rate": 0.00016274542717845586,
      "loss": 0.9449,
      "step": 15010
    },
    {
      "epoch": 5.69,
      "learning_rate": 0.00016269910385572795,
      "loss": 0.9923,
      "step": 15020
    },
    {
      "epoch": 5.69,
      "learning_rate": 0.00016265275835286065,
      "loss": 1.0572,
      "step": 15030
    },
    {
      "epoch": 5.69,
      "learning_rate": 0.00016260639068624882,
      "loss": 0.9555,
      "step": 15040
    },
    {
      "epoch": 5.7,
      "learning_rate": 0.00016256000087229536,
      "loss": 0.9875,
      "step": 15050
    },
    {
      "epoch": 5.7,
      "learning_rate": 0.00016251823111732328,
      "loss": 1.0596,
      "step": 15060
    },
    {
      "epoch": 5.71,
      "learning_rate": 0.00016247179926863836,
      "loss": 0.9516,
      "step": 15070
    },
    {
      "epoch": 5.71,
      "learning_rate": 0.0001624253453202242,
      "loss": 1.042,
      "step": 15080
    },
    {
      "epoch": 5.71,
      "learning_rate": 0.0001623788692885141,
      "loss": 0.9401,
      "step": 15090
    },
    {
      "epoch": 5.72,
      "learning_rate": 0.0001623323711899492,
      "loss": 0.9672,
      "step": 15100
    },
    {
      "epoch": 5.72,
      "learning_rate": 0.00016228585104097852,
      "loss": 1.0223,
      "step": 15110
    },
    {
      "epoch": 5.72,
      "learning_rate": 0.00016223930885805868,
      "loss": 1.091,
      "step": 15120
    },
    {
      "epoch": 5.73,
      "learning_rate": 0.00016219274465765433,
      "loss": 1.0107,
      "step": 15130
    },
    {
      "epoch": 5.73,
      "learning_rate": 0.00016214615845623777,
      "loss": 0.981,
      "step": 15140
    },
    {
      "epoch": 5.74,
      "learning_rate": 0.0001620995502702891,
      "loss": 0.9769,
      "step": 15150
    },
    {
      "epoch": 5.74,
      "learning_rate": 0.00016205292011629624,
      "loss": 1.0661,
      "step": 15160
    },
    {
      "epoch": 5.74,
      "learning_rate": 0.0001620062680107548,
      "loss": 1.0686,
      "step": 15170
    },
    {
      "epoch": 5.75,
      "learning_rate": 0.00016195959397016826,
      "loss": 1.0155,
      "step": 15180
    },
    {
      "epoch": 5.75,
      "learning_rate": 0.0001619128980110478,
      "loss": 1.037,
      "step": 15190
    },
    {
      "epoch": 5.75,
      "learning_rate": 0.00016186618014991236,
      "loss": 1.0599,
      "step": 15200
    },
    {
      "epoch": 5.76,
      "learning_rate": 0.00016181944040328863,
      "loss": 1.0041,
      "step": 15210
    },
    {
      "epoch": 5.76,
      "learning_rate": 0.000161772678787711,
      "loss": 1.0101,
      "step": 15220
    },
    {
      "epoch": 5.77,
      "learning_rate": 0.00016172589531972172,
      "loss": 0.9735,
      "step": 15230
    },
    {
      "epoch": 5.77,
      "learning_rate": 0.00016167909001587065,
      "loss": 1.016,
      "step": 15240
    },
    {
      "epoch": 5.77,
      "learning_rate": 0.00016163226289271537,
      "loss": 0.9968,
      "step": 15250
    },
    {
      "epoch": 5.78,
      "learning_rate": 0.00016158541396682133,
      "loss": 0.9822,
      "step": 15260
    },
    {
      "epoch": 5.78,
      "learning_rate": 0.00016153854325476146,
      "loss": 1.0105,
      "step": 15270
    },
    {
      "epoch": 5.79,
      "learning_rate": 0.00016149165077311662,
      "loss": 0.9817,
      "step": 15280
    },
    {
      "epoch": 5.79,
      "learning_rate": 0.0001614447365384752,
      "loss": 1.0228,
      "step": 15290
    },
    {
      "epoch": 5.79,
      "learning_rate": 0.00016139780056743342,
      "loss": 1.0424,
      "step": 15300
    },
    {
      "epoch": 5.8,
      "learning_rate": 0.00016135084287659506,
      "loss": 0.9484,
      "step": 15310
    },
    {
      "epoch": 5.8,
      "learning_rate": 0.00016130386348257175,
      "loss": 1.0244,
      "step": 15320
    },
    {
      "epoch": 5.8,
      "learning_rate": 0.00016125686240198262,
      "loss": 0.9695,
      "step": 15330
    },
    {
      "epoch": 5.81,
      "learning_rate": 0.00016120983965145453,
      "loss": 1.0166,
      "step": 15340
    },
    {
      "epoch": 5.81,
      "learning_rate": 0.0001611627952476221,
      "loss": 1.0343,
      "step": 15350
    },
    {
      "epoch": 5.82,
      "learning_rate": 0.00016111572920712752,
      "loss": 1.0641,
      "step": 15360
    },
    {
      "epoch": 5.82,
      "learning_rate": 0.00016106864154662062,
      "loss": 1.002,
      "step": 15370
    },
    {
      "epoch": 5.82,
      "learning_rate": 0.0001610215322827589,
      "loss": 1.0647,
      "step": 15380
    },
    {
      "epoch": 5.83,
      "learning_rate": 0.00016097440143220758,
      "loss": 1.0195,
      "step": 15390
    },
    {
      "epoch": 5.83,
      "learning_rate": 0.00016092724901163935,
      "loss": 1.0073,
      "step": 15400
    },
    {
      "epoch": 5.83,
      "learning_rate": 0.00016088007503773472,
      "loss": 1.0134,
      "step": 15410
    },
    {
      "epoch": 5.84,
      "learning_rate": 0.00016083287952718168,
      "loss": 0.986,
      "step": 15420
    },
    {
      "epoch": 5.84,
      "learning_rate": 0.00016078566249667594,
      "loss": 1.0254,
      "step": 15430
    },
    {
      "epoch": 5.85,
      "learning_rate": 0.00016073842396292068,
      "loss": 1.0739,
      "step": 15440
    },
    {
      "epoch": 5.85,
      "learning_rate": 0.00016069116394262686,
      "loss": 1.0303,
      "step": 15450
    },
    {
      "epoch": 5.85,
      "learning_rate": 0.00016064388245251297,
      "loss": 0.9942,
      "step": 15460
    },
    {
      "epoch": 5.86,
      "learning_rate": 0.00016059657950930504,
      "loss": 0.9908,
      "step": 15470
    },
    {
      "epoch": 5.86,
      "learning_rate": 0.00016054925512973677,
      "loss": 0.9954,
      "step": 15480
    },
    {
      "epoch": 5.86,
      "learning_rate": 0.00016050190933054935,
      "loss": 0.972,
      "step": 15490
    },
    {
      "epoch": 5.87,
      "learning_rate": 0.0001604545421284917,
      "loss": 1.0156,
      "step": 15500
    },
    {
      "epoch": 5.87,
      "learning_rate": 0.00016040715354032016,
      "loss": 0.9958,
      "step": 15510
    },
    {
      "epoch": 5.88,
      "learning_rate": 0.0001603597435827987,
      "loss": 0.9742,
      "step": 15520
    },
    {
      "epoch": 5.88,
      "learning_rate": 0.00016031231227269882,
      "loss": 0.9941,
      "step": 15530
    },
    {
      "epoch": 5.88,
      "learning_rate": 0.00016026485962679967,
      "loss": 0.943,
      "step": 15540
    },
    {
      "epoch": 5.89,
      "learning_rate": 0.00016021738566188777,
      "loss": 1.0162,
      "step": 15550
    },
    {
      "epoch": 5.89,
      "learning_rate": 0.0001601698903947574,
      "loss": 0.9523,
      "step": 15560
    },
    {
      "epoch": 5.89,
      "learning_rate": 0.00016012237384221018,
      "loss": 0.9657,
      "step": 15570
    },
    {
      "epoch": 5.9,
      "learning_rate": 0.00016007483602105537,
      "loss": 1.0206,
      "step": 15580
    },
    {
      "epoch": 5.9,
      "learning_rate": 0.00016002727694810971,
      "loss": 0.9773,
      "step": 15590
    },
    {
      "epoch": 5.91,
      "learning_rate": 0.00015997969664019752,
      "loss": 1.0119,
      "step": 15600
    },
    {
      "epoch": 5.91,
      "learning_rate": 0.00015993209511415052,
      "loss": 1.0202,
      "step": 15610
    },
    {
      "epoch": 5.91,
      "learning_rate": 0.00015988447238680803,
      "loss": 1.0445,
      "step": 15620
    },
    {
      "epoch": 5.92,
      "learning_rate": 0.00015983682847501687,
      "loss": 1.044,
      "step": 15630
    },
    {
      "epoch": 5.92,
      "learning_rate": 0.0001597891633956313,
      "loss": 0.9844,
      "step": 15640
    },
    {
      "epoch": 5.93,
      "learning_rate": 0.00015974147716551308,
      "loss": 1.0278,
      "step": 15650
    },
    {
      "epoch": 5.93,
      "learning_rate": 0.00015969376980153147,
      "loss": 0.9806,
      "step": 15660
    },
    {
      "epoch": 5.93,
      "learning_rate": 0.00015964604132056323,
      "loss": 0.9945,
      "step": 15670
    },
    {
      "epoch": 5.94,
      "learning_rate": 0.00015959829173949253,
      "loss": 0.9692,
      "step": 15680
    },
    {
      "epoch": 5.94,
      "learning_rate": 0.00015955052107521106,
      "loss": 0.976,
      "step": 15690
    },
    {
      "epoch": 5.94,
      "learning_rate": 0.00015950272934461794,
      "loss": 0.9697,
      "step": 15700
    },
    {
      "epoch": 5.95,
      "learning_rate": 0.00015945491656461976,
      "loss": 1.0487,
      "step": 15710
    },
    {
      "epoch": 5.95,
      "learning_rate": 0.0001594070827521305,
      "loss": 1.0193,
      "step": 15720
    },
    {
      "epoch": 5.96,
      "learning_rate": 0.00015935922792407166,
      "loss": 0.9773,
      "step": 15730
    },
    {
      "epoch": 5.96,
      "learning_rate": 0.00015931135209737213,
      "loss": 1.0018,
      "step": 15740
    },
    {
      "epoch": 5.96,
      "learning_rate": 0.00015926345528896824,
      "loss": 1.0442,
      "step": 15750
    },
    {
      "epoch": 5.97,
      "learning_rate": 0.00015921553751580372,
      "loss": 0.9977,
      "step": 15760
    },
    {
      "epoch": 5.97,
      "learning_rate": 0.0001591675987948298,
      "loss": 1.0316,
      "step": 15770
    },
    {
      "epoch": 5.97,
      "learning_rate": 0.00015911963914300495,
      "loss": 1.0153,
      "step": 15780
    },
    {
      "epoch": 5.98,
      "learning_rate": 0.00015907165857729523,
      "loss": 1.0397,
      "step": 15790
    },
    {
      "epoch": 5.98,
      "learning_rate": 0.000159023657114674,
      "loss": 1.0018,
      "step": 15800
    },
    {
      "epoch": 5.99,
      "learning_rate": 0.00015897563477212202,
      "loss": 0.9954,
      "step": 15810
    },
    {
      "epoch": 5.99,
      "learning_rate": 0.00015892759156662748,
      "loss": 1.0414,
      "step": 15820
    },
    {
      "epoch": 5.99,
      "learning_rate": 0.00015887952751518584,
      "loss": 1.0142,
      "step": 15830
    },
    {
      "epoch": 6.0,
      "learning_rate": 0.0001588314426348001,
      "loss": 0.9848,
      "step": 15840
    },
    {
      "epoch": 6.0,
      "learning_rate": 0.00015878333694248052,
      "loss": 0.9864,
      "step": 15850
    },
    {
      "epoch": 6.0,
      "learning_rate": 0.00015873521045524472,
      "loss": 1.0187,
      "step": 15860
    },
    {
      "epoch": 6.01,
      "learning_rate": 0.0001586870631901177,
      "loss": 0.9042,
      "step": 15870
    },
    {
      "epoch": 6.01,
      "learning_rate": 0.00015863889516413185,
      "loss": 0.9314,
      "step": 15880
    },
    {
      "epoch": 6.02,
      "learning_rate": 0.00015859070639432678,
      "loss": 0.996,
      "step": 15890
    },
    {
      "epoch": 6.02,
      "learning_rate": 0.00015854249689774963,
      "loss": 0.9569,
      "step": 15900
    },
    {
      "epoch": 6.02,
      "learning_rate": 0.00015849426669145466,
      "loss": 0.9878,
      "step": 15910
    },
    {
      "epoch": 6.03,
      "learning_rate": 0.0001584460157925036,
      "loss": 0.996,
      "step": 15920
    },
    {
      "epoch": 6.03,
      "learning_rate": 0.00015839774421796553,
      "loss": 0.9916,
      "step": 15930
    },
    {
      "epoch": 6.04,
      "learning_rate": 0.00015834945198491668,
      "loss": 0.9821,
      "step": 15940
    },
    {
      "epoch": 6.04,
      "learning_rate": 0.0001583011391104407,
      "loss": 1.0117,
      "step": 15950
    },
    {
      "epoch": 6.04,
      "learning_rate": 0.0001582528056116286,
      "loss": 0.9558,
      "step": 15960
    },
    {
      "epoch": 6.05,
      "learning_rate": 0.0001582044515055785,
      "loss": 0.9713,
      "step": 15970
    },
    {
      "epoch": 6.05,
      "learning_rate": 0.00015815607680939598,
      "loss": 0.9682,
      "step": 15980
    },
    {
      "epoch": 6.05,
      "learning_rate": 0.00015810768154019385,
      "loss": 1.0012,
      "step": 15990
    },
    {
      "epoch": 6.06,
      "learning_rate": 0.00015805926571509215,
      "loss": 0.9483,
      "step": 16000
    },
    {
      "epoch": 6.06,
      "learning_rate": 0.0001580108293512183,
      "loss": 0.9638,
      "step": 16010
    },
    {
      "epoch": 6.07,
      "learning_rate": 0.00015796237246570687,
      "loss": 1.006,
      "step": 16020
    },
    {
      "epoch": 6.07,
      "learning_rate": 0.00015791389507569976,
      "loss": 0.9587,
      "step": 16030
    },
    {
      "epoch": 6.07,
      "learning_rate": 0.0001578653971983461,
      "loss": 1.0481,
      "step": 16040
    },
    {
      "epoch": 6.08,
      "learning_rate": 0.00015781687885080224,
      "loss": 1.0113,
      "step": 16050
    },
    {
      "epoch": 6.08,
      "learning_rate": 0.00015776834005023184,
      "loss": 0.9864,
      "step": 16060
    },
    {
      "epoch": 6.08,
      "learning_rate": 0.0001577197808138058,
      "loss": 0.9445,
      "step": 16070
    },
    {
      "epoch": 6.09,
      "learning_rate": 0.00015767120115870204,
      "loss": 0.9792,
      "step": 16080
    },
    {
      "epoch": 6.09,
      "learning_rate": 0.00015762260110210608,
      "loss": 0.9587,
      "step": 16090
    },
    {
      "epoch": 6.1,
      "learning_rate": 0.00015757398066121032,
      "loss": 0.9861,
      "step": 16100
    },
    {
      "epoch": 6.1,
      "learning_rate": 0.00015752533985321452,
      "loss": 0.9605,
      "step": 16110
    },
    {
      "epoch": 6.1,
      "learning_rate": 0.00015747667869532564,
      "loss": 0.9347,
      "step": 16120
    },
    {
      "epoch": 6.11,
      "learning_rate": 0.00015742799720475778,
      "loss": 0.9761,
      "step": 16130
    },
    {
      "epoch": 6.11,
      "learning_rate": 0.00015737929539873236,
      "loss": 0.9393,
      "step": 16140
    },
    {
      "epoch": 6.11,
      "learning_rate": 0.0001573305732944778,
      "loss": 1.013,
      "step": 16150
    },
    {
      "epoch": 6.12,
      "learning_rate": 0.00015728183090922988,
      "loss": 0.9539,
      "step": 16160
    },
    {
      "epoch": 6.12,
      "learning_rate": 0.00015723306826023143,
      "loss": 0.9564,
      "step": 16170
    },
    {
      "epoch": 6.13,
      "learning_rate": 0.00015718428536473254,
      "loss": 0.9609,
      "step": 16180
    },
    {
      "epoch": 6.13,
      "learning_rate": 0.00015713548223999035,
      "loss": 0.9444,
      "step": 16190
    },
    {
      "epoch": 6.13,
      "learning_rate": 0.00015708665890326931,
      "loss": 0.9831,
      "step": 16200
    },
    {
      "epoch": 6.14,
      "learning_rate": 0.00015703781537184083,
      "loss": 0.9756,
      "step": 16210
    },
    {
      "epoch": 6.14,
      "learning_rate": 0.00015698895166298363,
      "loss": 0.9338,
      "step": 16220
    },
    {
      "epoch": 6.14,
      "learning_rate": 0.00015694006779398353,
      "loss": 0.9678,
      "step": 16230
    },
    {
      "epoch": 6.15,
      "learning_rate": 0.00015689116378213343,
      "loss": 1.0032,
      "step": 16240
    },
    {
      "epoch": 6.15,
      "learning_rate": 0.00015684223964473337,
      "loss": 1.011,
      "step": 16250
    },
    {
      "epoch": 6.16,
      "learning_rate": 0.00015679329539909048,
      "loss": 0.949,
      "step": 16260
    },
    {
      "epoch": 6.16,
      "learning_rate": 0.00015674433106251914,
      "loss": 1.0302,
      "step": 16270
    },
    {
      "epoch": 6.16,
      "learning_rate": 0.00015669534665234075,
      "loss": 0.9542,
      "step": 16280
    },
    {
      "epoch": 6.17,
      "learning_rate": 0.00015664634218588366,
      "loss": 0.9995,
      "step": 16290
    },
    {
      "epoch": 6.17,
      "learning_rate": 0.00015659731768048358,
      "loss": 0.9132,
      "step": 16300
    },
    {
      "epoch": 6.18,
      "learning_rate": 0.00015654827315348318,
      "loss": 1.0421,
      "step": 16310
    },
    {
      "epoch": 6.18,
      "learning_rate": 0.0001564992086222322,
      "loss": 0.9294,
      "step": 16320
    },
    {
      "epoch": 6.18,
      "learning_rate": 0.00015645012410408747,
      "loss": 0.9887,
      "step": 16330
    },
    {
      "epoch": 6.19,
      "learning_rate": 0.0001564010196164129,
      "loss": 0.9547,
      "step": 16340
    },
    {
      "epoch": 6.19,
      "learning_rate": 0.00015635189517657948,
      "loss": 0.9856,
      "step": 16350
    },
    {
      "epoch": 6.19,
      "learning_rate": 0.0001563027508019652,
      "loss": 0.9922,
      "step": 16360
    },
    {
      "epoch": 6.2,
      "learning_rate": 0.0001562535865099552,
      "loss": 1.0526,
      "step": 16370
    },
    {
      "epoch": 6.2,
      "learning_rate": 0.0001562044023179416,
      "loss": 1.0311,
      "step": 16380
    },
    {
      "epoch": 6.21,
      "learning_rate": 0.0001561551982433235,
      "loss": 0.9757,
      "step": 16390
    },
    {
      "epoch": 6.21,
      "learning_rate": 0.00015610597430350717,
      "loss": 0.969,
      "step": 16400
    },
    {
      "epoch": 6.21,
      "learning_rate": 0.0001560567305159058,
      "loss": 0.9763,
      "step": 16410
    },
    {
      "epoch": 6.22,
      "learning_rate": 0.00015600746689793972,
      "loss": 0.9594,
      "step": 16420
    },
    {
      "epoch": 6.22,
      "learning_rate": 0.00015595818346703606,
      "loss": 0.9749,
      "step": 16430
    },
    {
      "epoch": 6.22,
      "learning_rate": 0.00015590888024062918,
      "loss": 0.9559,
      "step": 16440
    },
    {
      "epoch": 6.23,
      "learning_rate": 0.00015585955723616034,
      "loss": 0.9823,
      "step": 16450
    },
    {
      "epoch": 6.23,
      "learning_rate": 0.00015581021447107785,
      "loss": 1.0466,
      "step": 16460
    },
    {
      "epoch": 6.24,
      "learning_rate": 0.00015576085196283693,
      "loss": 1.0384,
      "step": 16470
    },
    {
      "epoch": 6.24,
      "learning_rate": 0.00015571146972889982,
      "loss": 1.0216,
      "step": 16480
    },
    {
      "epoch": 6.24,
      "learning_rate": 0.0001556620677867358,
      "loss": 0.9507,
      "step": 16490
    },
    {
      "epoch": 6.25,
      "learning_rate": 0.000155612646153821,
      "loss": 0.9907,
      "step": 16500
    },
    {
      "epoch": 6.25,
      "learning_rate": 0.0001555632048476386,
      "loss": 0.9254,
      "step": 16510
    },
    {
      "epoch": 6.25,
      "learning_rate": 0.0001555137438856788,
      "loss": 0.9564,
      "step": 16520
    },
    {
      "epoch": 6.26,
      "learning_rate": 0.0001554642632854386,
      "loss": 0.9753,
      "step": 16530
    },
    {
      "epoch": 6.26,
      "learning_rate": 0.00015541476306442205,
      "loss": 0.9782,
      "step": 16540
    },
    {
      "epoch": 6.27,
      "learning_rate": 0.00015536524324014008,
      "loss": 0.9784,
      "step": 16550
    },
    {
      "epoch": 6.27,
      "learning_rate": 0.00015531570383011065,
      "loss": 1.0004,
      "step": 16560
    },
    {
      "epoch": 6.27,
      "learning_rate": 0.0001552661448518585,
      "loss": 0.9867,
      "step": 16570
    },
    {
      "epoch": 6.28,
      "learning_rate": 0.00015521656632291547,
      "loss": 0.9452,
      "step": 16580
    },
    {
      "epoch": 6.28,
      "learning_rate": 0.0001551669682608202,
      "loss": 1.0016,
      "step": 16590
    },
    {
      "epoch": 6.28,
      "learning_rate": 0.00015511735068311829,
      "loss": 1.0371,
      "step": 16600
    },
    {
      "epoch": 6.29,
      "learning_rate": 0.0001550677136073621,
      "loss": 0.9903,
      "step": 16610
    },
    {
      "epoch": 6.29,
      "learning_rate": 0.0001550180570511112,
      "loss": 0.954,
      "step": 16620
    },
    {
      "epoch": 6.3,
      "learning_rate": 0.00015496838103193169,
      "loss": 0.9891,
      "step": 16630
    },
    {
      "epoch": 6.3,
      "learning_rate": 0.00015491868556739678,
      "loss": 0.9881,
      "step": 16640
    },
    {
      "epoch": 6.3,
      "learning_rate": 0.00015486897067508654,
      "loss": 0.9984,
      "step": 16650
    },
    {
      "epoch": 6.31,
      "learning_rate": 0.0001548192363725879,
      "loss": 1.0003,
      "step": 16660
    },
    {
      "epoch": 6.31,
      "learning_rate": 0.0001547694826774945,
      "loss": 0.9756,
      "step": 16670
    },
    {
      "epoch": 6.32,
      "learning_rate": 0.0001547197096074071,
      "loss": 1.0002,
      "step": 16680
    },
    {
      "epoch": 6.32,
      "learning_rate": 0.00015466991717993312,
      "loss": 0.9358,
      "step": 16690
    },
    {
      "epoch": 6.32,
      "learning_rate": 0.00015462010541268694,
      "loss": 0.9705,
      "step": 16700
    },
    {
      "epoch": 6.33,
      "learning_rate": 0.0001545702743232897,
      "loss": 0.9679,
      "step": 16710
    },
    {
      "epoch": 6.33,
      "learning_rate": 0.00015452042392936942,
      "loss": 0.996,
      "step": 16720
    },
    {
      "epoch": 6.33,
      "learning_rate": 0.00015447055424856095,
      "loss": 0.9904,
      "step": 16730
    },
    {
      "epoch": 6.34,
      "learning_rate": 0.00015442066529850596,
      "loss": 0.9349,
      "step": 16740
    },
    {
      "epoch": 6.34,
      "learning_rate": 0.0001543707570968529,
      "loss": 0.9866,
      "step": 16750
    },
    {
      "epoch": 6.35,
      "learning_rate": 0.0001543208296612571,
      "loss": 0.9504,
      "step": 16760
    },
    {
      "epoch": 6.35,
      "learning_rate": 0.0001542708830093806,
      "loss": 1.0409,
      "step": 16770
    },
    {
      "epoch": 6.35,
      "learning_rate": 0.00015422091715889234,
      "loss": 1.0351,
      "step": 16780
    },
    {
      "epoch": 6.36,
      "learning_rate": 0.00015417093212746798,
      "loss": 0.9983,
      "step": 16790
    },
    {
      "epoch": 6.36,
      "learning_rate": 0.00015412092793279,
      "loss": 0.9773,
      "step": 16800
    },
    {
      "epoch": 6.36,
      "learning_rate": 0.00015407090459254764,
      "loss": 0.9547,
      "step": 16810
    },
    {
      "epoch": 6.37,
      "learning_rate": 0.00015402086212443694,
      "loss": 1.0686,
      "step": 16820
    },
    {
      "epoch": 6.37,
      "learning_rate": 0.00015397080054616068,
      "loss": 0.9841,
      "step": 16830
    },
    {
      "epoch": 6.38,
      "learning_rate": 0.00015392071987542838,
      "loss": 0.9935,
      "step": 16840
    },
    {
      "epoch": 6.38,
      "learning_rate": 0.00015387062012995635,
      "loss": 0.9815,
      "step": 16850
    },
    {
      "epoch": 6.38,
      "learning_rate": 0.0001538205013274677,
      "loss": 1.0479,
      "step": 16860
    },
    {
      "epoch": 6.39,
      "learning_rate": 0.00015377036348569213,
      "loss": 0.9581,
      "step": 16870
    },
    {
      "epoch": 6.39,
      "learning_rate": 0.00015372020662236626,
      "loss": 0.9456,
      "step": 16880
    },
    {
      "epoch": 6.39,
      "learning_rate": 0.00015367003075523328,
      "loss": 0.951,
      "step": 16890
    },
    {
      "epoch": 6.4,
      "learning_rate": 0.00015361983590204316,
      "loss": 0.9381,
      "step": 16900
    },
    {
      "epoch": 6.4,
      "learning_rate": 0.00015356962208055264,
      "loss": 0.9541,
      "step": 16910
    },
    {
      "epoch": 6.41,
      "learning_rate": 0.0001535193893085251,
      "loss": 0.9552,
      "step": 16920
    },
    {
      "epoch": 6.41,
      "learning_rate": 0.00015346913760373065,
      "loss": 0.9666,
      "step": 16930
    },
    {
      "epoch": 6.41,
      "learning_rate": 0.00015341886698394612,
      "loss": 0.9859,
      "step": 16940
    },
    {
      "epoch": 6.42,
      "learning_rate": 0.00015336857746695498,
      "loss": 0.9581,
      "step": 16950
    },
    {
      "epoch": 6.42,
      "learning_rate": 0.0001533182690705474,
      "loss": 0.9463,
      "step": 16960
    },
    {
      "epoch": 6.42,
      "learning_rate": 0.0001532679418125203,
      "loss": 1.0445,
      "step": 16970
    },
    {
      "epoch": 6.43,
      "learning_rate": 0.00015321759571067714,
      "loss": 1.0125,
      "step": 16980
    },
    {
      "epoch": 6.43,
      "learning_rate": 0.00015316723078282816,
      "loss": 0.9776,
      "step": 16990
    },
    {
      "epoch": 6.44,
      "learning_rate": 0.0001531168470467902,
      "loss": 0.962,
      "step": 17000
    },
    {
      "epoch": 6.44,
      "learning_rate": 0.00015306644452038682,
      "loss": 0.9261,
      "step": 17010
    },
    {
      "epoch": 6.44,
      "learning_rate": 0.0001530160232214481,
      "loss": 0.9504,
      "step": 17020
    },
    {
      "epoch": 6.45,
      "learning_rate": 0.00015296558316781094,
      "loss": 0.9834,
      "step": 17030
    },
    {
      "epoch": 6.45,
      "learning_rate": 0.00015291512437731872,
      "loss": 1.0076,
      "step": 17040
    },
    {
      "epoch": 6.46,
      "learning_rate": 0.00015286464686782147,
      "loss": 0.9763,
      "step": 17050
    },
    {
      "epoch": 6.46,
      "learning_rate": 0.00015281415065717595,
      "loss": 0.931,
      "step": 17060
    },
    {
      "epoch": 6.46,
      "learning_rate": 0.0001527636357632454,
      "loss": 0.9973,
      "step": 17070
    },
    {
      "epoch": 6.47,
      "learning_rate": 0.00015271310220389976,
      "loss": 0.9287,
      "step": 17080
    },
    {
      "epoch": 6.47,
      "learning_rate": 0.00015266254999701554,
      "loss": 1.0156,
      "step": 17090
    },
    {
      "epoch": 6.47,
      "learning_rate": 0.00015261197916047585,
      "loss": 0.9672,
      "step": 17100
    },
    {
      "epoch": 6.48,
      "learning_rate": 0.0001525613897121704,
      "loss": 0.9635,
      "step": 17110
    },
    {
      "epoch": 6.48,
      "learning_rate": 0.00015251078166999546,
      "loss": 1.0152,
      "step": 17120
    },
    {
      "epoch": 6.49,
      "learning_rate": 0.00015246015505185388,
      "loss": 1.0051,
      "step": 17130
    },
    {
      "epoch": 6.49,
      "learning_rate": 0.00015240950987565512,
      "loss": 0.9997,
      "step": 17140
    },
    {
      "epoch": 6.49,
      "learning_rate": 0.0001523588461593152,
      "loss": 0.9706,
      "step": 17150
    },
    {
      "epoch": 6.5,
      "learning_rate": 0.0001523081639207566,
      "loss": 0.9917,
      "step": 17160
    },
    {
      "epoch": 6.5,
      "learning_rate": 0.00015225746317790853,
      "loss": 1.0066,
      "step": 17170
    },
    {
      "epoch": 6.5,
      "learning_rate": 0.00015220674394870657,
      "loss": 0.9632,
      "step": 17180
    },
    {
      "epoch": 6.51,
      "learning_rate": 0.00015215600625109293,
      "loss": 1.0107,
      "step": 17190
    },
    {
      "epoch": 6.51,
      "learning_rate": 0.00015210525010301638,
      "loss": 0.9854,
      "step": 17200
    },
    {
      "epoch": 6.52,
      "learning_rate": 0.0001520544755224321,
      "loss": 1.0459,
      "step": 17210
    },
    {
      "epoch": 6.52,
      "learning_rate": 0.0001520036825273019,
      "loss": 0.998,
      "step": 17220
    },
    {
      "epoch": 6.52,
      "learning_rate": 0.00015195287113559412,
      "loss": 1.0068,
      "step": 17230
    },
    {
      "epoch": 6.53,
      "learning_rate": 0.00015190204136528352,
      "loss": 1.0166,
      "step": 17240
    },
    {
      "epoch": 6.53,
      "learning_rate": 0.00015185119323435136,
      "loss": 0.9758,
      "step": 17250
    },
    {
      "epoch": 6.53,
      "learning_rate": 0.00015180032676078553,
      "loss": 0.9698,
      "step": 17260
    },
    {
      "epoch": 6.54,
      "learning_rate": 0.00015174944196258024,
      "loss": 0.9193,
      "step": 17270
    },
    {
      "epoch": 6.54,
      "learning_rate": 0.00015169853885773623,
      "loss": 0.958,
      "step": 17280
    },
    {
      "epoch": 6.55,
      "learning_rate": 0.00015164761746426083,
      "loss": 0.9538,
      "step": 17290
    },
    {
      "epoch": 6.55,
      "learning_rate": 0.0001515966778001677,
      "loss": 0.9899,
      "step": 17300
    },
    {
      "epoch": 6.55,
      "learning_rate": 0.00015154571988347702,
      "loss": 0.9415,
      "step": 17310
    },
    {
      "epoch": 6.56,
      "learning_rate": 0.00015149474373221545,
      "loss": 0.9574,
      "step": 17320
    },
    {
      "epoch": 6.56,
      "learning_rate": 0.000151443749364416,
      "loss": 1.0492,
      "step": 17330
    },
    {
      "epoch": 6.57,
      "learning_rate": 0.00015139273679811832,
      "loss": 0.9933,
      "step": 17340
    },
    {
      "epoch": 6.57,
      "learning_rate": 0.00015134170605136824,
      "loss": 0.983,
      "step": 17350
    },
    {
      "epoch": 6.57,
      "learning_rate": 0.00015129065714221821,
      "loss": 0.9674,
      "step": 17360
    },
    {
      "epoch": 6.58,
      "learning_rate": 0.00015123959008872713,
      "loss": 1.003,
      "step": 17370
    },
    {
      "epoch": 6.58,
      "learning_rate": 0.00015118850490896012,
      "loss": 0.9394,
      "step": 17380
    },
    {
      "epoch": 6.58,
      "learning_rate": 0.00015113740162098885,
      "loss": 1.0398,
      "step": 17390
    },
    {
      "epoch": 6.59,
      "learning_rate": 0.00015108628024289148,
      "loss": 1.0066,
      "step": 17400
    },
    {
      "epoch": 6.59,
      "learning_rate": 0.0001510351407927524,
      "loss": 0.9878,
      "step": 17410
    },
    {
      "epoch": 6.6,
      "learning_rate": 0.0001509839832886624,
      "loss": 0.9821,
      "step": 17420
    },
    {
      "epoch": 6.6,
      "learning_rate": 0.00015093280774871882,
      "loss": 0.9678,
      "step": 17430
    },
    {
      "epoch": 6.6,
      "learning_rate": 0.00015088161419102522,
      "loss": 1.0236,
      "step": 17440
    },
    {
      "epoch": 6.61,
      "learning_rate": 0.00015083040263369157,
      "loss": 0.9697,
      "step": 17450
    },
    {
      "epoch": 6.61,
      "learning_rate": 0.00015077917309483434,
      "loss": 1.0039,
      "step": 17460
    },
    {
      "epoch": 6.61,
      "learning_rate": 0.00015072792559257613,
      "loss": 0.9984,
      "step": 17470
    },
    {
      "epoch": 6.62,
      "learning_rate": 0.00015067666014504605,
      "loss": 0.949,
      "step": 17480
    },
    {
      "epoch": 6.62,
      "learning_rate": 0.0001506253767703796,
      "loss": 0.9961,
      "step": 17490
    },
    {
      "epoch": 6.63,
      "learning_rate": 0.00015057407548671844,
      "loss": 1.0607,
      "step": 17500
    },
    {
      "epoch": 6.63,
      "learning_rate": 0.00015052275631221066,
      "loss": 0.9496,
      "step": 17510
    },
    {
      "epoch": 6.63,
      "learning_rate": 0.0001504714192650108,
      "loss": 0.9581,
      "step": 17520
    },
    {
      "epoch": 6.64,
      "learning_rate": 0.0001504200643632795,
      "loss": 0.9987,
      "step": 17530
    },
    {
      "epoch": 6.64,
      "learning_rate": 0.0001503686916251839,
      "loss": 0.9614,
      "step": 17540
    },
    {
      "epoch": 6.64,
      "learning_rate": 0.0001503173010688974,
      "loss": 1.0152,
      "step": 17550
    },
    {
      "epoch": 6.65,
      "learning_rate": 0.00015026589271259957,
      "loss": 1.0029,
      "step": 17560
    },
    {
      "epoch": 6.65,
      "learning_rate": 0.00015021446657447648,
      "loss": 1.0275,
      "step": 17570
    },
    {
      "epoch": 6.66,
      "learning_rate": 0.0001501630226727204,
      "loss": 0.9937,
      "step": 17580
    },
    {
      "epoch": 6.66,
      "learning_rate": 0.00015011156102552982,
      "loss": 0.9772,
      "step": 17590
    },
    {
      "epoch": 6.66,
      "learning_rate": 0.0001500600816511096,
      "loss": 0.9389,
      "step": 17600
    },
    {
      "epoch": 6.67,
      "learning_rate": 0.00015000858456767089,
      "loss": 1.0208,
      "step": 17610
    },
    {
      "epoch": 6.67,
      "learning_rate": 0.00014995706979343098,
      "loss": 0.9844,
      "step": 17620
    },
    {
      "epoch": 6.67,
      "learning_rate": 0.00014990553734661353,
      "loss": 1.0392,
      "step": 17630
    },
    {
      "epoch": 6.68,
      "learning_rate": 0.0001498539872454484,
      "loss": 0.9668,
      "step": 17640
    },
    {
      "epoch": 6.68,
      "learning_rate": 0.0001498024195081717,
      "loss": 0.9834,
      "step": 17650
    },
    {
      "epoch": 6.69,
      "learning_rate": 0.00014975083415302588,
      "loss": 0.9274,
      "step": 17660
    },
    {
      "epoch": 6.69,
      "learning_rate": 0.00014969923119825942,
      "loss": 1.0095,
      "step": 17670
    },
    {
      "epoch": 6.69,
      "learning_rate": 0.0001496476106621272,
      "loss": 0.9774,
      "step": 17680
    },
    {
      "epoch": 6.7,
      "learning_rate": 0.0001495959725628902,
      "loss": 0.9697,
      "step": 17690
    },
    {
      "epoch": 6.7,
      "learning_rate": 0.00014954431691881572,
      "loss": 0.988,
      "step": 17700
    },
    {
      "epoch": 6.71,
      "learning_rate": 0.00014949264374817723,
      "loss": 0.9407,
      "step": 17710
    },
    {
      "epoch": 6.71,
      "learning_rate": 0.00014944095306925433,
      "loss": 0.9712,
      "step": 17720
    },
    {
      "epoch": 6.71,
      "learning_rate": 0.00014938924490033294,
      "loss": 1.0078,
      "step": 17730
    },
    {
      "epoch": 6.72,
      "learning_rate": 0.00014933751925970501,
      "loss": 0.9972,
      "step": 17740
    },
    {
      "epoch": 6.72,
      "learning_rate": 0.00014928577616566888,
      "loss": 0.9749,
      "step": 17750
    },
    {
      "epoch": 6.72,
      "learning_rate": 0.00014923401563652884,
      "loss": 0.9431,
      "step": 17760
    },
    {
      "epoch": 6.73,
      "learning_rate": 0.0001491822376905955,
      "loss": 0.9422,
      "step": 17770
    },
    {
      "epoch": 6.73,
      "learning_rate": 0.00014913044234618556,
      "loss": 0.9785,
      "step": 17780
    },
    {
      "epoch": 6.74,
      "learning_rate": 0.0001490786296216219,
      "loss": 1.0017,
      "step": 17790
    },
    {
      "epoch": 6.74,
      "learning_rate": 0.00014902679953523356,
      "loss": 0.9817,
      "step": 17800
    },
    {
      "epoch": 6.74,
      "learning_rate": 0.00014897495210535567,
      "loss": 0.9592,
      "step": 17810
    },
    {
      "epoch": 6.75,
      "learning_rate": 0.00014892308735032958,
      "loss": 1.0121,
      "step": 17820
    },
    {
      "epoch": 6.75,
      "learning_rate": 0.00014887120528850271,
      "loss": 0.9767,
      "step": 17830
    },
    {
      "epoch": 6.75,
      "learning_rate": 0.00014881930593822857,
      "loss": 1.0381,
      "step": 17840
    },
    {
      "epoch": 6.76,
      "learning_rate": 0.00014876738931786688,
      "loss": 1.0088,
      "step": 17850
    },
    {
      "epoch": 6.76,
      "learning_rate": 0.00014871545544578344,
      "loss": 0.9413,
      "step": 17860
    },
    {
      "epoch": 6.77,
      "learning_rate": 0.00014866350434035005,
      "loss": 0.9057,
      "step": 17870
    },
    {
      "epoch": 6.77,
      "learning_rate": 0.00014861153601994473,
      "loss": 0.9879,
      "step": 17880
    },
    {
      "epoch": 6.77,
      "learning_rate": 0.00014855955050295159,
      "loss": 1.0169,
      "step": 17890
    },
    {
      "epoch": 6.78,
      "learning_rate": 0.00014850754780776072,
      "loss": 0.9988,
      "step": 17900
    },
    {
      "epoch": 6.78,
      "learning_rate": 0.00014845552795276834,
      "loss": 0.9503,
      "step": 17910
    },
    {
      "epoch": 6.78,
      "learning_rate": 0.0001484034909563768,
      "loss": 0.9889,
      "step": 17920
    },
    {
      "epoch": 6.79,
      "learning_rate": 0.0001483514368369945,
      "loss": 0.9598,
      "step": 17930
    },
    {
      "epoch": 6.79,
      "learning_rate": 0.0001482993656130357,
      "loss": 0.9841,
      "step": 17940
    },
    {
      "epoch": 6.8,
      "learning_rate": 0.00014824727730292103,
      "loss": 1.0513,
      "step": 17950
    },
    {
      "epoch": 6.8,
      "learning_rate": 0.00014819517192507696,
      "loss": 1.0323,
      "step": 17960
    },
    {
      "epoch": 6.8,
      "learning_rate": 0.000148143049497936,
      "loss": 0.9749,
      "step": 17970
    },
    {
      "epoch": 6.81,
      "learning_rate": 0.00014809091003993675,
      "loss": 1.0094,
      "step": 17980
    },
    {
      "epoch": 6.81,
      "learning_rate": 0.0001480387535695239,
      "loss": 0.9834,
      "step": 17990
    },
    {
      "epoch": 6.81,
      "learning_rate": 0.00014798658010514793,
      "loss": 1.0197,
      "step": 18000
    },
    {
      "epoch": 6.82,
      "learning_rate": 0.00014793438966526561,
      "loss": 0.9994,
      "step": 18010
    },
    {
      "epoch": 6.82,
      "learning_rate": 0.00014788218226833953,
      "loss": 1.0057,
      "step": 18020
    },
    {
      "epoch": 6.83,
      "learning_rate": 0.00014782995793283831,
      "loss": 1.0313,
      "step": 18030
    },
    {
      "epoch": 6.83,
      "learning_rate": 0.00014777771667723666,
      "loss": 0.9616,
      "step": 18040
    },
    {
      "epoch": 6.83,
      "learning_rate": 0.0001477254585200151,
      "loss": 0.9954,
      "step": 18050
    },
    {
      "epoch": 6.84,
      "learning_rate": 0.0001476731834796603,
      "loss": 1.0235,
      "step": 18060
    },
    {
      "epoch": 6.84,
      "learning_rate": 0.00014762089157466482,
      "loss": 0.9784,
      "step": 18070
    },
    {
      "epoch": 6.85,
      "learning_rate": 0.00014756858282352717,
      "loss": 1.0141,
      "step": 18080
    },
    {
      "epoch": 6.85,
      "learning_rate": 0.00014751625724475186,
      "loss": 0.9751,
      "step": 18090
    },
    {
      "epoch": 6.85,
      "learning_rate": 0.0001474639148568494,
      "loss": 1.0025,
      "step": 18100
    },
    {
      "epoch": 6.86,
      "learning_rate": 0.0001474115556783361,
      "loss": 0.95,
      "step": 18110
    },
    {
      "epoch": 6.86,
      "learning_rate": 0.00014735917972773433,
      "loss": 0.9826,
      "step": 18120
    },
    {
      "epoch": 6.86,
      "learning_rate": 0.00014730678702357233,
      "loss": 1.0144,
      "step": 18130
    },
    {
      "epoch": 6.87,
      "learning_rate": 0.0001472543775843844,
      "loss": 0.9752,
      "step": 18140
    },
    {
      "epoch": 6.87,
      "learning_rate": 0.00014720195142871054,
      "loss": 0.9663,
      "step": 18150
    },
    {
      "epoch": 6.88,
      "learning_rate": 0.0001471495085750968,
      "loss": 0.9748,
      "step": 18160
    },
    {
      "epoch": 6.88,
      "learning_rate": 0.00014709704904209515,
      "loss": 0.9815,
      "step": 18170
    },
    {
      "epoch": 6.88,
      "learning_rate": 0.00014704457284826346,
      "loss": 0.9493,
      "step": 18180
    },
    {
      "epoch": 6.89,
      "learning_rate": 0.00014699208001216536,
      "loss": 0.9745,
      "step": 18190
    },
    {
      "epoch": 6.89,
      "learning_rate": 0.00014693957055237052,
      "loss": 0.9491,
      "step": 18200
    },
    {
      "epoch": 6.89,
      "learning_rate": 0.0001468870444874545,
      "loss": 0.9852,
      "step": 18210
    },
    {
      "epoch": 6.9,
      "learning_rate": 0.00014683450183599858,
      "loss": 1.0256,
      "step": 18220
    },
    {
      "epoch": 6.9,
      "learning_rate": 0.00014678194261659005,
      "loss": 0.9883,
      "step": 18230
    },
    {
      "epoch": 6.91,
      "learning_rate": 0.000146729366847822,
      "loss": 1.0028,
      "step": 18240
    },
    {
      "epoch": 6.91,
      "learning_rate": 0.00014667677454829336,
      "loss": 0.9548,
      "step": 18250
    },
    {
      "epoch": 6.91,
      "learning_rate": 0.00014662416573660896,
      "loss": 0.9577,
      "step": 18260
    },
    {
      "epoch": 6.92,
      "learning_rate": 0.0001465715404313795,
      "loss": 0.9668,
      "step": 18270
    },
    {
      "epoch": 6.92,
      "learning_rate": 0.00014651889865122136,
      "loss": 0.9758,
      "step": 18280
    },
    {
      "epoch": 6.92,
      "learning_rate": 0.00014646624041475689,
      "loss": 1.011,
      "step": 18290
    },
    {
      "epoch": 6.93,
      "learning_rate": 0.0001464135657406142,
      "loss": 0.9625,
      "step": 18300
    },
    {
      "epoch": 6.93,
      "learning_rate": 0.00014636087464742732,
      "loss": 0.9936,
      "step": 18310
    },
    {
      "epoch": 6.94,
      "learning_rate": 0.00014630816715383593,
      "loss": 0.9891,
      "step": 18320
    },
    {
      "epoch": 6.94,
      "learning_rate": 0.00014625544327848556,
      "loss": 0.9964,
      "step": 18330
    },
    {
      "epoch": 6.94,
      "learning_rate": 0.00014620270304002762,
      "loss": 0.9304,
      "step": 18340
    },
    {
      "epoch": 6.95,
      "learning_rate": 0.0001461499464571192,
      "loss": 1.0027,
      "step": 18350
    },
    {
      "epoch": 6.95,
      "learning_rate": 0.00014609717354842328,
      "loss": 0.9841,
      "step": 18360
    },
    {
      "epoch": 6.96,
      "learning_rate": 0.00014604438433260845,
      "loss": 1.0066,
      "step": 18370
    },
    {
      "epoch": 6.96,
      "learning_rate": 0.00014599157882834928,
      "loss": 0.9263,
      "step": 18380
    },
    {
      "epoch": 6.96,
      "learning_rate": 0.00014593875705432596,
      "loss": 1.0168,
      "step": 18390
    },
    {
      "epoch": 6.97,
      "learning_rate": 0.00014588591902922447,
      "loss": 1.0025,
      "step": 18400
    },
    {
      "epoch": 6.97,
      "learning_rate": 0.00014583306477173656,
      "loss": 0.9888,
      "step": 18410
    },
    {
      "epoch": 6.97,
      "learning_rate": 0.0001457801943005596,
      "loss": 0.9268,
      "step": 18420
    },
    {
      "epoch": 6.98,
      "learning_rate": 0.000145727307634397,
      "loss": 1.0157,
      "step": 18430
    },
    {
      "epoch": 6.98,
      "learning_rate": 0.0001456744047919575,
      "loss": 0.9889,
      "step": 18440
    },
    {
      "epoch": 6.99,
      "learning_rate": 0.00014562148579195586,
      "loss": 0.9585,
      "step": 18450
    },
    {
      "epoch": 6.99,
      "learning_rate": 0.00014556855065311246,
      "loss": 1.0042,
      "step": 18460
    },
    {
      "epoch": 6.99,
      "learning_rate": 0.00014551559939415332,
      "loss": 1.029,
      "step": 18470
    },
    {
      "epoch": 7.0,
      "learning_rate": 0.0001454626320338103,
      "loss": 0.9846,
      "step": 18480
    },
    {
      "epoch": 7.0,
      "learning_rate": 0.00014540964859082088,
      "loss": 0.9949,
      "step": 18490
    },
    {
      "epoch": 7.0,
      "learning_rate": 0.00014535664908392818,
      "loss": 1.0036,
      "step": 18500
    },
    {
      "epoch": 7.01,
      "learning_rate": 0.000145303633531881,
      "loss": 0.9909,
      "step": 18510
    },
    {
      "epoch": 7.01,
      "learning_rate": 0.00014525060195343405,
      "loss": 1.0254,
      "step": 18520
    },
    {
      "epoch": 7.02,
      "learning_rate": 0.00014519755436734742,
      "loss": 0.9255,
      "step": 18530
    },
    {
      "epoch": 7.02,
      "learning_rate": 0.00014514449079238697,
      "loss": 0.9579,
      "step": 18540
    },
    {
      "epoch": 7.02,
      "learning_rate": 0.00014509141124732425,
      "loss": 0.9656,
      "step": 18550
    },
    {
      "epoch": 7.03,
      "learning_rate": 0.0001450383157509364,
      "loss": 0.956,
      "step": 18560
    },
    {
      "epoch": 7.03,
      "learning_rate": 0.0001449852043220063,
      "loss": 0.9762,
      "step": 18570
    },
    {
      "epoch": 7.03,
      "learning_rate": 0.0001449320769793223,
      "loss": 0.8929,
      "step": 18580
    },
    {
      "epoch": 7.04,
      "learning_rate": 0.00014487893374167855,
      "loss": 0.9812,
      "step": 18590
    },
    {
      "epoch": 7.04,
      "learning_rate": 0.0001448257746278747,
      "loss": 1.0164,
      "step": 18600
    },
    {
      "epoch": 7.05,
      "learning_rate": 0.00014477259965671612,
      "loss": 1.023,
      "step": 18610
    },
    {
      "epoch": 7.05,
      "learning_rate": 0.00014471940884701375,
      "loss": 0.9845,
      "step": 18620
    },
    {
      "epoch": 7.05,
      "learning_rate": 0.00014466620221758401,
      "loss": 0.9301,
      "step": 18630
    },
    {
      "epoch": 7.06,
      "learning_rate": 0.00014461297978724918,
      "loss": 0.9863,
      "step": 18640
    },
    {
      "epoch": 7.06,
      "learning_rate": 0.00014455974157483685,
      "loss": 0.9707,
      "step": 18650
    },
    {
      "epoch": 7.06,
      "learning_rate": 0.00014450648759918035,
      "loss": 0.9461,
      "step": 18660
    },
    {
      "epoch": 7.07,
      "learning_rate": 0.00014445321787911862,
      "loss": 0.9925,
      "step": 18670
    },
    {
      "epoch": 7.07,
      "learning_rate": 0.000144399932433496,
      "loss": 1.0023,
      "step": 18680
    },
    {
      "epoch": 7.08,
      "learning_rate": 0.0001443466312811626,
      "loss": 0.9721,
      "step": 18690
    },
    {
      "epoch": 7.08,
      "learning_rate": 0.00014429331444097395,
      "loss": 0.9668,
      "step": 18700
    },
    {
      "epoch": 7.08,
      "learning_rate": 0.00014423998193179109,
      "loss": 0.9743,
      "step": 18710
    },
    {
      "epoch": 7.09,
      "learning_rate": 0.0001441866337724808,
      "loss": 0.9762,
      "step": 18720
    },
    {
      "epoch": 7.09,
      "learning_rate": 0.0001441332699819152,
      "loss": 0.9687,
      "step": 18730
    },
    {
      "epoch": 7.1,
      "learning_rate": 0.000144079890578972,
      "loss": 0.945,
      "step": 18740
    },
    {
      "epoch": 7.1,
      "learning_rate": 0.00014402649558253446,
      "loss": 0.9941,
      "step": 18750
    },
    {
      "epoch": 7.1,
      "learning_rate": 0.00014397308501149143,
      "loss": 0.9832,
      "step": 18760
    },
    {
      "epoch": 7.11,
      "learning_rate": 0.00014391965888473703,
      "loss": 0.9699,
      "step": 18770
    },
    {
      "epoch": 7.11,
      "learning_rate": 0.00014386621722117118,
      "loss": 1.0237,
      "step": 18780
    },
    {
      "epoch": 7.11,
      "learning_rate": 0.00014381276003969904,
      "loss": 1.0336,
      "step": 18790
    },
    {
      "epoch": 7.12,
      "learning_rate": 0.0001437592873592314,
      "loss": 0.9422,
      "step": 18800
    },
    {
      "epoch": 7.12,
      "learning_rate": 0.00014370579919868455,
      "loss": 0.9567,
      "step": 18810
    },
    {
      "epoch": 7.13,
      "learning_rate": 0.00014365229557698015,
      "loss": 0.9733,
      "step": 18820
    },
    {
      "epoch": 7.13,
      "learning_rate": 0.0001435987765130454,
      "loss": 0.9799,
      "step": 18830
    },
    {
      "epoch": 7.13,
      "learning_rate": 0.00014354524202581304,
      "loss": 0.9436,
      "step": 18840
    },
    {
      "epoch": 7.14,
      "learning_rate": 0.00014349169213422104,
      "loss": 0.9456,
      "step": 18850
    },
    {
      "epoch": 7.14,
      "learning_rate": 0.00014343812685721304,
      "loss": 0.9613,
      "step": 18860
    },
    {
      "epoch": 7.14,
      "learning_rate": 0.000143384546213738,
      "loss": 0.9968,
      "step": 18870
    },
    {
      "epoch": 7.15,
      "learning_rate": 0.00014333095022275042,
      "loss": 0.9281,
      "step": 18880
    },
    {
      "epoch": 7.15,
      "learning_rate": 0.00014327733890321008,
      "loss": 0.9895,
      "step": 18890
    },
    {
      "epoch": 7.16,
      "learning_rate": 0.00014322371227408235,
      "loss": 1.0154,
      "step": 18900
    },
    {
      "epoch": 7.16,
      "learning_rate": 0.00014317007035433786,
      "loss": 0.9821,
      "step": 18910
    },
    {
      "epoch": 7.16,
      "learning_rate": 0.00014311641316295281,
      "loss": 0.9604,
      "step": 18920
    },
    {
      "epoch": 7.17,
      "learning_rate": 0.0001430627407189086,
      "loss": 0.954,
      "step": 18930
    },
    {
      "epoch": 7.17,
      "learning_rate": 0.00014300905304119222,
      "loss": 1.0287,
      "step": 18940
    },
    {
      "epoch": 7.17,
      "learning_rate": 0.000142955350148796,
      "loss": 0.9675,
      "step": 18950
    },
    {
      "epoch": 7.18,
      "learning_rate": 0.0001429016320607175,
      "loss": 0.9542,
      "step": 18960
    },
    {
      "epoch": 7.18,
      "learning_rate": 0.0001428478987959599,
      "loss": 1.0313,
      "step": 18970
    },
    {
      "epoch": 7.19,
      "learning_rate": 0.0001427941503735316,
      "loss": 0.9805,
      "step": 18980
    },
    {
      "epoch": 7.19,
      "learning_rate": 0.00014274038681244634,
      "loss": 0.9225,
      "step": 18990
    },
    {
      "epoch": 7.19,
      "learning_rate": 0.00014268660813172325,
      "loss": 0.9488,
      "step": 19000
    },
    {
      "epoch": 7.2,
      "learning_rate": 0.00014263281435038691,
      "loss": 1.0033,
      "step": 19010
    },
    {
      "epoch": 7.2,
      "learning_rate": 0.00014257900548746713,
      "loss": 0.9664,
      "step": 19020
    },
    {
      "epoch": 7.2,
      "learning_rate": 0.000142525181561999,
      "loss": 0.9715,
      "step": 19030
    },
    {
      "epoch": 7.21,
      "learning_rate": 0.0001424713425930231,
      "loss": 0.9276,
      "step": 19040
    },
    {
      "epoch": 7.21,
      "learning_rate": 0.00014241748859958523,
      "loss": 0.9535,
      "step": 19050
    },
    {
      "epoch": 7.22,
      "learning_rate": 0.00014236361960073653,
      "loss": 0.9547,
      "step": 19060
    },
    {
      "epoch": 7.22,
      "learning_rate": 0.0001423097356155334,
      "loss": 0.9402,
      "step": 19070
    },
    {
      "epoch": 7.22,
      "learning_rate": 0.00014225583666303766,
      "loss": 0.964,
      "step": 19080
    },
    {
      "epoch": 7.23,
      "learning_rate": 0.0001422019227623163,
      "loss": 0.972,
      "step": 19090
    },
    {
      "epoch": 7.23,
      "learning_rate": 0.00014215338748669736,
      "loss": 0.9804,
      "step": 19100
    },
    {
      "epoch": 7.24,
      "learning_rate": 0.00014209944523689593,
      "loss": 0.9372,
      "step": 19110
    },
    {
      "epoch": 7.24,
      "learning_rate": 0.00014204548809419322,
      "loss": 0.9294,
      "step": 19120
    },
    {
      "epoch": 7.24,
      "learning_rate": 0.00014199151607767683,
      "loss": 0.9971,
      "step": 19130
    },
    {
      "epoch": 7.25,
      "learning_rate": 0.0001419375292064396,
      "loss": 1.0155,
      "step": 19140
    },
    {
      "epoch": 7.25,
      "learning_rate": 0.0001418835274995797,
      "loss": 1.0175,
      "step": 19150
    },
    {
      "epoch": 7.25,
      "learning_rate": 0.00014182951097620053,
      "loss": 0.9474,
      "step": 19160
    },
    {
      "epoch": 7.26,
      "learning_rate": 0.00014177547965541073,
      "loss": 0.9386,
      "step": 19170
    },
    {
      "epoch": 7.26,
      "learning_rate": 0.0001417268388307113,
      "loss": 0.9743,
      "step": 19180
    },
    {
      "epoch": 7.27,
      "learning_rate": 0.00014167277944750428,
      "loss": 0.9488,
      "step": 19190
    },
    {
      "epoch": 7.27,
      "learning_rate": 0.00014161870532233123,
      "loss": 0.9107,
      "step": 19200
    },
    {
      "epoch": 7.27,
      "learning_rate": 0.00014156461647432116,
      "loss": 0.9587,
      "step": 19210
    },
    {
      "epoch": 7.28,
      "learning_rate": 0.00014151051292260824,
      "loss": 0.9441,
      "step": 19220
    },
    {
      "epoch": 7.28,
      "learning_rate": 0.00014145639468633197,
      "loss": 0.9808,
      "step": 19230
    },
    {
      "epoch": 7.28,
      "learning_rate": 0.00014140226178463688,
      "loss": 1.0209,
      "step": 19240
    },
    {
      "epoch": 7.29,
      "learning_rate": 0.0001413481142366728,
      "loss": 0.9557,
      "step": 19250
    },
    {
      "epoch": 7.29,
      "learning_rate": 0.00014129395206159473,
      "loss": 0.9407,
      "step": 19260
    },
    {
      "epoch": 7.3,
      "learning_rate": 0.0001412397752785628,
      "loss": 1.0143,
      "step": 19270
    },
    {
      "epoch": 7.3,
      "learning_rate": 0.00014118558390674235,
      "loss": 0.9561,
      "step": 19280
    },
    {
      "epoch": 7.3,
      "learning_rate": 0.00014113137796530385,
      "loss": 0.9416,
      "step": 19290
    },
    {
      "epoch": 7.31,
      "learning_rate": 0.00014107715747342298,
      "loss": 1.004,
      "step": 19300
    },
    {
      "epoch": 7.31,
      "learning_rate": 0.00014102292245028045,
      "loss": 0.9395,
      "step": 19310
    },
    {
      "epoch": 7.31,
      "learning_rate": 0.0001409686729150623,
      "loss": 0.9205,
      "step": 19320
    },
    {
      "epoch": 7.32,
      "learning_rate": 0.00014091440888695943,
      "loss": 0.9579,
      "step": 19330
    },
    {
      "epoch": 7.32,
      "learning_rate": 0.00014086013038516813,
      "loss": 1.0099,
      "step": 19340
    },
    {
      "epoch": 7.33,
      "learning_rate": 0.00014080583742888975,
      "loss": 0.9665,
      "step": 19350
    },
    {
      "epoch": 7.33,
      "learning_rate": 0.00014075153003733062,
      "loss": 0.9677,
      "step": 19360
    },
    {
      "epoch": 7.33,
      "learning_rate": 0.00014069720822970226,
      "loss": 0.9596,
      "step": 19370
    },
    {
      "epoch": 7.34,
      "learning_rate": 0.00014064287202522141,
      "loss": 0.9459,
      "step": 19380
    },
    {
      "epoch": 7.34,
      "learning_rate": 0.00014058852144310967,
      "loss": 0.9441,
      "step": 19390
    },
    {
      "epoch": 7.35,
      "learning_rate": 0.00014053415650259392,
      "loss": 0.9771,
      "step": 19400
    },
    {
      "epoch": 7.35,
      "learning_rate": 0.000140479777222906,
      "loss": 0.9922,
      "step": 19410
    },
    {
      "epoch": 7.35,
      "learning_rate": 0.0001404253836232829,
      "loss": 0.9807,
      "step": 19420
    },
    {
      "epoch": 7.36,
      "learning_rate": 0.00014037097572296657,
      "loss": 0.9458,
      "step": 19430
    },
    {
      "epoch": 7.36,
      "learning_rate": 0.00014031655354120422,
      "loss": 0.965,
      "step": 19440
    },
    {
      "epoch": 7.36,
      "learning_rate": 0.0001402621170972479,
      "loss": 0.9474,
      "step": 19450
    },
    {
      "epoch": 7.37,
      "learning_rate": 0.00014020766641035482,
      "loss": 0.992,
      "step": 19460
    },
    {
      "epoch": 7.37,
      "learning_rate": 0.00014015320149978714,
      "loss": 0.9924,
      "step": 19470
    },
    {
      "epoch": 7.38,
      "learning_rate": 0.00014009872238481216,
      "loss": 0.9568,
      "step": 19480
    },
    {
      "epoch": 7.38,
      "learning_rate": 0.0001400442290847022,
      "loss": 0.9335,
      "step": 19490
    },
    {
      "epoch": 7.38,
      "learning_rate": 0.00013998972161873442,
      "loss": 0.9328,
      "step": 19500
    },
    {
      "epoch": 7.39,
      "learning_rate": 0.00013993520000619124,
      "loss": 0.9867,
      "step": 19510
    },
    {
      "epoch": 7.39,
      "learning_rate": 0.00013988066426635999,
      "loss": 0.9754,
      "step": 19520
    },
    {
      "epoch": 7.39,
      "learning_rate": 0.00013982611441853285,
      "loss": 0.9413,
      "step": 19530
    },
    {
      "epoch": 7.4,
      "learning_rate": 0.0001397715504820072,
      "loss": 0.9892,
      "step": 19540
    },
    {
      "epoch": 7.4,
      "learning_rate": 0.00013971697247608532,
      "loss": 0.9486,
      "step": 19550
    },
    {
      "epoch": 7.41,
      "learning_rate": 0.00013966238042007446,
      "loss": 0.9834,
      "step": 19560
    },
    {
      "epoch": 7.41,
      "learning_rate": 0.00013960777433328681,
      "loss": 0.9496,
      "step": 19570
    },
    {
      "epoch": 7.41,
      "learning_rate": 0.00013955315423503967,
      "loss": 0.985,
      "step": 19580
    },
    {
      "epoch": 7.42,
      "learning_rate": 0.00013949852014465505,
      "loss": 1.0063,
      "step": 19590
    },
    {
      "epoch": 7.42,
      "learning_rate": 0.00013944387208146016,
      "loss": 1.0082,
      "step": 19600
    },
    {
      "epoch": 7.42,
      "learning_rate": 0.00013938921006478695,
      "loss": 1.0128,
      "step": 19610
    },
    {
      "epoch": 7.43,
      "learning_rate": 0.00013933453411397247,
      "loss": 0.9402,
      "step": 19620
    },
    {
      "epoch": 7.43,
      "learning_rate": 0.0001392798442483586,
      "loss": 0.9364,
      "step": 19630
    },
    {
      "epoch": 7.44,
      "learning_rate": 0.00013922514048729217,
      "loss": 0.9529,
      "step": 19640
    },
    {
      "epoch": 7.44,
      "learning_rate": 0.00013917042285012488,
      "loss": 0.9845,
      "step": 19650
    },
    {
      "epoch": 7.44,
      "learning_rate": 0.0001391156913562135,
      "loss": 0.9662,
      "step": 19660
    },
    {
      "epoch": 7.45,
      "learning_rate": 0.0001390609460249195,
      "loss": 0.9937,
      "step": 19670
    },
    {
      "epoch": 7.45,
      "learning_rate": 0.00013900618687560926,
      "loss": 0.9611,
      "step": 19680
    },
    {
      "epoch": 7.45,
      "learning_rate": 0.00013895141392765428,
      "loss": 0.9662,
      "step": 19690
    },
    {
      "epoch": 7.46,
      "learning_rate": 0.00013889662720043068,
      "loss": 0.9032,
      "step": 19700
    },
    {
      "epoch": 7.46,
      "learning_rate": 0.00013884182671331953,
      "loss": 0.9705,
      "step": 19710
    },
    {
      "epoch": 7.47,
      "learning_rate": 0.0001387870124857069,
      "loss": 0.975,
      "step": 19720
    },
    {
      "epoch": 7.47,
      "learning_rate": 0.00013873218453698357,
      "loss": 0.9911,
      "step": 19730
    },
    {
      "epoch": 7.47,
      "learning_rate": 0.0001386773428865451,
      "loss": 0.9534,
      "step": 19740
    },
    {
      "epoch": 7.48,
      "learning_rate": 0.00013862248755379218,
      "loss": 0.9757,
      "step": 19750
    },
    {
      "epoch": 7.48,
      "learning_rate": 0.00013856761855813007,
      "loss": 0.9611,
      "step": 19760
    },
    {
      "epoch": 7.49,
      "learning_rate": 0.00013851273591896902,
      "loss": 0.9981,
      "step": 19770
    },
    {
      "epoch": 7.49,
      "learning_rate": 0.00013845783965572402,
      "loss": 0.9934,
      "step": 19780
    },
    {
      "epoch": 7.49,
      "learning_rate": 0.00013840292978781494,
      "loss": 0.9531,
      "step": 19790
    },
    {
      "epoch": 7.5,
      "learning_rate": 0.00013834800633466646,
      "loss": 1.0038,
      "step": 19800
    },
    {
      "epoch": 7.5,
      "learning_rate": 0.00013829306931570798,
      "loss": 1.0254,
      "step": 19810
    },
    {
      "epoch": 7.5,
      "learning_rate": 0.00013823811875037377,
      "loss": 0.9372,
      "step": 19820
    },
    {
      "epoch": 7.51,
      "learning_rate": 0.0001381831546581029,
      "loss": 1.0237,
      "step": 19830
    },
    {
      "epoch": 7.51,
      "learning_rate": 0.00013812817705833924,
      "loss": 0.9851,
      "step": 19840
    },
    {
      "epoch": 7.52,
      "learning_rate": 0.00013807318597053135,
      "loss": 0.945,
      "step": 19850
    },
    {
      "epoch": 7.52,
      "learning_rate": 0.00013801818141413264,
      "loss": 0.9752,
      "step": 19860
    },
    {
      "epoch": 7.52,
      "learning_rate": 0.0001379631634086013,
      "loss": 0.9531,
      "step": 19870
    },
    {
      "epoch": 7.53,
      "learning_rate": 0.00013790813197340015,
      "loss": 1.0118,
      "step": 19880
    },
    {
      "epoch": 7.53,
      "learning_rate": 0.00013785308712799694,
      "loss": 0.9489,
      "step": 19890
    },
    {
      "epoch": 7.53,
      "learning_rate": 0.00013779802889186406,
      "loss": 0.9368,
      "step": 19900
    },
    {
      "epoch": 7.54,
      "learning_rate": 0.00013774295728447863,
      "loss": 0.9684,
      "step": 19910
    },
    {
      "epoch": 7.54,
      "learning_rate": 0.0001376878723253225,
      "loss": 0.9221,
      "step": 19920
    },
    {
      "epoch": 7.55,
      "learning_rate": 0.0001376327740338823,
      "loss": 0.9516,
      "step": 19930
    },
    {
      "epoch": 7.55,
      "learning_rate": 0.0001375776624296493,
      "loss": 0.9641,
      "step": 19940
    },
    {
      "epoch": 7.55,
      "learning_rate": 0.00013752253753211962,
      "loss": 0.9204,
      "step": 19950
    },
    {
      "epoch": 7.56,
      "learning_rate": 0.0001374673993607939,
      "loss": 0.957,
      "step": 19960
    },
    {
      "epoch": 7.56,
      "learning_rate": 0.00013741224793517755,
      "loss": 0.9476,
      "step": 19970
    },
    {
      "epoch": 7.56,
      "learning_rate": 0.00013735708327478074,
      "loss": 0.9376,
      "step": 19980
    },
    {
      "epoch": 7.57,
      "learning_rate": 0.0001373019053991182,
      "loss": 0.9478,
      "step": 19990
    },
    {
      "epoch": 7.57,
      "learning_rate": 0.00013724671432770944,
      "loss": 1.0097,
      "step": 20000
    },
    {
      "epoch": 7.58,
      "learning_rate": 0.00013719151008007857,
      "loss": 0.9882,
      "step": 20010
    },
    {
      "epoch": 7.58,
      "learning_rate": 0.0001371362926757544,
      "loss": 0.9803,
      "step": 20020
    },
    {
      "epoch": 7.58,
      "learning_rate": 0.00013708106213427036,
      "loss": 0.9915,
      "step": 20030
    },
    {
      "epoch": 7.59,
      "learning_rate": 0.00013702581847516458,
      "loss": 0.9671,
      "step": 20040
    },
    {
      "epoch": 7.59,
      "learning_rate": 0.00013697056171797973,
      "loss": 0.9888,
      "step": 20050
    },
    {
      "epoch": 7.59,
      "learning_rate": 0.00013691529188226325,
      "loss": 0.9777,
      "step": 20060
    },
    {
      "epoch": 7.6,
      "learning_rate": 0.0001368600089875671,
      "loss": 0.9741,
      "step": 20070
    },
    {
      "epoch": 7.6,
      "learning_rate": 0.0001368047130534479,
      "loss": 0.9851,
      "step": 20080
    },
    {
      "epoch": 7.61,
      "learning_rate": 0.00013674940409946692,
      "loss": 0.9512,
      "step": 20090
    },
    {
      "epoch": 7.61,
      "learning_rate": 0.0001366940821451899,
      "loss": 0.9623,
      "step": 20100
    },
    {
      "epoch": 7.61,
      "learning_rate": 0.00013663874721018738,
      "loss": 0.999,
      "step": 20110
    },
    {
      "epoch": 7.62,
      "learning_rate": 0.0001365833993140343,
      "loss": 0.895,
      "step": 20120
    },
    {
      "epoch": 7.62,
      "learning_rate": 0.00013652803847631032,
      "loss": 1.0045,
      "step": 20130
    },
    {
      "epoch": 7.63,
      "learning_rate": 0.0001364726647165996,
      "loss": 0.9968,
      "step": 20140
    },
    {
      "epoch": 7.63,
      "learning_rate": 0.00013641727805449098,
      "loss": 0.9582,
      "step": 20150
    },
    {
      "epoch": 7.63,
      "learning_rate": 0.00013636187850957766,
      "loss": 0.9488,
      "step": 20160
    },
    {
      "epoch": 7.64,
      "learning_rate": 0.0001363064661014576,
      "loss": 0.9537,
      "step": 20170
    },
    {
      "epoch": 7.64,
      "learning_rate": 0.00013625104084973326,
      "loss": 0.9858,
      "step": 20180
    },
    {
      "epoch": 7.64,
      "learning_rate": 0.00013619560277401154,
      "loss": 0.9607,
      "step": 20190
    },
    {
      "epoch": 7.65,
      "learning_rate": 0.00013614015189390396,
      "loss": 0.9444,
      "step": 20200
    },
    {
      "epoch": 7.65,
      "learning_rate": 0.00013608468822902663,
      "loss": 0.9644,
      "step": 20210
    },
    {
      "epoch": 7.66,
      "learning_rate": 0.00013602921179900005,
      "loss": 0.9949,
      "step": 20220
    },
    {
      "epoch": 7.66,
      "learning_rate": 0.00013597372262344934,
      "loss": 1.0483,
      "step": 20230
    },
    {
      "epoch": 7.66,
      "learning_rate": 0.00013591822072200405,
      "loss": 0.9791,
      "step": 20240
    },
    {
      "epoch": 7.67,
      "learning_rate": 0.00013586270611429827,
      "loss": 1.0001,
      "step": 20250
    },
    {
      "epoch": 7.67,
      "learning_rate": 0.00013580717881997068,
      "loss": 0.9948,
      "step": 20260
    },
    {
      "epoch": 7.67,
      "learning_rate": 0.00013575163885866422,
      "loss": 0.9789,
      "step": 20270
    },
    {
      "epoch": 7.68,
      "learning_rate": 0.0001356960862500265,
      "loss": 0.9344,
      "step": 20280
    },
    {
      "epoch": 7.68,
      "learning_rate": 0.0001356405210137096,
      "loss": 0.9146,
      "step": 20290
    },
    {
      "epoch": 7.69,
      "learning_rate": 0.00013558494316936998,
      "loss": 0.9443,
      "step": 20300
    },
    {
      "epoch": 7.69,
      "learning_rate": 0.00013552935273666852,
      "loss": 0.952,
      "step": 20310
    },
    {
      "epoch": 7.69,
      "learning_rate": 0.00013547374973527077,
      "loss": 1.0214,
      "step": 20320
    },
    {
      "epoch": 7.7,
      "learning_rate": 0.0001354181341848465,
      "loss": 0.9998,
      "step": 20330
    },
    {
      "epoch": 7.7,
      "learning_rate": 0.00013536250610507,
      "loss": 0.9846,
      "step": 20340
    },
    {
      "epoch": 7.7,
      "learning_rate": 0.00013530686551562,
      "loss": 0.9923,
      "step": 20350
    },
    {
      "epoch": 7.71,
      "learning_rate": 0.0001352512124361797,
      "loss": 0.9291,
      "step": 20360
    },
    {
      "epoch": 7.71,
      "learning_rate": 0.00013519554688643662,
      "loss": 0.963,
      "step": 20370
    },
    {
      "epoch": 7.72,
      "learning_rate": 0.00013513986888608276,
      "loss": 0.9844,
      "step": 20380
    },
    {
      "epoch": 7.72,
      "learning_rate": 0.00013508417845481453,
      "loss": 1.0046,
      "step": 20390
    },
    {
      "epoch": 7.72,
      "learning_rate": 0.0001350284756123327,
      "loss": 0.9463,
      "step": 20400
    },
    {
      "epoch": 7.73,
      "learning_rate": 0.00013497276037834242,
      "loss": 1.0073,
      "step": 20410
    },
    {
      "epoch": 7.73,
      "learning_rate": 0.00013491703277255325,
      "loss": 0.9633,
      "step": 20420
    },
    {
      "epoch": 7.73,
      "learning_rate": 0.00013486129281467917,
      "loss": 0.9811,
      "step": 20430
    },
    {
      "epoch": 7.74,
      "learning_rate": 0.00013480554052443846,
      "loss": 0.9711,
      "step": 20440
    },
    {
      "epoch": 7.74,
      "learning_rate": 0.00013474977592155377,
      "loss": 1.0022,
      "step": 20450
    },
    {
      "epoch": 7.75,
      "learning_rate": 0.00013469399902575212,
      "loss": 0.9745,
      "step": 20460
    },
    {
      "epoch": 7.75,
      "learning_rate": 0.00013463820985676493,
      "loss": 0.9639,
      "step": 20470
    },
    {
      "epoch": 7.75,
      "learning_rate": 0.00013458240843432787,
      "loss": 0.9279,
      "step": 20480
    },
    {
      "epoch": 7.76,
      "learning_rate": 0.00013452659477818102,
      "loss": 1.0104,
      "step": 20490
    },
    {
      "epoch": 7.76,
      "learning_rate": 0.00013447076890806873,
      "loss": 0.9683,
      "step": 20500
    },
    {
      "epoch": 7.77,
      "learning_rate": 0.00013441493084373967,
      "loss": 0.9691,
      "step": 20510
    },
    {
      "epoch": 7.77,
      "learning_rate": 0.00013435908060494692,
      "loss": 0.9962,
      "step": 20520
    },
    {
      "epoch": 7.77,
      "learning_rate": 0.00013430321821144775,
      "loss": 0.9558,
      "step": 20530
    },
    {
      "epoch": 7.78,
      "learning_rate": 0.0001342473436830038,
      "loss": 0.9452,
      "step": 20540
    },
    {
      "epoch": 7.78,
      "learning_rate": 0.00013419145703938095,
      "loss": 0.9837,
      "step": 20550
    },
    {
      "epoch": 7.78,
      "learning_rate": 0.00013413555830034944,
      "loss": 0.9569,
      "step": 20560
    },
    {
      "epoch": 7.79,
      "learning_rate": 0.00013407964748568367,
      "loss": 0.9549,
      "step": 20570
    },
    {
      "epoch": 7.79,
      "learning_rate": 0.00013402372461516248,
      "loss": 0.9251,
      "step": 20580
    },
    {
      "epoch": 7.8,
      "learning_rate": 0.00013396778970856883,
      "loss": 0.954,
      "step": 20590
    },
    {
      "epoch": 7.8,
      "learning_rate": 0.00013391184278569,
      "loss": 0.9724,
      "step": 20600
    },
    {
      "epoch": 7.8,
      "learning_rate": 0.00013385588386631746,
      "loss": 0.9683,
      "step": 20610
    },
    {
      "epoch": 7.81,
      "learning_rate": 0.00013379991297024705,
      "loss": 0.9562,
      "step": 20620
    },
    {
      "epoch": 7.81,
      "learning_rate": 0.00013374393011727874,
      "loss": 0.9274,
      "step": 20630
    },
    {
      "epoch": 7.81,
      "learning_rate": 0.00013368793532721676,
      "loss": 0.9863,
      "step": 20640
    },
    {
      "epoch": 7.82,
      "learning_rate": 0.00013363192861986955,
      "loss": 0.9722,
      "step": 20650
    },
    {
      "epoch": 7.82,
      "learning_rate": 0.0001335759100150498,
      "loss": 0.9537,
      "step": 20660
    },
    {
      "epoch": 7.83,
      "learning_rate": 0.00013351987953257437,
      "loss": 0.9994,
      "step": 20670
    },
    {
      "epoch": 7.83,
      "learning_rate": 0.00013346383719226433,
      "loss": 1.0282,
      "step": 20680
    },
    {
      "epoch": 7.83,
      "learning_rate": 0.00013340778301394504,
      "loss": 0.8804,
      "step": 20690
    },
    {
      "epoch": 7.84,
      "learning_rate": 0.00013335171701744583,
      "loss": 0.968,
      "step": 20700
    },
    {
      "epoch": 7.84,
      "learning_rate": 0.0001332956392226004,
      "loss": 0.9907,
      "step": 20710
    },
    {
      "epoch": 7.84,
      "learning_rate": 0.0001332395496492466,
      "loss": 0.8966,
      "step": 20720
    },
    {
      "epoch": 7.85,
      "learning_rate": 0.00013318344831722638,
      "loss": 0.942,
      "step": 20730
    },
    {
      "epoch": 7.85,
      "learning_rate": 0.0001331273352463859,
      "loss": 0.9458,
      "step": 20740
    },
    {
      "epoch": 7.86,
      "learning_rate": 0.00013307121045657544,
      "loss": 0.9729,
      "step": 20750
    },
    {
      "epoch": 7.86,
      "learning_rate": 0.00013301507396764944,
      "loss": 0.9597,
      "step": 20760
    },
    {
      "epoch": 7.86,
      "learning_rate": 0.00013295892579946646,
      "loss": 0.963,
      "step": 20770
    },
    {
      "epoch": 7.87,
      "learning_rate": 0.00013290276597188928,
      "loss": 1.0156,
      "step": 20780
    },
    {
      "epoch": 7.87,
      "learning_rate": 0.00013284659450478467,
      "loss": 0.9645,
      "step": 20790
    },
    {
      "epoch": 7.88,
      "learning_rate": 0.00013279041141802357,
      "loss": 0.9667,
      "step": 20800
    },
    {
      "epoch": 7.88,
      "learning_rate": 0.00013273421673148114,
      "loss": 0.9701,
      "step": 20810
    },
    {
      "epoch": 7.88,
      "learning_rate": 0.00013267801046503648,
      "loss": 0.9496,
      "step": 20820
    },
    {
      "epoch": 7.89,
      "learning_rate": 0.00013262179263857284,
      "loss": 0.9545,
      "step": 20830
    },
    {
      "epoch": 7.89,
      "learning_rate": 0.00013256556327197758,
      "loss": 1.0323,
      "step": 20840
    },
    {
      "epoch": 7.89,
      "learning_rate": 0.00013250932238514218,
      "loss": 0.9839,
      "step": 20850
    },
    {
      "epoch": 7.9,
      "learning_rate": 0.00013245306999796208,
      "loss": 0.9673,
      "step": 20860
    },
    {
      "epoch": 7.9,
      "learning_rate": 0.00013239680613033695,
      "loss": 0.9653,
      "step": 20870
    },
    {
      "epoch": 7.91,
      "learning_rate": 0.00013234053080217033,
      "loss": 0.9506,
      "step": 20880
    },
    {
      "epoch": 7.91,
      "learning_rate": 0.00013228424403337002,
      "loss": 1.0105,
      "step": 20890
    },
    {
      "epoch": 7.91,
      "learning_rate": 0.00013222794584384767,
      "loss": 0.9534,
      "step": 20900
    },
    {
      "epoch": 7.92,
      "learning_rate": 0.00013217163625351913,
      "loss": 1.0163,
      "step": 20910
    },
    {
      "epoch": 7.92,
      "learning_rate": 0.00013211531528230415,
      "loss": 0.8891,
      "step": 20920
    },
    {
      "epoch": 7.92,
      "learning_rate": 0.00013205898295012665,
      "loss": 0.9872,
      "step": 20930
    },
    {
      "epoch": 7.93,
      "learning_rate": 0.00013200263927691435,
      "loss": 0.9825,
      "step": 20940
    },
    {
      "epoch": 7.93,
      "learning_rate": 0.00013194628428259933,
      "loss": 1.0027,
      "step": 20950
    },
    {
      "epoch": 7.94,
      "learning_rate": 0.0001318899179871173,
      "loss": 0.9784,
      "step": 20960
    },
    {
      "epoch": 7.94,
      "learning_rate": 0.00013183354041040822,
      "loss": 0.9866,
      "step": 20970
    },
    {
      "epoch": 7.94,
      "learning_rate": 0.0001317771515724159,
      "loss": 0.9568,
      "step": 20980
    },
    {
      "epoch": 7.95,
      "learning_rate": 0.00013172075149308824,
      "loss": 0.9936,
      "step": 20990
    },
    {
      "epoch": 7.95,
      "learning_rate": 0.00013166434019237704,
      "loss": 0.9729,
      "step": 21000
    },
    {
      "epoch": 7.95,
      "learning_rate": 0.00013160791769023807,
      "loss": 1.0249,
      "step": 21010
    },
    {
      "epoch": 7.96,
      "learning_rate": 0.00013155148400663115,
      "loss": 0.9525,
      "step": 21020
    },
    {
      "epoch": 7.96,
      "learning_rate": 0.00013149503916151992,
      "loss": 0.987,
      "step": 21030
    },
    {
      "epoch": 7.97,
      "learning_rate": 0.00013143858317487213,
      "loss": 0.9882,
      "step": 21040
    },
    {
      "epoch": 7.97,
      "learning_rate": 0.0001313821160666593,
      "loss": 0.9719,
      "step": 21050
    },
    {
      "epoch": 7.97,
      "learning_rate": 0.00013132563785685702,
      "loss": 0.9478,
      "step": 21060
    },
    {
      "epoch": 7.98,
      "learning_rate": 0.00013126914856544477,
      "loss": 0.9495,
      "step": 21070
    },
    {
      "epoch": 7.98,
      "learning_rate": 0.00013121264821240586,
      "loss": 0.9848,
      "step": 21080
    },
    {
      "epoch": 7.98,
      "learning_rate": 0.00013115613681772764,
      "loss": 0.977,
      "step": 21090
    },
    {
      "epoch": 7.99,
      "learning_rate": 0.00013109961440140134,
      "loss": 0.9884,
      "step": 21100
    },
    {
      "epoch": 7.99,
      "learning_rate": 0.000131043080983422,
      "loss": 0.9692,
      "step": 21110
    },
    {
      "epoch": 8.0,
      "learning_rate": 0.00013098653658378864,
      "loss": 1.0123,
      "step": 21120
    },
    {
      "epoch": 8.0,
      "learning_rate": 0.00013092998122250421,
      "loss": 0.9885,
      "step": 21130
    },
    {
      "epoch": 8.0,
      "learning_rate": 0.00013087341491957533,
      "loss": 0.9641,
      "step": 21140
    },
    {
      "epoch": 8.01,
      "learning_rate": 0.00013081683769501276,
      "loss": 0.939,
      "step": 21150
    },
    {
      "epoch": 8.01,
      "learning_rate": 0.00013076024956883093,
      "loss": 0.9509,
      "step": 21160
    },
    {
      "epoch": 8.02,
      "learning_rate": 0.00013070365056104817,
      "loss": 0.9391,
      "step": 21170
    },
    {
      "epoch": 8.02,
      "learning_rate": 0.00013064704069168674,
      "loss": 0.951,
      "step": 21180
    },
    {
      "epoch": 8.02,
      "learning_rate": 0.0001305904199807726,
      "loss": 0.9463,
      "step": 21190
    },
    {
      "epoch": 8.03,
      "learning_rate": 0.0001305337884483357,
      "loss": 0.9251,
      "step": 21200
    },
    {
      "epoch": 8.03,
      "learning_rate": 0.00013047714611440973,
      "loss": 0.9185,
      "step": 21210
    },
    {
      "epoch": 8.03,
      "learning_rate": 0.00013042049299903216,
      "loss": 0.9439,
      "step": 21220
    },
    {
      "epoch": 8.04,
      "learning_rate": 0.0001303638291222444,
      "loss": 0.9063,
      "step": 21230
    },
    {
      "epoch": 8.04,
      "learning_rate": 0.00013030715450409157,
      "loss": 0.9161,
      "step": 21240
    },
    {
      "epoch": 8.05,
      "learning_rate": 0.0001302504691646226,
      "loss": 0.9751,
      "step": 21250
    },
    {
      "epoch": 8.05,
      "learning_rate": 0.0001301937731238902,
      "loss": 1.007,
      "step": 21260
    },
    {
      "epoch": 8.05,
      "learning_rate": 0.000130137066401951,
      "loss": 0.955,
      "step": 21270
    },
    {
      "epoch": 8.06,
      "learning_rate": 0.00013008034901886522,
      "loss": 0.9929,
      "step": 21280
    },
    {
      "epoch": 8.06,
      "learning_rate": 0.00013002362099469688,
      "loss": 0.9401,
      "step": 21290
    },
    {
      "epoch": 8.06,
      "learning_rate": 0.00012996688234951398,
      "loss": 0.9672,
      "step": 21300
    },
    {
      "epoch": 8.07,
      "learning_rate": 0.00012991013310338797,
      "loss": 0.9683,
      "step": 21310
    },
    {
      "epoch": 8.07,
      "learning_rate": 0.00012985337327639428,
      "loss": 0.9418,
      "step": 21320
    },
    {
      "epoch": 8.08,
      "learning_rate": 0.00012979660288861195,
      "loss": 0.9879,
      "step": 21330
    },
    {
      "epoch": 8.08,
      "learning_rate": 0.00012973982196012382,
      "loss": 0.9524,
      "step": 21340
    },
    {
      "epoch": 8.08,
      "learning_rate": 0.00012968303051101647,
      "loss": 1.0079,
      "step": 21350
    },
    {
      "epoch": 8.09,
      "learning_rate": 0.00012962622856138017,
      "loss": 0.9712,
      "step": 21360
    },
    {
      "epoch": 8.09,
      "learning_rate": 0.0001295694161313088,
      "loss": 0.9646,
      "step": 21370
    },
    {
      "epoch": 8.09,
      "learning_rate": 0.00012951259324090023,
      "loss": 0.9669,
      "step": 21380
    },
    {
      "epoch": 8.1,
      "learning_rate": 0.00012945575991025581,
      "loss": 0.9267,
      "step": 21390
    },
    {
      "epoch": 8.1,
      "learning_rate": 0.0001293989161594805,
      "loss": 0.9418,
      "step": 21400
    },
    {
      "epoch": 8.11,
      "learning_rate": 0.00012934206200868325,
      "loss": 0.9214,
      "step": 21410
    },
    {
      "epoch": 8.11,
      "learning_rate": 0.00012928519747797641,
      "loss": 0.9572,
      "step": 21420
    },
    {
      "epoch": 8.11,
      "learning_rate": 0.00012922832258747616,
      "loss": 0.9434,
      "step": 21430
    },
    {
      "epoch": 8.12,
      "learning_rate": 0.00012917143735730226,
      "loss": 0.9144,
      "step": 21440
    },
    {
      "epoch": 8.12,
      "learning_rate": 0.00012911454180757818,
      "loss": 0.9049,
      "step": 21450
    },
    {
      "epoch": 8.12,
      "learning_rate": 0.00012905763595843104,
      "loss": 0.8743,
      "step": 21460
    },
    {
      "epoch": 8.13,
      "learning_rate": 0.00012900071982999153,
      "loss": 0.9168,
      "step": 21470
    },
    {
      "epoch": 8.13,
      "learning_rate": 0.00012894379344239408,
      "loss": 0.9252,
      "step": 21480
    },
    {
      "epoch": 8.14,
      "learning_rate": 0.00012888685681577665,
      "loss": 0.957,
      "step": 21490
    },
    {
      "epoch": 8.14,
      "learning_rate": 0.00012882990997028097,
      "loss": 0.9299,
      "step": 21500
    },
    {
      "epoch": 8.14,
      "learning_rate": 0.00012877295292605217,
      "loss": 0.9313,
      "step": 21510
    },
    {
      "epoch": 8.15,
      "learning_rate": 0.00012871598570323917,
      "loss": 0.9465,
      "step": 21520
    },
    {
      "epoch": 8.15,
      "learning_rate": 0.00012865900832199445,
      "loss": 0.9744,
      "step": 21530
    },
    {
      "epoch": 8.16,
      "learning_rate": 0.000128602020802474,
      "loss": 0.9892,
      "step": 21540
    },
    {
      "epoch": 8.16,
      "learning_rate": 0.00012854502316483746,
      "loss": 0.9224,
      "step": 21550
    },
    {
      "epoch": 8.16,
      "learning_rate": 0.0001284880154292481,
      "loss": 0.9299,
      "step": 21560
    },
    {
      "epoch": 8.17,
      "learning_rate": 0.00012843099761587268,
      "loss": 0.8961,
      "step": 21570
    },
    {
      "epoch": 8.17,
      "learning_rate": 0.00012837396974488152,
      "loss": 0.9409,
      "step": 21580
    },
    {
      "epoch": 8.17,
      "learning_rate": 0.0001283169318364486,
      "loss": 1.0155,
      "step": 21590
    },
    {
      "epoch": 8.18,
      "learning_rate": 0.0001282598839107513,
      "loss": 0.9714,
      "step": 21600
    },
    {
      "epoch": 8.18,
      "learning_rate": 0.00012820282598797068,
      "loss": 0.9462,
      "step": 21610
    },
    {
      "epoch": 8.19,
      "learning_rate": 0.00012814575808829128,
      "loss": 0.9219,
      "step": 21620
    },
    {
      "epoch": 8.19,
      "learning_rate": 0.00012808868023190113,
      "loss": 0.9422,
      "step": 21630
    },
    {
      "epoch": 8.19,
      "learning_rate": 0.00012803159243899187,
      "loss": 0.9506,
      "step": 21640
    },
    {
      "epoch": 8.2,
      "learning_rate": 0.0001279744947297586,
      "loss": 0.9131,
      "step": 21650
    },
    {
      "epoch": 8.2,
      "learning_rate": 0.0001279173871243999,
      "loss": 0.9561,
      "step": 21660
    },
    {
      "epoch": 8.2,
      "learning_rate": 0.00012786026964311796,
      "loss": 0.9269,
      "step": 21670
    },
    {
      "epoch": 8.21,
      "learning_rate": 0.00012780314230611831,
      "loss": 0.904,
      "step": 21680
    },
    {
      "epoch": 8.21,
      "learning_rate": 0.0001277460051336101,
      "loss": 0.9532,
      "step": 21690
    },
    {
      "epoch": 8.22,
      "learning_rate": 0.00012768885814580592,
      "loss": 0.9611,
      "step": 21700
    },
    {
      "epoch": 8.22,
      "learning_rate": 0.00012763170136292172,
      "loss": 1.0167,
      "step": 21710
    },
    {
      "epoch": 8.22,
      "learning_rate": 0.00012757453480517712,
      "loss": 0.9843,
      "step": 21720
    },
    {
      "epoch": 8.23,
      "learning_rate": 0.00012751735849279508,
      "loss": 0.9367,
      "step": 21730
    },
    {
      "epoch": 8.23,
      "learning_rate": 0.00012746017244600198,
      "loss": 0.9452,
      "step": 21740
    },
    {
      "epoch": 8.23,
      "learning_rate": 0.00012740297668502768,
      "loss": 0.9407,
      "step": 21750
    },
    {
      "epoch": 8.24,
      "learning_rate": 0.0001273457712301055,
      "loss": 0.8961,
      "step": 21760
    },
    {
      "epoch": 8.24,
      "learning_rate": 0.00012728855610147222,
      "loss": 0.9247,
      "step": 21770
    },
    {
      "epoch": 8.25,
      "learning_rate": 0.00012723133131936794,
      "loss": 0.9938,
      "step": 21780
    },
    {
      "epoch": 8.25,
      "learning_rate": 0.00012717409690403625,
      "loss": 0.9553,
      "step": 21790
    },
    {
      "epoch": 8.25,
      "learning_rate": 0.0001271168528757241,
      "loss": 0.9357,
      "step": 21800
    },
    {
      "epoch": 8.26,
      "learning_rate": 0.0001270595992546819,
      "loss": 0.9754,
      "step": 21810
    },
    {
      "epoch": 8.26,
      "learning_rate": 0.00012700233606116344,
      "loss": 1.0447,
      "step": 21820
    },
    {
      "epoch": 8.27,
      "learning_rate": 0.0001269450633154258,
      "loss": 0.9176,
      "step": 21830
    },
    {
      "epoch": 8.27,
      "learning_rate": 0.0001268877810377296,
      "loss": 0.9441,
      "step": 21840
    },
    {
      "epoch": 8.27,
      "learning_rate": 0.00012683048924833868,
      "loss": 0.8999,
      "step": 21850
    },
    {
      "epoch": 8.28,
      "learning_rate": 0.00012677318796752035,
      "loss": 0.9489,
      "step": 21860
    },
    {
      "epoch": 8.28,
      "learning_rate": 0.00012671587721554522,
      "loss": 0.9751,
      "step": 21870
    },
    {
      "epoch": 8.28,
      "learning_rate": 0.00012665855701268734,
      "loss": 0.928,
      "step": 21880
    },
    {
      "epoch": 8.29,
      "learning_rate": 0.00012660122737922393,
      "loss": 0.9287,
      "step": 21890
    },
    {
      "epoch": 8.29,
      "learning_rate": 0.00012654388833543574,
      "loss": 1.0305,
      "step": 21900
    },
    {
      "epoch": 8.3,
      "learning_rate": 0.00012648653990160672,
      "loss": 0.9728,
      "step": 21910
    },
    {
      "epoch": 8.3,
      "learning_rate": 0.00012642918209802416,
      "loss": 1.0099,
      "step": 21920
    },
    {
      "epoch": 8.3,
      "learning_rate": 0.00012637181494497873,
      "loss": 0.9138,
      "step": 21930
    },
    {
      "epoch": 8.31,
      "learning_rate": 0.00012631443846276434,
      "loss": 1.0067,
      "step": 21940
    },
    {
      "epoch": 8.31,
      "learning_rate": 0.00012625705267167822,
      "loss": 0.9752,
      "step": 21950
    },
    {
      "epoch": 8.31,
      "learning_rate": 0.0001261996575920209,
      "loss": 1.0047,
      "step": 21960
    },
    {
      "epoch": 8.32,
      "learning_rate": 0.0001261422532440962,
      "loss": 0.929,
      "step": 21970
    },
    {
      "epoch": 8.32,
      "learning_rate": 0.00012608483964821122,
      "loss": 0.9964,
      "step": 21980
    },
    {
      "epoch": 8.33,
      "learning_rate": 0.00012602741682467633,
      "loss": 0.9432,
      "step": 21990
    },
    {
      "epoch": 8.33,
      "learning_rate": 0.00012596998479380512,
      "loss": 0.9759,
      "step": 22000
    },
    {
      "epoch": 8.33,
      "learning_rate": 0.0001259125435759145,
      "loss": 0.9883,
      "step": 22010
    },
    {
      "epoch": 8.34,
      "learning_rate": 0.0001258550931913246,
      "loss": 0.9789,
      "step": 22020
    },
    {
      "epoch": 8.34,
      "learning_rate": 0.0001257976336603588,
      "loss": 0.976,
      "step": 22030
    },
    {
      "epoch": 8.34,
      "learning_rate": 0.00012574016500334367,
      "loss": 0.9445,
      "step": 22040
    },
    {
      "epoch": 8.35,
      "learning_rate": 0.00012568268724060915,
      "loss": 0.928,
      "step": 22050
    },
    {
      "epoch": 8.35,
      "learning_rate": 0.00012562520039248822,
      "loss": 0.9831,
      "step": 22060
    },
    {
      "epoch": 8.36,
      "learning_rate": 0.00012556770447931715,
      "loss": 0.9449,
      "step": 22070
    },
    {
      "epoch": 8.36,
      "learning_rate": 0.0001255101995214355,
      "loss": 0.9585,
      "step": 22080
    },
    {
      "epoch": 8.36,
      "learning_rate": 0.00012545268553918587,
      "loss": 1.0169,
      "step": 22090
    },
    {
      "epoch": 8.37,
      "learning_rate": 0.0001253951625529142,
      "loss": 0.9665,
      "step": 22100
    },
    {
      "epoch": 8.37,
      "learning_rate": 0.0001253376305829695,
      "loss": 0.9873,
      "step": 22110
    },
    {
      "epoch": 8.37,
      "learning_rate": 0.00012528008964970405,
      "loss": 0.9961,
      "step": 22120
    },
    {
      "epoch": 8.38,
      "learning_rate": 0.00012522253977347323,
      "loss": 0.9662,
      "step": 22130
    },
    {
      "epoch": 8.38,
      "learning_rate": 0.0001251649809746356,
      "loss": 0.9716,
      "step": 22140
    },
    {
      "epoch": 8.39,
      "learning_rate": 0.00012510741327355292,
      "loss": 0.9168,
      "step": 22150
    },
    {
      "epoch": 8.39,
      "learning_rate": 0.0001250498366905901,
      "loss": 0.9009,
      "step": 22160
    },
    {
      "epoch": 8.39,
      "learning_rate": 0.00012499225124611507,
      "loss": 0.9292,
      "step": 22170
    },
    {
      "epoch": 8.4,
      "learning_rate": 0.00012493465696049907,
      "loss": 0.9524,
      "step": 22180
    },
    {
      "epoch": 8.4,
      "learning_rate": 0.00012487705385411633,
      "loss": 0.9277,
      "step": 22190
    },
    {
      "epoch": 8.41,
      "learning_rate": 0.00012481944194734428,
      "loss": 0.9693,
      "step": 22200
    },
    {
      "epoch": 8.41,
      "learning_rate": 0.00012476182126056341,
      "loss": 0.8959,
      "step": 22210
    },
    {
      "epoch": 8.41,
      "learning_rate": 0.0001247041918141574,
      "loss": 0.9353,
      "step": 22220
    },
    {
      "epoch": 8.42,
      "learning_rate": 0.00012464655362851292,
      "loss": 0.9319,
      "step": 22230
    },
    {
      "epoch": 8.42,
      "learning_rate": 0.00012458890672401978,
      "loss": 0.9828,
      "step": 22240
    },
    {
      "epoch": 8.42,
      "learning_rate": 0.00012453125112107092,
      "loss": 0.9476,
      "step": 22250
    },
    {
      "epoch": 8.43,
      "learning_rate": 0.00012447358684006225,
      "loss": 0.9588,
      "step": 22260
    },
    {
      "epoch": 8.43,
      "learning_rate": 0.00012441591390139288,
      "loss": 0.9299,
      "step": 22270
    },
    {
      "epoch": 8.44,
      "learning_rate": 0.0001243582323254649,
      "loss": 0.9439,
      "step": 22280
    },
    {
      "epoch": 8.44,
      "learning_rate": 0.00012430054213268343,
      "loss": 0.9558,
      "step": 22290
    },
    {
      "epoch": 8.44,
      "learning_rate": 0.00012424284334345672,
      "loss": 0.9568,
      "step": 22300
    },
    {
      "epoch": 8.45,
      "learning_rate": 0.00012418513597819603,
      "loss": 0.9784,
      "step": 22310
    },
    {
      "epoch": 8.45,
      "learning_rate": 0.00012412742005731562,
      "loss": 0.9565,
      "step": 22320
    },
    {
      "epoch": 8.45,
      "learning_rate": 0.00012406969560123282,
      "loss": 0.9869,
      "step": 22330
    },
    {
      "epoch": 8.46,
      "learning_rate": 0.00012401196263036793,
      "loss": 0.937,
      "step": 22340
    },
    {
      "epoch": 8.46,
      "learning_rate": 0.00012395422116514432,
      "loss": 0.9786,
      "step": 22350
    },
    {
      "epoch": 8.47,
      "learning_rate": 0.00012389647122598835,
      "loss": 0.9678,
      "step": 22360
    },
    {
      "epoch": 8.47,
      "learning_rate": 0.00012383871283332937,
      "loss": 1.0011,
      "step": 22370
    },
    {
      "epoch": 8.47,
      "learning_rate": 0.00012378094600759963,
      "loss": 0.9591,
      "step": 22380
    },
    {
      "epoch": 8.48,
      "learning_rate": 0.0001237231707692346,
      "loss": 0.9861,
      "step": 22390
    },
    {
      "epoch": 8.48,
      "learning_rate": 0.00012366538713867245,
      "loss": 0.9647,
      "step": 22400
    },
    {
      "epoch": 8.48,
      "learning_rate": 0.0001236075951363545,
      "loss": 0.9426,
      "step": 22410
    },
    {
      "epoch": 8.49,
      "learning_rate": 0.00012354979478272494,
      "loss": 0.9349,
      "step": 22420
    },
    {
      "epoch": 8.49,
      "learning_rate": 0.000123491986098231,
      "loss": 0.9795,
      "step": 22430
    },
    {
      "epoch": 8.5,
      "learning_rate": 0.0001234341691033228,
      "loss": 0.9675,
      "step": 22440
    },
    {
      "epoch": 8.5,
      "learning_rate": 0.00012337634381845338,
      "loss": 0.9857,
      "step": 22450
    },
    {
      "epoch": 8.5,
      "learning_rate": 0.0001233185102640787,
      "loss": 1.0077,
      "step": 22460
    },
    {
      "epoch": 8.51,
      "learning_rate": 0.0001232606684606578,
      "loss": 0.97,
      "step": 22470
    },
    {
      "epoch": 8.51,
      "learning_rate": 0.00012320281842865245,
      "loss": 0.9079,
      "step": 22480
    },
    {
      "epoch": 8.51,
      "learning_rate": 0.0001231449601885274,
      "loss": 0.9258,
      "step": 22490
    },
    {
      "epoch": 8.52,
      "learning_rate": 0.00012308709376075033,
      "loss": 0.9911,
      "step": 22500
    },
    {
      "epoch": 8.52,
      "learning_rate": 0.0001230292191657918,
      "loss": 0.934,
      "step": 22510
    },
    {
      "epoch": 8.53,
      "learning_rate": 0.00012297133642412522,
      "loss": 0.926,
      "step": 22520
    },
    {
      "epoch": 8.53,
      "learning_rate": 0.00012291344555622694,
      "loss": 0.9702,
      "step": 22530
    },
    {
      "epoch": 8.53,
      "learning_rate": 0.00012285554658257619,
      "loss": 0.9727,
      "step": 22540
    },
    {
      "epoch": 8.54,
      "learning_rate": 0.00012279763952365496,
      "loss": 0.9724,
      "step": 22550
    },
    {
      "epoch": 8.54,
      "learning_rate": 0.00012273972439994828,
      "loss": 0.9397,
      "step": 22560
    },
    {
      "epoch": 8.55,
      "learning_rate": 0.00012268180123194386,
      "loss": 0.9237,
      "step": 22570
    },
    {
      "epoch": 8.55,
      "learning_rate": 0.00012262387004013231,
      "loss": 0.9339,
      "step": 22580
    },
    {
      "epoch": 8.55,
      "learning_rate": 0.00012256593084500716,
      "loss": 0.9306,
      "step": 22590
    },
    {
      "epoch": 8.56,
      "learning_rate": 0.00012250798366706466,
      "loss": 0.9886,
      "step": 22600
    },
    {
      "epoch": 8.56,
      "learning_rate": 0.00012245002852680393,
      "loss": 0.9613,
      "step": 22610
    },
    {
      "epoch": 8.56,
      "learning_rate": 0.00012239206544472698,
      "loss": 0.9488,
      "step": 22620
    },
    {
      "epoch": 8.57,
      "learning_rate": 0.00012233409444133844,
      "loss": 0.9315,
      "step": 22630
    },
    {
      "epoch": 8.57,
      "learning_rate": 0.00012227611553714595,
      "loss": 1.0228,
      "step": 22640
    },
    {
      "epoch": 8.58,
      "learning_rate": 0.00012221812875265982,
      "loss": 0.9696,
      "step": 22650
    },
    {
      "epoch": 8.58,
      "learning_rate": 0.00012216013410839318,
      "loss": 0.9438,
      "step": 22660
    },
    {
      "epoch": 8.58,
      "learning_rate": 0.00012210213162486196,
      "loss": 0.9702,
      "step": 22670
    },
    {
      "epoch": 8.59,
      "learning_rate": 0.0001220441213225848,
      "loss": 0.9383,
      "step": 22680
    },
    {
      "epoch": 8.59,
      "learning_rate": 0.00012198610322208322,
      "loss": 0.947,
      "step": 22690
    },
    {
      "epoch": 8.59,
      "learning_rate": 0.00012192807734388134,
      "loss": 0.968,
      "step": 22700
    },
    {
      "epoch": 8.6,
      "learning_rate": 0.00012187004370850623,
      "loss": 0.9214,
      "step": 22710
    },
    {
      "epoch": 8.6,
      "learning_rate": 0.00012181200233648751,
      "loss": 0.9935,
      "step": 22720
    },
    {
      "epoch": 8.61,
      "learning_rate": 0.00012175395324835767,
      "loss": 0.9456,
      "step": 22730
    },
    {
      "epoch": 8.61,
      "learning_rate": 0.00012169589646465183,
      "loss": 0.987,
      "step": 22740
    },
    {
      "epoch": 8.61,
      "learning_rate": 0.00012163783200590792,
      "loss": 0.9664,
      "step": 22750
    },
    {
      "epoch": 8.62,
      "learning_rate": 0.0001215797598926666,
      "loss": 0.966,
      "step": 22760
    },
    {
      "epoch": 8.62,
      "learning_rate": 0.00012152168014547108,
      "loss": 0.9644,
      "step": 22770
    },
    {
      "epoch": 8.62,
      "learning_rate": 0.00012146359278486743,
      "loss": 0.969,
      "step": 22780
    },
    {
      "epoch": 8.63,
      "learning_rate": 0.0001214054978314044,
      "loss": 0.9506,
      "step": 22790
    },
    {
      "epoch": 8.63,
      "learning_rate": 0.00012134739530563332,
      "loss": 0.9692,
      "step": 22800
    },
    {
      "epoch": 8.64,
      "learning_rate": 0.00012128928522810827,
      "loss": 0.9649,
      "step": 22810
    },
    {
      "epoch": 8.64,
      "learning_rate": 0.00012123116761938608,
      "loss": 0.9362,
      "step": 22820
    },
    {
      "epoch": 8.64,
      "learning_rate": 0.00012117304250002605,
      "loss": 0.9459,
      "step": 22830
    },
    {
      "epoch": 8.65,
      "learning_rate": 0.00012111490989059033,
      "loss": 1.0069,
      "step": 22840
    },
    {
      "epoch": 8.65,
      "learning_rate": 0.00012105676981164362,
      "loss": 0.992,
      "step": 22850
    },
    {
      "epoch": 8.65,
      "learning_rate": 0.00012099862228375325,
      "loss": 1.0066,
      "step": 22860
    },
    {
      "epoch": 8.66,
      "learning_rate": 0.00012094046732748925,
      "loss": 1.0151,
      "step": 22870
    },
    {
      "epoch": 8.66,
      "learning_rate": 0.00012088230496342421,
      "loss": 0.9599,
      "step": 22880
    },
    {
      "epoch": 8.67,
      "learning_rate": 0.00012082413521213341,
      "loss": 0.9481,
      "step": 22890
    },
    {
      "epoch": 8.67,
      "learning_rate": 0.00012076595809419467,
      "loss": 0.9881,
      "step": 22900
    },
    {
      "epoch": 8.67,
      "learning_rate": 0.00012070777363018848,
      "loss": 0.9954,
      "step": 22910
    },
    {
      "epoch": 8.68,
      "learning_rate": 0.00012064958184069787,
      "loss": 0.9172,
      "step": 22920
    },
    {
      "epoch": 8.68,
      "learning_rate": 0.00012059138274630856,
      "loss": 0.9304,
      "step": 22930
    },
    {
      "epoch": 8.69,
      "learning_rate": 0.00012053317636760874,
      "loss": 0.9667,
      "step": 22940
    },
    {
      "epoch": 8.69,
      "learning_rate": 0.00012047496272518919,
      "loss": 0.9453,
      "step": 22950
    },
    {
      "epoch": 8.69,
      "learning_rate": 0.00012041674183964335,
      "loss": 0.9222,
      "step": 22960
    },
    {
      "epoch": 8.7,
      "learning_rate": 0.00012035851373156716,
      "loss": 0.9772,
      "step": 22970
    },
    {
      "epoch": 8.7,
      "learning_rate": 0.00012030027842155909,
      "loss": 0.9827,
      "step": 22980
    },
    {
      "epoch": 8.7,
      "learning_rate": 0.00012024203593022023,
      "loss": 0.974,
      "step": 22990
    },
    {
      "epoch": 8.71,
      "learning_rate": 0.00012018378627815414,
      "loss": 0.9501,
      "step": 23000
    },
    {
      "epoch": 8.71,
      "learning_rate": 0.00012012552948596693,
      "loss": 0.9674,
      "step": 23010
    },
    {
      "epoch": 8.72,
      "learning_rate": 0.00012006726557426729,
      "loss": 0.9235,
      "step": 23020
    },
    {
      "epoch": 8.72,
      "learning_rate": 0.00012000899456366636,
      "loss": 1.0094,
      "step": 23030
    },
    {
      "epoch": 8.72,
      "learning_rate": 0.0001199507164747778,
      "loss": 0.9029,
      "step": 23040
    },
    {
      "epoch": 8.73,
      "learning_rate": 0.00011989243132821784,
      "loss": 0.959,
      "step": 23050
    },
    {
      "epoch": 8.73,
      "learning_rate": 0.00011983413914460513,
      "loss": 0.9687,
      "step": 23060
    },
    {
      "epoch": 8.73,
      "learning_rate": 0.00011977583994456083,
      "loss": 0.984,
      "step": 23070
    },
    {
      "epoch": 8.74,
      "learning_rate": 0.00011971753374870862,
      "loss": 0.9507,
      "step": 23080
    },
    {
      "epoch": 8.74,
      "learning_rate": 0.0001196592205776746,
      "loss": 0.9646,
      "step": 23090
    },
    {
      "epoch": 8.75,
      "learning_rate": 0.00011960090045208736,
      "loss": 0.9478,
      "step": 23100
    },
    {
      "epoch": 8.75,
      "learning_rate": 0.00011954257339257797,
      "loss": 0.9706,
      "step": 23110
    },
    {
      "epoch": 8.75,
      "learning_rate": 0.00011948423941977994,
      "loss": 0.9502,
      "step": 23120
    },
    {
      "epoch": 8.76,
      "learning_rate": 0.00011942589855432917,
      "loss": 0.9711,
      "step": 23130
    },
    {
      "epoch": 8.76,
      "learning_rate": 0.00011936755081686412,
      "loss": 0.9795,
      "step": 23140
    },
    {
      "epoch": 8.76,
      "learning_rate": 0.00011930919622802556,
      "loss": 0.946,
      "step": 23150
    },
    {
      "epoch": 8.77,
      "learning_rate": 0.00011925083480845676,
      "loss": 0.9628,
      "step": 23160
    },
    {
      "epoch": 8.77,
      "learning_rate": 0.00011919246657880339,
      "loss": 0.9977,
      "step": 23170
    },
    {
      "epoch": 8.78,
      "learning_rate": 0.0001191340915597135,
      "loss": 0.9827,
      "step": 23180
    },
    {
      "epoch": 8.78,
      "learning_rate": 0.00011907570977183753,
      "loss": 0.9363,
      "step": 23190
    },
    {
      "epoch": 8.78,
      "learning_rate": 0.00011901732123582843,
      "loss": 0.9195,
      "step": 23200
    },
    {
      "epoch": 8.79,
      "learning_rate": 0.00011895892597234137,
      "loss": 0.9744,
      "step": 23210
    },
    {
      "epoch": 8.79,
      "learning_rate": 0.00011890052400203404,
      "loss": 0.9501,
      "step": 23220
    },
    {
      "epoch": 8.8,
      "learning_rate": 0.00011884211534556642,
      "loss": 0.9622,
      "step": 23230
    },
    {
      "epoch": 8.8,
      "learning_rate": 0.00011878370002360086,
      "loss": 0.9456,
      "step": 23240
    },
    {
      "epoch": 8.8,
      "learning_rate": 0.00011872527805680216,
      "loss": 0.9245,
      "step": 23250
    },
    {
      "epoch": 8.81,
      "learning_rate": 0.00011867269262243222,
      "loss": 0.9064,
      "step": 23260
    },
    {
      "epoch": 8.81,
      "learning_rate": 0.00011861425808739018,
      "loss": 0.9051,
      "step": 23270
    },
    {
      "epoch": 8.81,
      "learning_rate": 0.00011855581696745594,
      "loss": 0.9714,
      "step": 23280
    },
    {
      "epoch": 8.82,
      "learning_rate": 0.00011849736928330333,
      "loss": 1.0009,
      "step": 23290
    },
    {
      "epoch": 8.82,
      "learning_rate": 0.00011843891505560856,
      "loss": 0.9424,
      "step": 23300
    },
    {
      "epoch": 8.83,
      "learning_rate": 0.00011838045430505011,
      "loss": 0.9823,
      "step": 23310
    },
    {
      "epoch": 8.83,
      "learning_rate": 0.00011832198705230879,
      "loss": 0.994,
      "step": 23320
    },
    {
      "epoch": 8.83,
      "learning_rate": 0.00011826351331806769,
      "loss": 0.9589,
      "step": 23330
    },
    {
      "epoch": 8.84,
      "learning_rate": 0.00011820503312301218,
      "loss": 0.9824,
      "step": 23340
    },
    {
      "epoch": 8.84,
      "learning_rate": 0.00011814654648782997,
      "loss": 0.9703,
      "step": 23350
    },
    {
      "epoch": 8.84,
      "learning_rate": 0.000118088053433211,
      "loss": 0.9855,
      "step": 23360
    },
    {
      "epoch": 8.85,
      "learning_rate": 0.0001180295539798475,
      "loss": 0.9939,
      "step": 23370
    },
    {
      "epoch": 8.85,
      "learning_rate": 0.00011797104814843396,
      "loss": 0.9929,
      "step": 23380
    },
    {
      "epoch": 8.86,
      "learning_rate": 0.00011791253595966716,
      "loss": 0.952,
      "step": 23390
    },
    {
      "epoch": 8.86,
      "learning_rate": 0.00011785401743424605,
      "loss": 0.9736,
      "step": 23400
    },
    {
      "epoch": 8.86,
      "learning_rate": 0.00011779549259287185,
      "loss": 0.9364,
      "step": 23410
    },
    {
      "epoch": 8.87,
      "learning_rate": 0.00011773696145624813,
      "loss": 0.999,
      "step": 23420
    },
    {
      "epoch": 8.87,
      "learning_rate": 0.00011767842404508047,
      "loss": 0.9231,
      "step": 23430
    },
    {
      "epoch": 8.87,
      "learning_rate": 0.00011761988038007688,
      "loss": 1.0079,
      "step": 23440
    },
    {
      "epoch": 8.88,
      "learning_rate": 0.00011756133048194744,
      "loss": 0.9432,
      "step": 23450
    },
    {
      "epoch": 8.88,
      "learning_rate": 0.00011750277437140451,
      "loss": 1.0017,
      "step": 23460
    },
    {
      "epoch": 8.89,
      "learning_rate": 0.0001174442120691626,
      "loss": 0.9796,
      "step": 23470
    },
    {
      "epoch": 8.89,
      "learning_rate": 0.00011738564359593847,
      "loss": 1.0094,
      "step": 23480
    },
    {
      "epoch": 8.89,
      "learning_rate": 0.00011732706897245098,
      "loss": 0.9456,
      "step": 23490
    },
    {
      "epoch": 8.9,
      "learning_rate": 0.00011726848821942127,
      "loss": 0.9694,
      "step": 23500
    },
    {
      "epoch": 8.9,
      "learning_rate": 0.00011720990135757253,
      "loss": 0.9539,
      "step": 23510
    },
    {
      "epoch": 8.9,
      "learning_rate": 0.0001171513084076302,
      "loss": 0.9283,
      "step": 23520
    },
    {
      "epoch": 8.91,
      "learning_rate": 0.00011709270939032189,
      "loss": 0.9587,
      "step": 23530
    },
    {
      "epoch": 8.91,
      "learning_rate": 0.00011703410432637725,
      "loss": 0.93,
      "step": 23540
    },
    {
      "epoch": 8.92,
      "learning_rate": 0.00011697549323652812,
      "loss": 0.9872,
      "step": 23550
    },
    {
      "epoch": 8.92,
      "learning_rate": 0.00011691687614150855,
      "loss": 0.9801,
      "step": 23560
    },
    {
      "epoch": 8.92,
      "learning_rate": 0.00011685825306205463,
      "loss": 0.9431,
      "step": 23570
    },
    {
      "epoch": 8.93,
      "learning_rate": 0.00011679962401890452,
      "loss": 0.9908,
      "step": 23580
    },
    {
      "epoch": 8.93,
      "learning_rate": 0.0001167409890327986,
      "loss": 0.928,
      "step": 23590
    },
    {
      "epoch": 8.94,
      "learning_rate": 0.00011668234812447934,
      "loss": 0.9784,
      "step": 23600
    },
    {
      "epoch": 8.94,
      "learning_rate": 0.0001166237013146912,
      "loss": 0.985,
      "step": 23610
    },
    {
      "epoch": 8.94,
      "learning_rate": 0.00011656504862418085,
      "loss": 0.9688,
      "step": 23620
    },
    {
      "epoch": 8.95,
      "learning_rate": 0.00011650639007369699,
      "loss": 0.9598,
      "step": 23630
    },
    {
      "epoch": 8.95,
      "learning_rate": 0.0001164535923851346,
      "loss": 0.9752,
      "step": 23640
    },
    {
      "epoch": 8.95,
      "learning_rate": 0.00011639492275787114,
      "loss": 0.9664,
      "step": 23650
    },
    {
      "epoch": 8.96,
      "learning_rate": 0.00011633624733081703,
      "loss": 0.9794,
      "step": 23660
    },
    {
      "epoch": 8.96,
      "learning_rate": 0.00011627756612472911,
      "loss": 0.9274,
      "step": 23670
    },
    {
      "epoch": 8.97,
      "learning_rate": 0.00011621887916036611,
      "loss": 0.9244,
      "step": 23680
    },
    {
      "epoch": 8.97,
      "learning_rate": 0.00011616018645848885,
      "loss": 0.9791,
      "step": 23690
    },
    {
      "epoch": 8.97,
      "learning_rate": 0.00011610148803986018,
      "loss": 0.9495,
      "step": 23700
    },
    {
      "epoch": 8.98,
      "learning_rate": 0.00011604278392524504,
      "loss": 0.9999,
      "step": 23710
    },
    {
      "epoch": 8.98,
      "learning_rate": 0.00011598407413541023,
      "loss": 0.9296,
      "step": 23720
    },
    {
      "epoch": 8.98,
      "learning_rate": 0.00011592535869112471,
      "loss": 0.9532,
      "step": 23730
    },
    {
      "epoch": 8.99,
      "learning_rate": 0.00011586663761315937,
      "loss": 0.9804,
      "step": 23740
    },
    {
      "epoch": 8.99,
      "learning_rate": 0.00011580791092228706,
      "loss": 0.9734,
      "step": 23750
    },
    {
      "epoch": 9.0,
      "learning_rate": 0.00011574917863928273,
      "loss": 0.9729,
      "step": 23760
    },
    {
      "epoch": 9.0,
      "learning_rate": 0.0001156904407849232,
      "loss": 0.9533,
      "step": 23770
    },
    {
      "epoch": 9.0,
      "learning_rate": 0.00011563169737998725,
      "loss": 0.8654,
      "step": 23780
    },
    {
      "epoch": 9.01,
      "learning_rate": 0.00011557294844525575,
      "loss": 0.9001,
      "step": 23790
    },
    {
      "epoch": 9.01,
      "learning_rate": 0.00011551419400151138,
      "loss": 0.9465,
      "step": 23800
    },
    {
      "epoch": 9.01,
      "learning_rate": 0.00011545543406953887,
      "loss": 0.9425,
      "step": 23810
    },
    {
      "epoch": 9.02,
      "learning_rate": 0.00011539666867012489,
      "loss": 0.9376,
      "step": 23820
    },
    {
      "epoch": 9.02,
      "learning_rate": 0.00011533789782405792,
      "loss": 0.9045,
      "step": 23830
    },
    {
      "epoch": 9.03,
      "learning_rate": 0.00011527912155212852,
      "loss": 0.9624,
      "step": 23840
    },
    {
      "epoch": 9.03,
      "learning_rate": 0.00011522033987512912,
      "loss": 0.9739,
      "step": 23850
    },
    {
      "epoch": 9.03,
      "learning_rate": 0.000115161552813854,
      "loss": 0.9194,
      "step": 23860
    },
    {
      "epoch": 9.04,
      "learning_rate": 0.00011510276038909942,
      "loss": 0.9993,
      "step": 23870
    },
    {
      "epoch": 9.04,
      "learning_rate": 0.00011504396262166352,
      "loss": 0.8856,
      "step": 23880
    },
    {
      "epoch": 9.04,
      "learning_rate": 0.0001149851595323463,
      "loss": 0.8938,
      "step": 23890
    },
    {
      "epoch": 9.05,
      "learning_rate": 0.0001149263511419497,
      "loss": 1.0012,
      "step": 23900
    },
    {
      "epoch": 9.05,
      "learning_rate": 0.00011486753747127743,
      "loss": 0.9818,
      "step": 23910
    },
    {
      "epoch": 9.06,
      "learning_rate": 0.00011480871854113519,
      "loss": 0.8987,
      "step": 23920
    },
    {
      "epoch": 9.06,
      "learning_rate": 0.0001147498943723305,
      "loss": 0.9252,
      "step": 23930
    },
    {
      "epoch": 9.06,
      "learning_rate": 0.00011469106498567268,
      "loss": 0.9281,
      "step": 23940
    },
    {
      "epoch": 9.07,
      "learning_rate": 0.00011463223040197297,
      "loss": 0.9998,
      "step": 23950
    },
    {
      "epoch": 9.07,
      "learning_rate": 0.0001145733906420444,
      "loss": 0.9758,
      "step": 23960
    },
    {
      "epoch": 9.08,
      "learning_rate": 0.00011451454572670183,
      "loss": 0.9446,
      "step": 23970
    },
    {
      "epoch": 9.08,
      "learning_rate": 0.00011445569567676198,
      "loss": 0.8837,
      "step": 23980
    },
    {
      "epoch": 9.08,
      "learning_rate": 0.00011439684051304338,
      "loss": 0.9148,
      "step": 23990
    },
    {
      "epoch": 9.09,
      "learning_rate": 0.00011433798025636631,
      "loss": 0.9805,
      "step": 24000
    },
    {
      "epoch": 9.09,
      "learning_rate": 0.00011427911492755292,
      "loss": 0.9129,
      "step": 24010
    },
    {
      "epoch": 9.09,
      "learning_rate": 0.00011422024454742719,
      "loss": 0.9833,
      "step": 24020
    },
    {
      "epoch": 9.1,
      "learning_rate": 0.00011416136913681472,
      "loss": 0.909,
      "step": 24030
    },
    {
      "epoch": 9.1,
      "learning_rate": 0.00011410248871654308,
      "loss": 0.934,
      "step": 24040
    },
    {
      "epoch": 9.11,
      "learning_rate": 0.00011404360330744149,
      "loss": 0.8993,
      "step": 24050
    },
    {
      "epoch": 9.11,
      "learning_rate": 0.00011398471293034097,
      "loss": 0.9454,
      "step": 24060
    },
    {
      "epoch": 9.11,
      "learning_rate": 0.00011392581760607435,
      "loss": 0.9117,
      "step": 24070
    },
    {
      "epoch": 9.12,
      "learning_rate": 0.0001138669173554761,
      "loss": 0.9712,
      "step": 24080
    },
    {
      "epoch": 9.12,
      "learning_rate": 0.00011380801219938256,
      "loss": 0.8976,
      "step": 24090
    },
    {
      "epoch": 9.12,
      "learning_rate": 0.00011374910215863168,
      "loss": 0.962,
      "step": 24100
    },
    {
      "epoch": 9.13,
      "learning_rate": 0.00011369018725406327,
      "loss": 0.9239,
      "step": 24110
    },
    {
      "epoch": 9.13,
      "learning_rate": 0.00011363126750651867,
      "loss": 0.9127,
      "step": 24120
    },
    {
      "epoch": 9.14,
      "learning_rate": 0.00011357234293684116,
      "loss": 0.8759,
      "step": 24130
    },
    {
      "epoch": 9.14,
      "learning_rate": 0.00011351341356587562,
      "loss": 0.8765,
      "step": 24140
    },
    {
      "epoch": 9.14,
      "learning_rate": 0.00011345447941446852,
      "loss": 0.9232,
      "step": 24150
    },
    {
      "epoch": 9.15,
      "learning_rate": 0.00011339554050346826,
      "loss": 0.961,
      "step": 24160
    },
    {
      "epoch": 9.15,
      "learning_rate": 0.0001133365968537247,
      "loss": 0.9755,
      "step": 24170
    },
    {
      "epoch": 9.15,
      "learning_rate": 0.00011327764848608949,
      "loss": 0.9405,
      "step": 24180
    },
    {
      "epoch": 9.16,
      "learning_rate": 0.00011321869542141594,
      "loss": 0.9512,
      "step": 24190
    },
    {
      "epoch": 9.16,
      "learning_rate": 0.000113159737680559,
      "loss": 0.9339,
      "step": 24200
    },
    {
      "epoch": 9.17,
      "learning_rate": 0.0001131007752843753,
      "loss": 0.9064,
      "step": 24210
    },
    {
      "epoch": 9.17,
      "learning_rate": 0.00011304180825372308,
      "loss": 0.891,
      "step": 24220
    },
    {
      "epoch": 9.17,
      "learning_rate": 0.00011298283660946223,
      "loss": 0.956,
      "step": 24230
    },
    {
      "epoch": 9.18,
      "learning_rate": 0.0001129238603724543,
      "loss": 0.9402,
      "step": 24240
    },
    {
      "epoch": 9.18,
      "learning_rate": 0.00011286487956356247,
      "loss": 0.9402,
      "step": 24250
    },
    {
      "epoch": 9.19,
      "learning_rate": 0.00011280589420365142,
      "loss": 0.9931,
      "step": 24260
    },
    {
      "epoch": 9.19,
      "learning_rate": 0.00011274690431358763,
      "loss": 0.9258,
      "step": 24270
    },
    {
      "epoch": 9.19,
      "learning_rate": 0.00011268790991423908,
      "loss": 0.8838,
      "step": 24280
    },
    {
      "epoch": 9.2,
      "learning_rate": 0.00011262891102647524,
      "loss": 0.9195,
      "step": 24290
    },
    {
      "epoch": 9.2,
      "learning_rate": 0.00011256990767116745,
      "loss": 0.8962,
      "step": 24300
    },
    {
      "epoch": 9.2,
      "learning_rate": 0.00011251089986918832,
      "loss": 0.92,
      "step": 24310
    },
    {
      "epoch": 9.21,
      "learning_rate": 0.00011245188764141223,
      "loss": 0.8941,
      "step": 24320
    },
    {
      "epoch": 9.21,
      "learning_rate": 0.00011239287100871505,
      "loss": 0.9299,
      "step": 24330
    },
    {
      "epoch": 9.22,
      "learning_rate": 0.00011233384999197425,
      "loss": 0.9363,
      "step": 24340
    },
    {
      "epoch": 9.22,
      "learning_rate": 0.0001122748246120688,
      "loss": 0.9176,
      "step": 24350
    },
    {
      "epoch": 9.22,
      "learning_rate": 0.00011221579488987923,
      "loss": 0.9248,
      "step": 24360
    },
    {
      "epoch": 9.23,
      "learning_rate": 0.00011215676084628768,
      "loss": 0.9194,
      "step": 24370
    },
    {
      "epoch": 9.23,
      "learning_rate": 0.00011209772250217767,
      "loss": 0.9512,
      "step": 24380
    },
    {
      "epoch": 9.23,
      "learning_rate": 0.00011203867987843442,
      "loss": 0.8901,
      "step": 24390
    },
    {
      "epoch": 9.24,
      "learning_rate": 0.00011197963299594447,
      "loss": 0.961,
      "step": 24400
    },
    {
      "epoch": 9.24,
      "learning_rate": 0.00011192058187559602,
      "loss": 0.9288,
      "step": 24410
    },
    {
      "epoch": 9.25,
      "learning_rate": 0.00011186152653827875,
      "loss": 0.9629,
      "step": 24420
    },
    {
      "epoch": 9.25,
      "learning_rate": 0.00011180246700488372,
      "loss": 0.924,
      "step": 24430
    },
    {
      "epoch": 9.25,
      "learning_rate": 0.0001117434032963036,
      "loss": 0.9363,
      "step": 24440
    },
    {
      "epoch": 9.26,
      "learning_rate": 0.0001116843354334325,
      "loss": 0.9582,
      "step": 24450
    },
    {
      "epoch": 9.26,
      "learning_rate": 0.00011162526343716595,
      "loss": 0.9715,
      "step": 24460
    },
    {
      "epoch": 9.26,
      "learning_rate": 0.00011156618732840098,
      "loss": 0.899,
      "step": 24470
    },
    {
      "epoch": 9.27,
      "learning_rate": 0.00011150710712803615,
      "loss": 0.9751,
      "step": 24480
    },
    {
      "epoch": 9.27,
      "learning_rate": 0.00011144802285697131,
      "loss": 0.9777,
      "step": 24490
    },
    {
      "epoch": 9.28,
      "learning_rate": 0.00011138893453610785,
      "loss": 0.9425,
      "step": 24500
    },
    {
      "epoch": 9.28,
      "learning_rate": 0.0001113298421863486,
      "loss": 0.965,
      "step": 24510
    },
    {
      "epoch": 9.28,
      "learning_rate": 0.0001112707458285978,
      "loss": 0.9503,
      "step": 24520
    },
    {
      "epoch": 9.29,
      "learning_rate": 0.00011121164548376106,
      "loss": 0.9176,
      "step": 24530
    },
    {
      "epoch": 9.29,
      "learning_rate": 0.00011115254117274545,
      "loss": 1.0002,
      "step": 24540
    },
    {
      "epoch": 9.29,
      "learning_rate": 0.00011109343291645944,
      "loss": 0.9498,
      "step": 24550
    },
    {
      "epoch": 9.3,
      "learning_rate": 0.00011103432073581293,
      "loss": 0.9458,
      "step": 24560
    },
    {
      "epoch": 9.3,
      "learning_rate": 0.00011097520465171707,
      "loss": 0.9343,
      "step": 24570
    },
    {
      "epoch": 9.31,
      "learning_rate": 0.00011091608468508457,
      "loss": 0.9359,
      "step": 24580
    },
    {
      "epoch": 9.31,
      "learning_rate": 0.0001108569608568294,
      "loss": 0.9472,
      "step": 24590
    },
    {
      "epoch": 9.31,
      "learning_rate": 0.00011079783318786692,
      "loss": 0.9532,
      "step": 24600
    },
    {
      "epoch": 9.32,
      "learning_rate": 0.00011073870169911386,
      "loss": 0.9781,
      "step": 24610
    },
    {
      "epoch": 9.32,
      "learning_rate": 0.00011067956641148834,
      "loss": 0.99,
      "step": 24620
    },
    {
      "epoch": 9.33,
      "learning_rate": 0.00011062042734590971,
      "loss": 0.9196,
      "step": 24630
    },
    {
      "epoch": 9.33,
      "learning_rate": 0.00011056128452329878,
      "loss": 0.969,
      "step": 24640
    },
    {
      "epoch": 9.33,
      "learning_rate": 0.0001105021379645776,
      "loss": 0.948,
      "step": 24650
    },
    {
      "epoch": 9.34,
      "learning_rate": 0.00011044298769066959,
      "loss": 0.9304,
      "step": 24660
    },
    {
      "epoch": 9.34,
      "learning_rate": 0.0001103838337224995,
      "loss": 0.9336,
      "step": 24670
    },
    {
      "epoch": 9.34,
      "learning_rate": 0.00011032467608099331,
      "loss": 1.0121,
      "step": 24680
    },
    {
      "epoch": 9.35,
      "learning_rate": 0.00011026551478707838,
      "loss": 0.9647,
      "step": 24690
    },
    {
      "epoch": 9.35,
      "learning_rate": 0.00011020634986168335,
      "loss": 0.9603,
      "step": 24700
    },
    {
      "epoch": 9.36,
      "learning_rate": 0.00011014718132573805,
      "loss": 1.0151,
      "step": 24710
    },
    {
      "epoch": 9.36,
      "learning_rate": 0.00011008800920017372,
      "loss": 0.9968,
      "step": 24720
    },
    {
      "epoch": 9.36,
      "learning_rate": 0.00011002883350592283,
      "loss": 0.9082,
      "step": 24730
    },
    {
      "epoch": 9.37,
      "learning_rate": 0.0001099696542639191,
      "loss": 0.9085,
      "step": 24740
    },
    {
      "epoch": 9.37,
      "learning_rate": 0.00010991047149509738,
      "loss": 0.8987,
      "step": 24750
    },
    {
      "epoch": 9.37,
      "learning_rate": 0.00010985128522039403,
      "loss": 0.9369,
      "step": 24760
    },
    {
      "epoch": 9.38,
      "learning_rate": 0.00010979209546074647,
      "loss": 0.9596,
      "step": 24770
    },
    {
      "epoch": 9.38,
      "learning_rate": 0.00010973290223709334,
      "loss": 0.9525,
      "step": 24780
    },
    {
      "epoch": 9.39,
      "learning_rate": 0.00010967370557037459,
      "loss": 0.9141,
      "step": 24790
    },
    {
      "epoch": 9.39,
      "learning_rate": 0.00010961450548153139,
      "loss": 0.9411,
      "step": 24800
    },
    {
      "epoch": 9.39,
      "learning_rate": 0.00010955530199150598,
      "loss": 0.9936,
      "step": 24810
    },
    {
      "epoch": 9.4,
      "learning_rate": 0.00010949609512124202,
      "loss": 0.9817,
      "step": 24820
    },
    {
      "epoch": 9.4,
      "learning_rate": 0.00010943688489168422,
      "loss": 0.9391,
      "step": 24830
    },
    {
      "epoch": 9.4,
      "learning_rate": 0.00010937767132377847,
      "loss": 0.8898,
      "step": 24840
    },
    {
      "epoch": 9.41,
      "learning_rate": 0.00010931845443847193,
      "loss": 0.9186,
      "step": 24850
    },
    {
      "epoch": 9.41,
      "learning_rate": 0.00010925923425671286,
      "loss": 0.9273,
      "step": 24860
    },
    {
      "epoch": 9.42,
      "learning_rate": 0.00010920001079945073,
      "loss": 0.9234,
      "step": 24870
    },
    {
      "epoch": 9.42,
      "learning_rate": 0.00010914078408763613,
      "loss": 0.9562,
      "step": 24880
    },
    {
      "epoch": 9.42,
      "learning_rate": 0.00010908155414222083,
      "loss": 0.9285,
      "step": 24890
    },
    {
      "epoch": 9.43,
      "learning_rate": 0.00010902232098415774,
      "loss": 0.9036,
      "step": 24900
    },
    {
      "epoch": 9.43,
      "learning_rate": 0.00010896308463440095,
      "loss": 0.9342,
      "step": 24910
    },
    {
      "epoch": 9.43,
      "learning_rate": 0.00010890384511390554,
      "loss": 0.9614,
      "step": 24920
    },
    {
      "epoch": 9.44,
      "learning_rate": 0.00010884460244362784,
      "loss": 0.9071,
      "step": 24930
    },
    {
      "epoch": 9.44,
      "learning_rate": 0.00010878535664452531,
      "loss": 0.963,
      "step": 24940
    },
    {
      "epoch": 9.45,
      "learning_rate": 0.0001087261077375564,
      "loss": 0.9591,
      "step": 24950
    },
    {
      "epoch": 9.45,
      "learning_rate": 0.00010866685574368074,
      "loss": 0.9208,
      "step": 24960
    },
    {
      "epoch": 9.45,
      "learning_rate": 0.00010860760068385907,
      "loss": 0.9237,
      "step": 24970
    },
    {
      "epoch": 9.46,
      "learning_rate": 0.0001085483425790531,
      "loss": 0.9074,
      "step": 24980
    },
    {
      "epoch": 9.46,
      "learning_rate": 0.00010848908145022581,
      "loss": 0.9381,
      "step": 24990
    },
    {
      "epoch": 9.47,
      "learning_rate": 0.00010842981731834103,
      "loss": 0.9342,
      "step": 25000
    },
    {
      "epoch": 9.47,
      "learning_rate": 0.00010837055020436382,
      "loss": 0.9553,
      "step": 25010
    },
    {
      "epoch": 9.47,
      "learning_rate": 0.00010831128012926026,
      "loss": 1.0159,
      "step": 25020
    },
    {
      "epoch": 9.48,
      "learning_rate": 0.00010825200711399737,
      "loss": 0.9631,
      "step": 25030
    },
    {
      "epoch": 9.48,
      "learning_rate": 0.00010819273117954334,
      "loss": 0.9957,
      "step": 25040
    },
    {
      "epoch": 9.48,
      "learning_rate": 0.00010813345234686738,
      "loss": 0.921,
      "step": 25050
    },
    {
      "epoch": 9.49,
      "learning_rate": 0.00010807417063693963,
      "loss": 0.9738,
      "step": 25060
    },
    {
      "epoch": 9.49,
      "learning_rate": 0.00010801488607073131,
      "loss": 0.9924,
      "step": 25070
    },
    {
      "epoch": 9.5,
      "learning_rate": 0.00010795559866921473,
      "loss": 0.9385,
      "step": 25080
    },
    {
      "epoch": 9.5,
      "learning_rate": 0.000107896308453363,
      "loss": 0.9452,
      "step": 25090
    },
    {
      "epoch": 9.5,
      "learning_rate": 0.00010783701544415044,
      "loss": 0.9565,
      "step": 25100
    },
    {
      "epoch": 9.51,
      "learning_rate": 0.00010777771966255223,
      "loss": 0.952,
      "step": 25110
    },
    {
      "epoch": 9.51,
      "learning_rate": 0.00010771842112954458,
      "loss": 0.9412,
      "step": 25120
    },
    {
      "epoch": 9.51,
      "learning_rate": 0.00010765911986610464,
      "loss": 0.9692,
      "step": 25130
    },
    {
      "epoch": 9.52,
      "learning_rate": 0.00010759981589321055,
      "loss": 0.9692,
      "step": 25140
    },
    {
      "epoch": 9.52,
      "learning_rate": 0.00010754050923184142,
      "loss": 0.9459,
      "step": 25150
    },
    {
      "epoch": 9.53,
      "learning_rate": 0.00010748119990297729,
      "loss": 0.9782,
      "step": 25160
    },
    {
      "epoch": 9.53,
      "learning_rate": 0.00010742188792759912,
      "loss": 0.9676,
      "step": 25170
    },
    {
      "epoch": 9.53,
      "learning_rate": 0.00010736257332668889,
      "loss": 0.9603,
      "step": 25180
    },
    {
      "epoch": 9.54,
      "learning_rate": 0.00010730325612122942,
      "loss": 0.9365,
      "step": 25190
    },
    {
      "epoch": 9.54,
      "learning_rate": 0.00010724393633220448,
      "loss": 0.9431,
      "step": 25200
    },
    {
      "epoch": 9.54,
      "learning_rate": 0.00010718461398059874,
      "loss": 0.9614,
      "step": 25210
    },
    {
      "epoch": 9.55,
      "learning_rate": 0.00010712528908739785,
      "loss": 0.9666,
      "step": 25220
    },
    {
      "epoch": 9.55,
      "learning_rate": 0.00010706596167358829,
      "loss": 0.9113,
      "step": 25230
    },
    {
      "epoch": 9.56,
      "learning_rate": 0.00010700663176015737,
      "loss": 0.9135,
      "step": 25240
    },
    {
      "epoch": 9.56,
      "learning_rate": 0.00010694729936809348,
      "loss": 0.9977,
      "step": 25250
    },
    {
      "epoch": 9.56,
      "learning_rate": 0.00010688796451838571,
      "loss": 0.9343,
      "step": 25260
    },
    {
      "epoch": 9.57,
      "learning_rate": 0.00010682862723202407,
      "loss": 0.8728,
      "step": 25270
    },
    {
      "epoch": 9.57,
      "learning_rate": 0.00010676928752999944,
      "loss": 0.96,
      "step": 25280
    },
    {
      "epoch": 9.58,
      "learning_rate": 0.00010670994543330357,
      "loss": 0.9756,
      "step": 25290
    },
    {
      "epoch": 9.58,
      "learning_rate": 0.000106650600962929,
      "loss": 0.9654,
      "step": 25300
    },
    {
      "epoch": 9.58,
      "learning_rate": 0.0001065912541398692,
      "loss": 0.9378,
      "step": 25310
    },
    {
      "epoch": 9.59,
      "learning_rate": 0.00010653190498511842,
      "loss": 0.9998,
      "step": 25320
    },
    {
      "epoch": 9.59,
      "learning_rate": 0.00010647255351967169,
      "loss": 0.9838,
      "step": 25330
    },
    {
      "epoch": 9.59,
      "learning_rate": 0.00010641319976452495,
      "loss": 0.9375,
      "step": 25340
    },
    {
      "epoch": 9.6,
      "learning_rate": 0.00010635384374067489,
      "loss": 0.9265,
      "step": 25350
    },
    {
      "epoch": 9.6,
      "learning_rate": 0.000106294485469119,
      "loss": 0.9454,
      "step": 25360
    },
    {
      "epoch": 9.61,
      "learning_rate": 0.00010623512497085562,
      "loss": 0.9383,
      "step": 25370
    },
    {
      "epoch": 9.61,
      "learning_rate": 0.00010617576226688377,
      "loss": 0.9584,
      "step": 25380
    },
    {
      "epoch": 9.61,
      "learning_rate": 0.00010611639737820342,
      "loss": 0.9125,
      "step": 25390
    },
    {
      "epoch": 9.62,
      "learning_rate": 0.00010605703032581517,
      "loss": 0.9415,
      "step": 25400
    },
    {
      "epoch": 9.62,
      "learning_rate": 0.00010599766113072041,
      "loss": 0.9971,
      "step": 25410
    },
    {
      "epoch": 9.62,
      "learning_rate": 0.00010593828981392129,
      "loss": 0.969,
      "step": 25420
    },
    {
      "epoch": 9.63,
      "learning_rate": 0.00010587891639642077,
      "loss": 0.9312,
      "step": 25430
    },
    {
      "epoch": 9.63,
      "learning_rate": 0.0001058195408992225,
      "loss": 0.9258,
      "step": 25440
    },
    {
      "epoch": 9.64,
      "learning_rate": 0.00010576016334333085,
      "loss": 0.9325,
      "step": 25450
    },
    {
      "epoch": 9.64,
      "learning_rate": 0.000105700783749751,
      "loss": 0.9875,
      "step": 25460
    },
    {
      "epoch": 9.64,
      "learning_rate": 0.00010564140213948874,
      "loss": 0.9732,
      "step": 25470
    },
    {
      "epoch": 9.65,
      "learning_rate": 0.00010558201853355068,
      "loss": 0.9499,
      "step": 25480
    },
    {
      "epoch": 9.65,
      "learning_rate": 0.000105522632952944,
      "loss": 0.918,
      "step": 25490
    },
    {
      "epoch": 9.65,
      "learning_rate": 0.00010546324541867673,
      "loss": 0.956,
      "step": 25500
    },
    {
      "epoch": 9.66,
      "learning_rate": 0.00010540385595175755,
      "loss": 0.9868,
      "step": 25510
    },
    {
      "epoch": 9.66,
      "learning_rate": 0.00010534446457319574,
      "loss": 0.9051,
      "step": 25520
    },
    {
      "epoch": 9.67,
      "learning_rate": 0.0001052850713040013,
      "loss": 0.9152,
      "step": 25530
    },
    {
      "epoch": 9.67,
      "learning_rate": 0.000105225676165185,
      "loss": 1.0032,
      "step": 25540
    },
    {
      "epoch": 9.67,
      "learning_rate": 0.00010516627917775808,
      "loss": 0.9786,
      "step": 25550
    },
    {
      "epoch": 9.68,
      "learning_rate": 0.00010510688036273259,
      "loss": 0.9307,
      "step": 25560
    },
    {
      "epoch": 9.68,
      "learning_rate": 0.00010504747974112122,
      "loss": 0.956,
      "step": 25570
    },
    {
      "epoch": 9.68,
      "learning_rate": 0.00010498807733393716,
      "loss": 0.9729,
      "step": 25580
    },
    {
      "epoch": 9.69,
      "learning_rate": 0.00010492867316219439,
      "loss": 0.9548,
      "step": 25590
    },
    {
      "epoch": 9.69,
      "learning_rate": 0.00010486926724690747,
      "loss": 0.9966,
      "step": 25600
    },
    {
      "epoch": 9.7,
      "learning_rate": 0.00010480985960909146,
      "loss": 0.921,
      "step": 25610
    },
    {
      "epoch": 9.7,
      "learning_rate": 0.00010475045026976223,
      "loss": 0.9392,
      "step": 25620
    },
    {
      "epoch": 9.7,
      "learning_rate": 0.00010469103924993608,
      "loss": 0.9554,
      "step": 25630
    },
    {
      "epoch": 9.71,
      "learning_rate": 0.00010463162657063,
      "loss": 0.9169,
      "step": 25640
    },
    {
      "epoch": 9.71,
      "learning_rate": 0.00010457221225286153,
      "loss": 0.9175,
      "step": 25650
    },
    {
      "epoch": 9.72,
      "learning_rate": 0.0001045127963176488,
      "loss": 0.9238,
      "step": 25660
    },
    {
      "epoch": 9.72,
      "learning_rate": 0.00010445337878601052,
      "loss": 0.931,
      "step": 25670
    },
    {
      "epoch": 9.72,
      "learning_rate": 0.00010439990165996466,
      "loss": 0.941,
      "step": 25680
    },
    {
      "epoch": 9.73,
      "learning_rate": 0.00010434048115302635,
      "loss": 0.9617,
      "step": 25690
    },
    {
      "epoch": 9.73,
      "learning_rate": 0.0001042810591106199,
      "loss": 0.9323,
      "step": 25700
    },
    {
      "epoch": 9.73,
      "learning_rate": 0.00010422163555376617,
      "loss": 0.9425,
      "step": 25710
    },
    {
      "epoch": 9.74,
      "learning_rate": 0.00010416221050348652,
      "loss": 0.9657,
      "step": 25720
    },
    {
      "epoch": 9.74,
      "learning_rate": 0.00010410278398080292,
      "loss": 0.8929,
      "step": 25730
    },
    {
      "epoch": 9.75,
      "learning_rate": 0.00010404335600673781,
      "loss": 0.97,
      "step": 25740
    },
    {
      "epoch": 9.75,
      "learning_rate": 0.00010398392660231408,
      "loss": 0.943,
      "step": 25750
    },
    {
      "epoch": 9.75,
      "learning_rate": 0.00010392449578855531,
      "loss": 0.9277,
      "step": 25760
    },
    {
      "epoch": 9.76,
      "learning_rate": 0.00010386506358648538,
      "loss": 0.9891,
      "step": 25770
    },
    {
      "epoch": 9.76,
      "learning_rate": 0.00010380563001712877,
      "loss": 0.9427,
      "step": 25780
    },
    {
      "epoch": 9.76,
      "learning_rate": 0.00010374619510151047,
      "loss": 0.9183,
      "step": 25790
    },
    {
      "epoch": 9.77,
      "learning_rate": 0.00010368675886065582,
      "loss": 1.0032,
      "step": 25800
    },
    {
      "epoch": 9.77,
      "learning_rate": 0.0001036273213155907,
      "loss": 0.9479,
      "step": 25810
    },
    {
      "epoch": 9.78,
      "learning_rate": 0.00010356788248734151,
      "loss": 0.9688,
      "step": 25820
    },
    {
      "epoch": 9.78,
      "learning_rate": 0.00010350844239693504,
      "loss": 0.9395,
      "step": 25830
    },
    {
      "epoch": 9.78,
      "learning_rate": 0.0001034490010653985,
      "loss": 0.8963,
      "step": 25840
    },
    {
      "epoch": 9.79,
      "learning_rate": 0.00010338955851375962,
      "loss": 0.9188,
      "step": 25850
    },
    {
      "epoch": 9.79,
      "learning_rate": 0.00010333011476304648,
      "loss": 0.9013,
      "step": 25860
    },
    {
      "epoch": 9.79,
      "learning_rate": 0.00010327066983428767,
      "loss": 0.9757,
      "step": 25870
    },
    {
      "epoch": 9.8,
      "learning_rate": 0.00010321122374851208,
      "loss": 0.9619,
      "step": 25880
    },
    {
      "epoch": 9.8,
      "learning_rate": 0.00010315177652674913,
      "loss": 1.0036,
      "step": 25890
    },
    {
      "epoch": 9.81,
      "learning_rate": 0.00010309232819002856,
      "loss": 0.9565,
      "step": 25900
    },
    {
      "epoch": 9.81,
      "learning_rate": 0.00010303287875938057,
      "loss": 0.9655,
      "step": 25910
    },
    {
      "epoch": 9.81,
      "learning_rate": 0.00010297342825583565,
      "loss": 0.9484,
      "step": 25920
    },
    {
      "epoch": 9.82,
      "learning_rate": 0.00010291397670042477,
      "loss": 0.9454,
      "step": 25930
    },
    {
      "epoch": 9.82,
      "learning_rate": 0.00010285452411417926,
      "loss": 0.9928,
      "step": 25940
    },
    {
      "epoch": 9.82,
      "learning_rate": 0.0001027950705181307,
      "loss": 0.9674,
      "step": 25950
    },
    {
      "epoch": 9.83,
      "learning_rate": 0.00010273561593331123,
      "loss": 0.9141,
      "step": 25960
    },
    {
      "epoch": 9.83,
      "learning_rate": 0.00010267616038075314,
      "loss": 0.9493,
      "step": 25970
    },
    {
      "epoch": 9.84,
      "learning_rate": 0.00010261670388148914,
      "loss": 0.9705,
      "step": 25980
    },
    {
      "epoch": 9.84,
      "learning_rate": 0.00010255724645655231,
      "loss": 0.976,
      "step": 25990
    },
    {
      "epoch": 9.84,
      "learning_rate": 0.00010249778812697608,
      "loss": 0.9806,
      "step": 26000
    },
    {
      "epoch": 9.85,
      "learning_rate": 0.00010243832891379404,
      "loss": 1.0243,
      "step": 26010
    },
    {
      "epoch": 9.85,
      "learning_rate": 0.00010237886883804027,
      "loss": 0.9941,
      "step": 26020
    },
    {
      "epoch": 9.86,
      "learning_rate": 0.0001023194079207491,
      "loss": 1.0245,
      "step": 26030
    },
    {
      "epoch": 9.86,
      "learning_rate": 0.00010225994618295506,
      "loss": 1.0132,
      "step": 26040
    },
    {
      "epoch": 9.86,
      "learning_rate": 0.00010220048364569317,
      "loss": 0.9092,
      "step": 26050
    },
    {
      "epoch": 9.87,
      "learning_rate": 0.00010214102032999853,
      "loss": 0.9706,
      "step": 26060
    },
    {
      "epoch": 9.87,
      "learning_rate": 0.00010208155625690661,
      "loss": 1.0045,
      "step": 26070
    },
    {
      "epoch": 9.87,
      "learning_rate": 0.0001020220914474532,
      "loss": 0.9284,
      "step": 26080
    },
    {
      "epoch": 9.88,
      "learning_rate": 0.00010196262592267423,
      "loss": 0.9514,
      "step": 26090
    },
    {
      "epoch": 9.88,
      "learning_rate": 0.00010190315970360596,
      "loss": 0.9902,
      "step": 26100
    },
    {
      "epoch": 9.89,
      "learning_rate": 0.0001018436928112849,
      "loss": 0.9544,
      "step": 26110
    },
    {
      "epoch": 9.89,
      "learning_rate": 0.00010178422526674773,
      "loss": 0.9783,
      "step": 26120
    },
    {
      "epoch": 9.89,
      "learning_rate": 0.00010172475709103145,
      "loss": 0.9344,
      "step": 26130
    },
    {
      "epoch": 9.9,
      "learning_rate": 0.00010166528830517326,
      "loss": 0.9435,
      "step": 26140
    },
    {
      "epoch": 9.9,
      "learning_rate": 0.00010160581893021048,
      "loss": 0.9466,
      "step": 26150
    },
    {
      "epoch": 9.9,
      "learning_rate": 0.00010154634898718078,
      "loss": 0.9328,
      "step": 26160
    },
    {
      "epoch": 9.91,
      "learning_rate": 0.000101486878497122,
      "loss": 0.9795,
      "step": 26170
    },
    {
      "epoch": 9.91,
      "learning_rate": 0.00010142740748107203,
      "loss": 0.9508,
      "step": 26180
    },
    {
      "epoch": 9.92,
      "learning_rate": 0.00010136793596006915,
      "loss": 0.955,
      "step": 26190
    },
    {
      "epoch": 9.92,
      "learning_rate": 0.00010130846395515168,
      "loss": 0.9772,
      "step": 26200
    },
    {
      "epoch": 9.92,
      "learning_rate": 0.00010124899148735816,
      "loss": 0.9702,
      "step": 26210
    },
    {
      "epoch": 9.93,
      "learning_rate": 0.00010118951857772733,
      "loss": 0.9425,
      "step": 26220
    },
    {
      "epoch": 9.93,
      "learning_rate": 0.00010113004524729799,
      "loss": 0.9601,
      "step": 26230
    },
    {
      "epoch": 9.93,
      "learning_rate": 0.00010107057151710917,
      "loss": 0.9343,
      "step": 26240
    },
    {
      "epoch": 9.94,
      "learning_rate": 0.00010101109740820002,
      "loss": 0.9967,
      "step": 26250
    },
    {
      "epoch": 9.94,
      "learning_rate": 0.0001009516229416098,
      "loss": 0.9646,
      "step": 26260
    },
    {
      "epoch": 9.95,
      "learning_rate": 0.00010089214813837796,
      "loss": 0.9962,
      "step": 26270
    },
    {
      "epoch": 9.95,
      "learning_rate": 0.000100832673019544,
      "loss": 0.8624,
      "step": 26280
    },
    {
      "epoch": 9.95,
      "learning_rate": 0.00010077319760614754,
      "loss": 0.9484,
      "step": 26290
    },
    {
      "epoch": 9.96,
      "learning_rate": 0.00010071372191922832,
      "loss": 0.9646,
      "step": 26300
    },
    {
      "epoch": 9.96,
      "learning_rate": 0.00010065424597982625,
      "loss": 0.9653,
      "step": 26310
    },
    {
      "epoch": 9.96,
      "learning_rate": 0.00010059476980898117,
      "loss": 0.9578,
      "step": 26320
    },
    {
      "epoch": 9.97,
      "learning_rate": 0.00010053529342773316,
      "loss": 0.9813,
      "step": 26330
    },
    {
      "epoch": 9.97,
      "learning_rate": 0.00010047581685712222,
      "loss": 0.9663,
      "step": 26340
    },
    {
      "epoch": 9.98,
      "learning_rate": 0.00010041634011818857,
      "loss": 0.9695,
      "step": 26350
    },
    {
      "epoch": 9.98,
      "learning_rate": 0.00010035686323197242,
      "loss": 0.9334,
      "step": 26360
    },
    {
      "epoch": 9.98,
      "learning_rate": 0.00010029738621951402,
      "loss": 0.9377,
      "step": 26370
    },
    {
      "epoch": 9.99,
      "learning_rate": 0.00010023790910185362,
      "loss": 0.9403,
      "step": 26380
    },
    {
      "epoch": 9.99,
      "learning_rate": 0.00010017843190003166,
      "loss": 0.9775,
      "step": 26390
    },
    {
      "epoch": 10.0,
      "learning_rate": 0.00010011895463508849,
      "loss": 0.975,
      "step": 26400
    },
    {
      "epoch": 10.0,
      "learning_rate": 0.00010005947732806444,
      "loss": 1.0084,
      "step": 26410
    },
    {
      "epoch": 10.0,
      "learning_rate": 0.0001,
      "loss": 0.9472,
      "step": 26420
    },
    {
      "epoch": 10.01,
      "learning_rate": 9.994052267193555e-05,
      "loss": 0.9021,
      "step": 26430
    },
    {
      "epoch": 10.01,
      "learning_rate": 9.988104536491155e-05,
      "loss": 0.9055,
      "step": 26440
    },
    {
      "epoch": 10.01,
      "learning_rate": 9.982156809996835e-05,
      "loss": 0.9501,
      "step": 26450
    },
    {
      "epoch": 10.02,
      "learning_rate": 9.976209089814636e-05,
      "loss": 0.9364,
      "step": 26460
    },
    {
      "epoch": 10.02,
      "learning_rate": 9.970261378048602e-05,
      "loss": 0.9673,
      "step": 26470
    },
    {
      "epoch": 10.03,
      "learning_rate": 9.96431367680276e-05,
      "loss": 0.9658,
      "step": 26480
    },
    {
      "epoch": 10.03,
      "learning_rate": 9.958365988181145e-05,
      "loss": 0.8643,
      "step": 26490
    },
    {
      "epoch": 10.03,
      "learning_rate": 9.95241831428778e-05,
      "loss": 0.8873,
      "step": 26500
    },
    {
      "epoch": 10.04,
      "learning_rate": 9.946470657226688e-05,
      "loss": 0.9316,
      "step": 26510
    },
    {
      "epoch": 10.04,
      "learning_rate": 9.940523019101885e-05,
      "loss": 0.9,
      "step": 26520
    },
    {
      "epoch": 10.04,
      "learning_rate": 9.934575402017378e-05,
      "loss": 0.9293,
      "step": 26530
    },
    {
      "epoch": 10.05,
      "learning_rate": 9.928627808077166e-05,
      "loss": 0.931,
      "step": 26540
    },
    {
      "epoch": 10.05,
      "learning_rate": 9.92268023938525e-05,
      "loss": 0.9178,
      "step": 26550
    },
    {
      "epoch": 10.06,
      "learning_rate": 9.916732698045604e-05,
      "loss": 0.8977,
      "step": 26560
    },
    {
      "epoch": 10.06,
      "learning_rate": 9.910785186162205e-05,
      "loss": 0.9539,
      "step": 26570
    },
    {
      "epoch": 10.06,
      "learning_rate": 9.904837705839021e-05,
      "loss": 1.0,
      "step": 26580
    },
    {
      "epoch": 10.07,
      "learning_rate": 9.89889025918e-05,
      "loss": 0.8944,
      "step": 26590
    },
    {
      "epoch": 10.07,
      "learning_rate": 9.892942848289084e-05,
      "loss": 0.9403,
      "step": 26600
    },
    {
      "epoch": 10.07,
      "learning_rate": 9.886995475270205e-05,
      "loss": 0.9102,
      "step": 26610
    },
    {
      "epoch": 10.08,
      "learning_rate": 9.881048142227269e-05,
      "loss": 0.8482,
      "step": 26620
    },
    {
      "epoch": 10.08,
      "learning_rate": 9.875100851264186e-05,
      "loss": 1.0161,
      "step": 26630
    },
    {
      "epoch": 10.09,
      "learning_rate": 9.869153604484834e-05,
      "loss": 0.875,
      "step": 26640
    },
    {
      "epoch": 10.09,
      "learning_rate": 9.863206403993086e-05,
      "loss": 0.9255,
      "step": 26650
    },
    {
      "epoch": 10.09,
      "learning_rate": 9.857259251892798e-05,
      "loss": 0.904,
      "step": 26660
    },
    {
      "epoch": 10.1,
      "learning_rate": 9.851312150287804e-05,
      "loss": 0.9065,
      "step": 26670
    },
    {
      "epoch": 10.1,
      "learning_rate": 9.84536510128192e-05,
      "loss": 0.9403,
      "step": 26680
    },
    {
      "epoch": 10.11,
      "learning_rate": 9.839418106978954e-05,
      "loss": 0.9062,
      "step": 26690
    },
    {
      "epoch": 10.11,
      "learning_rate": 9.833471169482678e-05,
      "loss": 0.9801,
      "step": 26700
    },
    {
      "epoch": 10.11,
      "learning_rate": 9.827524290896855e-05,
      "loss": 0.9148,
      "step": 26710
    },
    {
      "epoch": 10.12,
      "learning_rate": 9.82157747332523e-05,
      "loss": 0.9883,
      "step": 26720
    },
    {
      "epoch": 10.12,
      "learning_rate": 9.815630718871514e-05,
      "loss": 0.9847,
      "step": 26730
    },
    {
      "epoch": 10.12,
      "learning_rate": 9.809684029639405e-05,
      "loss": 0.9203,
      "step": 26740
    },
    {
      "epoch": 10.13,
      "learning_rate": 9.803737407732581e-05,
      "loss": 0.8874,
      "step": 26750
    },
    {
      "epoch": 10.13,
      "learning_rate": 9.797790855254682e-05,
      "loss": 0.9248,
      "step": 26760
    },
    {
      "epoch": 10.14,
      "learning_rate": 9.791844374309342e-05,
      "loss": 0.9349,
      "step": 26770
    },
    {
      "epoch": 10.14,
      "learning_rate": 9.785897967000149e-05,
      "loss": 0.9598,
      "step": 26780
    },
    {
      "epoch": 10.14,
      "learning_rate": 9.779951635430685e-05,
      "loss": 0.9462,
      "step": 26790
    },
    {
      "epoch": 10.15,
      "learning_rate": 9.774005381704497e-05,
      "loss": 0.9756,
      "step": 26800
    },
    {
      "epoch": 10.15,
      "learning_rate": 9.768059207925093e-05,
      "loss": 0.9572,
      "step": 26810
    },
    {
      "epoch": 10.15,
      "learning_rate": 9.762113116195973e-05,
      "loss": 0.9756,
      "step": 26820
    },
    {
      "epoch": 10.16,
      "learning_rate": 9.7561671086206e-05,
      "loss": 0.9557,
      "step": 26830
    },
    {
      "epoch": 10.16,
      "learning_rate": 9.750221187302396e-05,
      "loss": 0.8749,
      "step": 26840
    },
    {
      "epoch": 10.17,
      "learning_rate": 9.744275354344767e-05,
      "loss": 0.9175,
      "step": 26850
    },
    {
      "epoch": 10.17,
      "learning_rate": 9.738329611851091e-05,
      "loss": 0.9594,
      "step": 26860
    },
    {
      "epoch": 10.17,
      "learning_rate": 9.732383961924688e-05,
      "loss": 0.9968,
      "step": 26870
    },
    {
      "epoch": 10.18,
      "learning_rate": 9.726438406668878e-05,
      "loss": 0.9615,
      "step": 26880
    },
    {
      "epoch": 10.18,
      "learning_rate": 9.72049294818693e-05,
      "loss": 0.96,
      "step": 26890
    },
    {
      "epoch": 10.18,
      "learning_rate": 9.714547588582076e-05,
      "loss": 0.9286,
      "step": 26900
    },
    {
      "epoch": 10.19,
      "learning_rate": 9.708602329957525e-05,
      "loss": 0.9641,
      "step": 26910
    },
    {
      "epoch": 10.19,
      "learning_rate": 9.702657174416438e-05,
      "loss": 0.8953,
      "step": 26920
    },
    {
      "epoch": 10.2,
      "learning_rate": 9.696712124061945e-05,
      "loss": 0.9156,
      "step": 26930
    },
    {
      "epoch": 10.2,
      "learning_rate": 9.690767180997148e-05,
      "loss": 0.9477,
      "step": 26940
    },
    {
      "epoch": 10.2,
      "learning_rate": 9.684822347325091e-05,
      "loss": 0.9173,
      "step": 26950
    },
    {
      "epoch": 10.21,
      "learning_rate": 9.678877625148793e-05,
      "loss": 0.9174,
      "step": 26960
    },
    {
      "epoch": 10.21,
      "learning_rate": 9.672933016571237e-05,
      "loss": 0.977,
      "step": 26970
    },
    {
      "epoch": 10.21,
      "learning_rate": 9.666988523695354e-05,
      "loss": 0.9058,
      "step": 26980
    },
    {
      "epoch": 10.22,
      "learning_rate": 9.661044148624037e-05,
      "loss": 0.9097,
      "step": 26990
    },
    {
      "epoch": 10.22,
      "learning_rate": 9.655099893460153e-05,
      "loss": 0.8958,
      "step": 27000
    },
    {
      "epoch": 10.23,
      "learning_rate": 9.649155760306498e-05,
      "loss": 0.931,
      "step": 27010
    },
    {
      "epoch": 10.23,
      "learning_rate": 9.643211751265849e-05,
      "loss": 0.9584,
      "step": 27020
    },
    {
      "epoch": 10.23,
      "learning_rate": 9.637267868440934e-05,
      "loss": 0.9371,
      "step": 27030
    },
    {
      "epoch": 10.24,
      "learning_rate": 9.631324113934421e-05,
      "loss": 0.8591,
      "step": 27040
    },
    {
      "epoch": 10.24,
      "learning_rate": 9.625380489848959e-05,
      "loss": 0.9446,
      "step": 27050
    },
    {
      "epoch": 10.25,
      "learning_rate": 9.619436998287124e-05,
      "loss": 0.9233,
      "step": 27060
    },
    {
      "epoch": 10.25,
      "learning_rate": 9.613493641351461e-05,
      "loss": 0.9364,
      "step": 27070
    },
    {
      "epoch": 10.25,
      "learning_rate": 9.607550421144472e-05,
      "loss": 0.908,
      "step": 27080
    },
    {
      "epoch": 10.26,
      "learning_rate": 9.601607339768593e-05,
      "loss": 0.9227,
      "step": 27090
    },
    {
      "epoch": 10.26,
      "learning_rate": 9.59566439932622e-05,
      "loss": 0.9925,
      "step": 27100
    },
    {
      "epoch": 10.26,
      "learning_rate": 9.589721601919711e-05,
      "loss": 0.9016,
      "step": 27110
    },
    {
      "epoch": 10.27,
      "learning_rate": 9.583778949651349e-05,
      "loss": 0.9663,
      "step": 27120
    },
    {
      "epoch": 10.27,
      "learning_rate": 9.577836444623384e-05,
      "loss": 0.9455,
      "step": 27130
    },
    {
      "epoch": 10.28,
      "learning_rate": 9.571894088938013e-05,
      "loss": 0.9052,
      "step": 27140
    },
    {
      "epoch": 10.28,
      "learning_rate": 9.565951884697367e-05,
      "loss": 0.9348,
      "step": 27150
    },
    {
      "epoch": 10.28,
      "learning_rate": 9.560009834003535e-05,
      "loss": 0.9329,
      "step": 27160
    },
    {
      "epoch": 10.29,
      "learning_rate": 9.554067938958556e-05,
      "loss": 0.9318,
      "step": 27170
    },
    {
      "epoch": 10.29,
      "learning_rate": 9.548126201664398e-05,
      "loss": 0.9588,
      "step": 27180
    },
    {
      "epoch": 10.29,
      "learning_rate": 9.542184624222986e-05,
      "loss": 0.9451,
      "step": 27190
    },
    {
      "epoch": 10.3,
      "learning_rate": 9.536243208736182e-05,
      "loss": 0.9453,
      "step": 27200
    },
    {
      "epoch": 10.3,
      "learning_rate": 9.530301957305796e-05,
      "loss": 0.9287,
      "step": 27210
    },
    {
      "epoch": 10.31,
      "learning_rate": 9.524360872033576e-05,
      "loss": 0.9398,
      "step": 27220
    },
    {
      "epoch": 10.31,
      "learning_rate": 9.518419955021209e-05,
      "loss": 0.9201,
      "step": 27230
    },
    {
      "epoch": 10.31,
      "learning_rate": 9.512479208370331e-05,
      "loss": 0.9701,
      "step": 27240
    },
    {
      "epoch": 10.32,
      "learning_rate": 9.506538634182511e-05,
      "loss": 0.9532,
      "step": 27250
    },
    {
      "epoch": 10.32,
      "learning_rate": 9.500598234559257e-05,
      "loss": 0.919,
      "step": 27260
    },
    {
      "epoch": 10.32,
      "learning_rate": 9.494658011602017e-05,
      "loss": 0.9382,
      "step": 27270
    },
    {
      "epoch": 10.33,
      "learning_rate": 9.48871796741218e-05,
      "loss": 0.8893,
      "step": 27280
    },
    {
      "epoch": 10.33,
      "learning_rate": 9.482778104091061e-05,
      "loss": 0.9738,
      "step": 27290
    },
    {
      "epoch": 10.34,
      "learning_rate": 9.476838423739923e-05,
      "loss": 0.9135,
      "step": 27300
    },
    {
      "epoch": 10.34,
      "learning_rate": 9.470898928459961e-05,
      "loss": 0.9586,
      "step": 27310
    },
    {
      "epoch": 10.34,
      "learning_rate": 9.464959620352297e-05,
      "loss": 1.0043,
      "step": 27320
    },
    {
      "epoch": 10.35,
      "learning_rate": 9.459020501517999e-05,
      "loss": 0.9427,
      "step": 27330
    },
    {
      "epoch": 10.35,
      "learning_rate": 9.453081574058057e-05,
      "loss": 0.927,
      "step": 27340
    },
    {
      "epoch": 10.35,
      "learning_rate": 9.447142840073398e-05,
      "loss": 0.9236,
      "step": 27350
    },
    {
      "epoch": 10.36,
      "learning_rate": 9.441204301664885e-05,
      "loss": 0.8985,
      "step": 27360
    },
    {
      "epoch": 10.36,
      "learning_rate": 9.435265960933302e-05,
      "loss": 0.9583,
      "step": 27370
    },
    {
      "epoch": 10.37,
      "learning_rate": 9.429327819979373e-05,
      "loss": 0.912,
      "step": 27380
    },
    {
      "epoch": 10.37,
      "learning_rate": 9.423389880903744e-05,
      "loss": 0.9018,
      "step": 27390
    },
    {
      "epoch": 10.37,
      "learning_rate": 9.41745214580699e-05,
      "loss": 0.9129,
      "step": 27400
    },
    {
      "epoch": 10.38,
      "learning_rate": 9.411514616789623e-05,
      "loss": 0.9403,
      "step": 27410
    },
    {
      "epoch": 10.38,
      "learning_rate": 9.405577295952071e-05,
      "loss": 0.919,
      "step": 27420
    },
    {
      "epoch": 10.39,
      "learning_rate": 9.399640185394691e-05,
      "loss": 0.952,
      "step": 27430
    },
    {
      "epoch": 10.39,
      "learning_rate": 9.39370328721777e-05,
      "loss": 0.9175,
      "step": 27440
    },
    {
      "epoch": 10.39,
      "learning_rate": 9.387766603521519e-05,
      "loss": 0.9458,
      "step": 27450
    },
    {
      "epoch": 10.4,
      "learning_rate": 9.381830136406065e-05,
      "loss": 0.8936,
      "step": 27460
    },
    {
      "epoch": 10.4,
      "learning_rate": 9.37589388797147e-05,
      "loss": 0.9398,
      "step": 27470
    },
    {
      "epoch": 10.4,
      "learning_rate": 9.369957860317711e-05,
      "loss": 0.9357,
      "step": 27480
    },
    {
      "epoch": 10.41,
      "learning_rate": 9.36402205554469e-05,
      "loss": 0.9556,
      "step": 27490
    },
    {
      "epoch": 10.41,
      "learning_rate": 9.35808647575223e-05,
      "loss": 0.8986,
      "step": 27500
    },
    {
      "epoch": 10.42,
      "learning_rate": 9.352151123040072e-05,
      "loss": 0.9675,
      "step": 27510
    },
    {
      "epoch": 10.42,
      "learning_rate": 9.346215999507878e-05,
      "loss": 0.9364,
      "step": 27520
    },
    {
      "epoch": 10.42,
      "learning_rate": 9.340281107255233e-05,
      "loss": 0.9732,
      "step": 27530
    },
    {
      "epoch": 10.43,
      "learning_rate": 9.334346448381632e-05,
      "loss": 0.9693,
      "step": 27540
    },
    {
      "epoch": 10.43,
      "learning_rate": 9.328412024986494e-05,
      "loss": 0.9779,
      "step": 27550
    },
    {
      "epoch": 10.43,
      "learning_rate": 9.322477839169154e-05,
      "loss": 0.9558,
      "step": 27560
    },
    {
      "epoch": 10.44,
      "learning_rate": 9.316543893028859e-05,
      "loss": 0.9378,
      "step": 27570
    },
    {
      "epoch": 10.44,
      "learning_rate": 9.310610188664777e-05,
      "loss": 0.8857,
      "step": 27580
    },
    {
      "epoch": 10.45,
      "learning_rate": 9.304676728175983e-05,
      "loss": 0.8974,
      "step": 27590
    },
    {
      "epoch": 10.45,
      "learning_rate": 9.298743513661472e-05,
      "loss": 0.9164,
      "step": 27600
    },
    {
      "epoch": 10.45,
      "learning_rate": 9.292810547220154e-05,
      "loss": 0.9282,
      "step": 27610
    },
    {
      "epoch": 10.46,
      "learning_rate": 9.28687783095084e-05,
      "loss": 0.9343,
      "step": 27620
    },
    {
      "epoch": 10.46,
      "learning_rate": 9.280945366952264e-05,
      "loss": 0.9416,
      "step": 27630
    },
    {
      "epoch": 10.46,
      "learning_rate": 9.275013157323067e-05,
      "loss": 0.938,
      "step": 27640
    },
    {
      "epoch": 10.47,
      "learning_rate": 9.269081204161797e-05,
      "loss": 0.9047,
      "step": 27650
    },
    {
      "epoch": 10.47,
      "learning_rate": 9.263149509566915e-05,
      "loss": 0.9526,
      "step": 27660
    },
    {
      "epoch": 10.48,
      "learning_rate": 9.257218075636792e-05,
      "loss": 0.9054,
      "step": 27670
    },
    {
      "epoch": 10.48,
      "learning_rate": 9.251286904469699e-05,
      "loss": 0.9175,
      "step": 27680
    },
    {
      "epoch": 10.48,
      "learning_rate": 9.245355998163821e-05,
      "loss": 0.9209,
      "step": 27690
    },
    {
      "epoch": 10.49,
      "learning_rate": 9.239425358817252e-05,
      "loss": 0.9117,
      "step": 27700
    },
    {
      "epoch": 10.49,
      "learning_rate": 9.23349498852798e-05,
      "loss": 0.9708,
      "step": 27710
    },
    {
      "epoch": 10.5,
      "learning_rate": 9.227564889393913e-05,
      "loss": 0.9531,
      "step": 27720
    },
    {
      "epoch": 10.5,
      "learning_rate": 9.221635063512842e-05,
      "loss": 0.9492,
      "step": 27730
    },
    {
      "epoch": 10.5,
      "learning_rate": 9.215705512982485e-05,
      "loss": 0.9629,
      "step": 27740
    },
    {
      "epoch": 10.51,
      "learning_rate": 9.209776239900453e-05,
      "loss": 0.9393,
      "step": 27750
    },
    {
      "epoch": 10.51,
      "learning_rate": 9.20384724636425e-05,
      "loss": 0.9449,
      "step": 27760
    },
    {
      "epoch": 10.51,
      "learning_rate": 9.197918534471292e-05,
      "loss": 0.8633,
      "step": 27770
    },
    {
      "epoch": 10.52,
      "learning_rate": 9.191990106318896e-05,
      "loss": 0.9691,
      "step": 27780
    },
    {
      "epoch": 10.52,
      "learning_rate": 9.18606196400427e-05,
      "loss": 0.9212,
      "step": 27790
    },
    {
      "epoch": 10.53,
      "learning_rate": 9.180134109624527e-05,
      "loss": 0.9327,
      "step": 27800
    },
    {
      "epoch": 10.53,
      "learning_rate": 9.174206545276677e-05,
      "loss": 0.9267,
      "step": 27810
    },
    {
      "epoch": 10.53,
      "learning_rate": 9.168279273057627e-05,
      "loss": 0.9249,
      "step": 27820
    },
    {
      "epoch": 10.54,
      "learning_rate": 9.162352295064182e-05,
      "loss": 1.0254,
      "step": 27830
    },
    {
      "epoch": 10.54,
      "learning_rate": 9.156425613393041e-05,
      "loss": 0.9616,
      "step": 27840
    },
    {
      "epoch": 10.54,
      "learning_rate": 9.150499230140799e-05,
      "loss": 0.9348,
      "step": 27850
    },
    {
      "epoch": 10.55,
      "learning_rate": 9.144573147403948e-05,
      "loss": 0.9567,
      "step": 27860
    },
    {
      "epoch": 10.55,
      "learning_rate": 9.138647367278864e-05,
      "loss": 0.9804,
      "step": 27870
    },
    {
      "epoch": 10.56,
      "learning_rate": 9.132721891861826e-05,
      "loss": 0.9166,
      "step": 27880
    },
    {
      "epoch": 10.56,
      "learning_rate": 9.126796723249011e-05,
      "loss": 0.9675,
      "step": 27890
    },
    {
      "epoch": 10.56,
      "learning_rate": 9.120871863536465e-05,
      "loss": 0.9645,
      "step": 27900
    },
    {
      "epoch": 10.57,
      "learning_rate": 9.114947314820146e-05,
      "loss": 0.9504,
      "step": 27910
    },
    {
      "epoch": 10.57,
      "learning_rate": 9.109023079195897e-05,
      "loss": 0.9378,
      "step": 27920
    },
    {
      "epoch": 10.57,
      "learning_rate": 9.10309915875944e-05,
      "loss": 0.9524,
      "step": 27930
    },
    {
      "epoch": 10.58,
      "learning_rate": 9.097175555606397e-05,
      "loss": 0.9513,
      "step": 27940
    },
    {
      "epoch": 10.58,
      "learning_rate": 9.09125227183228e-05,
      "loss": 0.9551,
      "step": 27950
    },
    {
      "epoch": 10.59,
      "learning_rate": 9.085329309532468e-05,
      "loss": 1.0163,
      "step": 27960
    },
    {
      "epoch": 10.59,
      "learning_rate": 9.079406670802251e-05,
      "loss": 0.9399,
      "step": 27970
    },
    {
      "epoch": 10.59,
      "learning_rate": 9.073484357736797e-05,
      "loss": 0.9701,
      "step": 27980
    },
    {
      "epoch": 10.6,
      "learning_rate": 9.067562372431141e-05,
      "loss": 0.8931,
      "step": 27990
    },
    {
      "epoch": 10.6,
      "learning_rate": 9.061640716980232e-05,
      "loss": 0.9355,
      "step": 28000
    },
    {
      "epoch": 10.6,
      "learning_rate": 9.055719393478878e-05,
      "loss": 0.92,
      "step": 28010
    },
    {
      "epoch": 10.61,
      "learning_rate": 9.049798404021777e-05,
      "loss": 0.935,
      "step": 28020
    },
    {
      "epoch": 10.61,
      "learning_rate": 9.04387775070352e-05,
      "loss": 0.8922,
      "step": 28030
    },
    {
      "epoch": 10.62,
      "learning_rate": 9.037957435618559e-05,
      "loss": 0.9499,
      "step": 28040
    },
    {
      "epoch": 10.62,
      "learning_rate": 9.032037460861239e-05,
      "loss": 0.9587,
      "step": 28050
    },
    {
      "epoch": 10.62,
      "learning_rate": 9.026117828525792e-05,
      "loss": 0.9605,
      "step": 28060
    },
    {
      "epoch": 10.63,
      "learning_rate": 9.020198540706308e-05,
      "loss": 0.9938,
      "step": 28070
    },
    {
      "epoch": 10.63,
      "learning_rate": 9.014279599496766e-05,
      "loss": 0.899,
      "step": 28080
    },
    {
      "epoch": 10.64,
      "learning_rate": 9.008361006991035e-05,
      "loss": 0.8961,
      "step": 28090
    },
    {
      "epoch": 10.64,
      "learning_rate": 9.002442765282834e-05,
      "loss": 0.9295,
      "step": 28100
    },
    {
      "epoch": 10.64,
      "learning_rate": 8.996524876465777e-05,
      "loss": 0.9832,
      "step": 28110
    },
    {
      "epoch": 10.65,
      "learning_rate": 8.990607342633357e-05,
      "loss": 0.9383,
      "step": 28120
    },
    {
      "epoch": 10.65,
      "learning_rate": 8.984690165878921e-05,
      "loss": 0.9501,
      "step": 28130
    },
    {
      "epoch": 10.65,
      "learning_rate": 8.97877334829571e-05,
      "loss": 0.9155,
      "step": 28140
    },
    {
      "epoch": 10.66,
      "learning_rate": 8.972856891976822e-05,
      "loss": 0.8773,
      "step": 28150
    },
    {
      "epoch": 10.66,
      "learning_rate": 8.966940799015236e-05,
      "loss": 0.9347,
      "step": 28160
    },
    {
      "epoch": 10.67,
      "learning_rate": 8.961025071503813e-05,
      "loss": 0.8601,
      "step": 28170
    },
    {
      "epoch": 10.67,
      "learning_rate": 8.955109711535257e-05,
      "loss": 0.9453,
      "step": 28180
    },
    {
      "epoch": 10.67,
      "learning_rate": 8.949194721202163e-05,
      "loss": 0.8911,
      "step": 28190
    },
    {
      "epoch": 10.68,
      "learning_rate": 8.943280102596998e-05,
      "loss": 0.9398,
      "step": 28200
    },
    {
      "epoch": 10.68,
      "learning_rate": 8.937365857812079e-05,
      "loss": 0.8755,
      "step": 28210
    },
    {
      "epoch": 10.68,
      "learning_rate": 8.931451988939602e-05,
      "loss": 0.9651,
      "step": 28220
    },
    {
      "epoch": 10.69,
      "learning_rate": 8.925538498071643e-05,
      "loss": 0.9405,
      "step": 28230
    },
    {
      "epoch": 10.69,
      "learning_rate": 8.919625387300113e-05,
      "loss": 0.9302,
      "step": 28240
    },
    {
      "epoch": 10.7,
      "learning_rate": 8.913712658716813e-05,
      "loss": 0.9611,
      "step": 28250
    },
    {
      "epoch": 10.7,
      "learning_rate": 8.907800314413409e-05,
      "loss": 0.9732,
      "step": 28260
    },
    {
      "epoch": 10.7,
      "learning_rate": 8.901888356481414e-05,
      "loss": 0.9091,
      "step": 28270
    },
    {
      "epoch": 10.71,
      "learning_rate": 8.89597678701222e-05,
      "loss": 0.9978,
      "step": 28280
    },
    {
      "epoch": 10.71,
      "learning_rate": 8.890065608097073e-05,
      "loss": 0.9596,
      "step": 28290
    },
    {
      "epoch": 10.71,
      "learning_rate": 8.884154821827083e-05,
      "loss": 0.9753,
      "step": 28300
    },
    {
      "epoch": 10.72,
      "learning_rate": 8.878244430293227e-05,
      "loss": 0.9233,
      "step": 28310
    },
    {
      "epoch": 10.72,
      "learning_rate": 8.872334435586332e-05,
      "loss": 0.8963,
      "step": 28320
    },
    {
      "epoch": 10.73,
      "learning_rate": 8.866424839797092e-05,
      "loss": 0.9555,
      "step": 28330
    },
    {
      "epoch": 10.73,
      "learning_rate": 8.86051564501606e-05,
      "loss": 0.8969,
      "step": 28340
    },
    {
      "epoch": 10.73,
      "learning_rate": 8.854606853333641e-05,
      "loss": 0.8379,
      "step": 28350
    },
    {
      "epoch": 10.74,
      "learning_rate": 8.848698466840102e-05,
      "loss": 0.9244,
      "step": 28360
    },
    {
      "epoch": 10.74,
      "learning_rate": 8.84279048762557e-05,
      "loss": 0.929,
      "step": 28370
    },
    {
      "epoch": 10.74,
      "learning_rate": 8.836882917780018e-05,
      "loss": 0.9397,
      "step": 28380
    },
    {
      "epoch": 10.75,
      "learning_rate": 8.830975759393283e-05,
      "loss": 0.9951,
      "step": 28390
    },
    {
      "epoch": 10.75,
      "learning_rate": 8.825069014555055e-05,
      "loss": 0.9982,
      "step": 28400
    },
    {
      "epoch": 10.76,
      "learning_rate": 8.819162685354872e-05,
      "loss": 0.9282,
      "step": 28410
    },
    {
      "epoch": 10.76,
      "learning_rate": 8.813256773882136e-05,
      "loss": 0.9732,
      "step": 28420
    },
    {
      "epoch": 10.76,
      "learning_rate": 8.807351282226086e-05,
      "loss": 0.9553,
      "step": 28430
    },
    {
      "epoch": 10.77,
      "learning_rate": 8.801446212475826e-05,
      "loss": 0.9117,
      "step": 28440
    },
    {
      "epoch": 10.77,
      "learning_rate": 8.795541566720307e-05,
      "loss": 0.9226,
      "step": 28450
    },
    {
      "epoch": 10.78,
      "learning_rate": 8.789637347048323e-05,
      "loss": 0.9507,
      "step": 28460
    },
    {
      "epoch": 10.78,
      "learning_rate": 8.783733555548527e-05,
      "loss": 0.9413,
      "step": 28470
    },
    {
      "epoch": 10.78,
      "learning_rate": 8.777830194309417e-05,
      "loss": 0.9096,
      "step": 28480
    },
    {
      "epoch": 10.79,
      "learning_rate": 8.771927265419336e-05,
      "loss": 0.9373,
      "step": 28490
    },
    {
      "epoch": 10.79,
      "learning_rate": 8.766024770966476e-05,
      "loss": 0.97,
      "step": 28500
    },
    {
      "epoch": 10.79,
      "learning_rate": 8.760122713038881e-05,
      "loss": 0.9915,
      "step": 28510
    },
    {
      "epoch": 10.8,
      "learning_rate": 8.754221093724427e-05,
      "loss": 0.98,
      "step": 28520
    },
    {
      "epoch": 10.8,
      "learning_rate": 8.748319915110849e-05,
      "loss": 0.9258,
      "step": 28530
    },
    {
      "epoch": 10.81,
      "learning_rate": 8.742419179285719e-05,
      "loss": 0.9576,
      "step": 28540
    },
    {
      "epoch": 10.81,
      "learning_rate": 8.73651888833645e-05,
      "loss": 0.9165,
      "step": 28550
    },
    {
      "epoch": 10.81,
      "learning_rate": 8.730619044350308e-05,
      "loss": 0.9576,
      "step": 28560
    },
    {
      "epoch": 10.82,
      "learning_rate": 8.724719649414386e-05,
      "loss": 0.9096,
      "step": 28570
    },
    {
      "epoch": 10.82,
      "learning_rate": 8.71882070561563e-05,
      "loss": 0.942,
      "step": 28580
    },
    {
      "epoch": 10.82,
      "learning_rate": 8.712922215040826e-05,
      "loss": 0.9615,
      "step": 28590
    },
    {
      "epoch": 10.83,
      "learning_rate": 8.707024179776588e-05,
      "loss": 0.9538,
      "step": 28600
    },
    {
      "epoch": 10.83,
      "learning_rate": 8.701716339053778e-05,
      "loss": 0.9543,
      "step": 28610
    },
    {
      "epoch": 10.84,
      "learning_rate": 8.695819174627695e-05,
      "loss": 0.9683,
      "step": 28620
    },
    {
      "epoch": 10.84,
      "learning_rate": 8.689922471562471e-05,
      "loss": 0.9554,
      "step": 28630
    },
    {
      "epoch": 10.84,
      "learning_rate": 8.684026231944102e-05,
      "loss": 0.8883,
      "step": 28640
    },
    {
      "epoch": 10.85,
      "learning_rate": 8.678130457858408e-05,
      "loss": 0.9157,
      "step": 28650
    },
    {
      "epoch": 10.85,
      "learning_rate": 8.672235151391052e-05,
      "loss": 0.9388,
      "step": 28660
    },
    {
      "epoch": 10.85,
      "learning_rate": 8.666340314627535e-05,
      "loss": 0.9779,
      "step": 28670
    },
    {
      "epoch": 10.86,
      "learning_rate": 8.660445949653178e-05,
      "loss": 0.9398,
      "step": 28680
    },
    {
      "epoch": 10.86,
      "learning_rate": 8.654552058553148e-05,
      "loss": 0.9306,
      "step": 28690
    },
    {
      "epoch": 10.87,
      "learning_rate": 8.648658643412444e-05,
      "loss": 0.8862,
      "step": 28700
    },
    {
      "epoch": 10.87,
      "learning_rate": 8.642765706315885e-05,
      "loss": 0.959,
      "step": 28710
    },
    {
      "epoch": 10.87,
      "learning_rate": 8.636873249348134e-05,
      "loss": 0.9605,
      "step": 28720
    },
    {
      "epoch": 10.88,
      "learning_rate": 8.630981274593678e-05,
      "loss": 0.9395,
      "step": 28730
    },
    {
      "epoch": 10.88,
      "learning_rate": 8.625089784136833e-05,
      "loss": 0.9208,
      "step": 28740
    },
    {
      "epoch": 10.88,
      "learning_rate": 8.619198780061745e-05,
      "loss": 0.9251,
      "step": 28750
    },
    {
      "epoch": 10.89,
      "learning_rate": 8.613308264452391e-05,
      "loss": 0.9332,
      "step": 28760
    },
    {
      "epoch": 10.89,
      "learning_rate": 8.607418239392566e-05,
      "loss": 0.9696,
      "step": 28770
    },
    {
      "epoch": 10.9,
      "learning_rate": 8.601528706965904e-05,
      "loss": 1.0014,
      "step": 28780
    },
    {
      "epoch": 10.9,
      "learning_rate": 8.595639669255854e-05,
      "loss": 0.9221,
      "step": 28790
    },
    {
      "epoch": 10.9,
      "learning_rate": 8.589751128345693e-05,
      "loss": 0.9333,
      "step": 28800
    },
    {
      "epoch": 10.91,
      "learning_rate": 8.58386308631853e-05,
      "loss": 0.9576,
      "step": 28810
    },
    {
      "epoch": 10.91,
      "learning_rate": 8.577975545257285e-05,
      "loss": 0.8984,
      "step": 28820
    },
    {
      "epoch": 10.92,
      "learning_rate": 8.572088507244707e-05,
      "loss": 0.8942,
      "step": 28830
    },
    {
      "epoch": 10.92,
      "learning_rate": 8.56620197436337e-05,
      "loss": 0.9883,
      "step": 28840
    },
    {
      "epoch": 10.92,
      "learning_rate": 8.560315948695664e-05,
      "loss": 0.9511,
      "step": 28850
    },
    {
      "epoch": 10.93,
      "learning_rate": 8.554430432323802e-05,
      "loss": 0.932,
      "step": 28860
    },
    {
      "epoch": 10.93,
      "learning_rate": 8.548545427329819e-05,
      "loss": 0.9412,
      "step": 28870
    },
    {
      "epoch": 10.93,
      "learning_rate": 8.542660935795562e-05,
      "loss": 0.9488,
      "step": 28880
    },
    {
      "epoch": 10.94,
      "learning_rate": 8.536776959802704e-05,
      "loss": 0.9597,
      "step": 28890
    },
    {
      "epoch": 10.94,
      "learning_rate": 8.530893501432733e-05,
      "loss": 0.9025,
      "step": 28900
    },
    {
      "epoch": 10.95,
      "learning_rate": 8.52501056276695e-05,
      "loss": 0.9885,
      "step": 28910
    },
    {
      "epoch": 10.95,
      "learning_rate": 8.519128145886485e-05,
      "loss": 0.9086,
      "step": 28920
    },
    {
      "epoch": 10.95,
      "learning_rate": 8.51324625287226e-05,
      "loss": 0.9413,
      "step": 28930
    },
    {
      "epoch": 10.96,
      "learning_rate": 8.507364885805034e-05,
      "loss": 0.9447,
      "step": 28940
    },
    {
      "epoch": 10.96,
      "learning_rate": 8.501484046765376e-05,
      "loss": 0.9428,
      "step": 28950
    },
    {
      "epoch": 10.96,
      "learning_rate": 8.49560373783365e-05,
      "loss": 0.9943,
      "step": 28960
    },
    {
      "epoch": 10.97,
      "learning_rate": 8.489723961090059e-05,
      "loss": 0.9321,
      "step": 28970
    },
    {
      "epoch": 10.97,
      "learning_rate": 8.483844718614605e-05,
      "loss": 0.9427,
      "step": 28980
    },
    {
      "epoch": 10.98,
      "learning_rate": 8.477966012487091e-05,
      "loss": 0.9524,
      "step": 28990
    },
    {
      "epoch": 10.98,
      "learning_rate": 8.47208784478715e-05,
      "loss": 0.9366,
      "step": 29000
    },
    {
      "epoch": 10.98,
      "learning_rate": 8.46621021759421e-05,
      "loss": 0.9204,
      "step": 29010
    },
    {
      "epoch": 10.99,
      "learning_rate": 8.460333132987515e-05,
      "loss": 0.9966,
      "step": 29020
    },
    {
      "epoch": 10.99,
      "learning_rate": 8.454456593046113e-05,
      "loss": 0.9192,
      "step": 29030
    },
    {
      "epoch": 10.99,
      "learning_rate": 8.448580599848863e-05,
      "loss": 0.9705,
      "step": 29040
    },
    {
      "epoch": 11.0,
      "learning_rate": 8.442705155474428e-05,
      "loss": 0.951,
      "step": 29050
    },
    {
      "epoch": 11.0,
      "learning_rate": 8.436830262001279e-05,
      "loss": 0.8819,
      "step": 29060
    },
    {
      "epoch": 11.01,
      "learning_rate": 8.430955921507684e-05,
      "loss": 0.9088,
      "step": 29070
    },
    {
      "epoch": 11.01,
      "learning_rate": 8.425082136071728e-05,
      "loss": 0.9014,
      "step": 29080
    },
    {
      "epoch": 11.01,
      "learning_rate": 8.419208907771296e-05,
      "loss": 0.8898,
      "step": 29090
    },
    {
      "epoch": 11.02,
      "learning_rate": 8.413336238684066e-05,
      "loss": 0.9157,
      "step": 29100
    },
    {
      "epoch": 11.02,
      "learning_rate": 8.407464130887529e-05,
      "loss": 0.8871,
      "step": 29110
    },
    {
      "epoch": 11.03,
      "learning_rate": 8.40159258645898e-05,
      "loss": 0.9769,
      "step": 29120
    },
    {
      "epoch": 11.03,
      "learning_rate": 8.395721607475498e-05,
      "loss": 0.9406,
      "step": 29130
    },
    {
      "epoch": 11.03,
      "learning_rate": 8.389851196013981e-05,
      "loss": 0.8811,
      "step": 29140
    },
    {
      "epoch": 11.04,
      "learning_rate": 8.38398135415112e-05,
      "loss": 0.9239,
      "step": 29150
    },
    {
      "epoch": 11.04,
      "learning_rate": 8.37811208396339e-05,
      "loss": 0.9846,
      "step": 29160
    },
    {
      "epoch": 11.04,
      "learning_rate": 8.37224338752709e-05,
      "loss": 0.8546,
      "step": 29170
    },
    {
      "epoch": 11.05,
      "learning_rate": 8.366375266918299e-05,
      "loss": 0.9477,
      "step": 29180
    },
    {
      "epoch": 11.05,
      "learning_rate": 8.360507724212888e-05,
      "loss": 0.9234,
      "step": 29190
    },
    {
      "epoch": 11.06,
      "learning_rate": 8.354640761486543e-05,
      "loss": 0.9395,
      "step": 29200
    },
    {
      "epoch": 11.06,
      "learning_rate": 8.348774380814723e-05,
      "loss": 0.9006,
      "step": 29210
    },
    {
      "epoch": 11.06,
      "learning_rate": 8.342908584272693e-05,
      "loss": 0.9273,
      "step": 29220
    },
    {
      "epoch": 11.07,
      "learning_rate": 8.337043373935519e-05,
      "loss": 0.9059,
      "step": 29230
    },
    {
      "epoch": 11.07,
      "learning_rate": 8.331178751878039e-05,
      "loss": 0.9095,
      "step": 29240
    },
    {
      "epoch": 11.07,
      "learning_rate": 8.325314720174894e-05,
      "loss": 0.9261,
      "step": 29250
    },
    {
      "epoch": 11.08,
      "learning_rate": 8.319451280900528e-05,
      "loss": 0.9038,
      "step": 29260
    },
    {
      "epoch": 11.08,
      "learning_rate": 8.313588436129151e-05,
      "loss": 0.9234,
      "step": 29270
    },
    {
      "epoch": 11.09,
      "learning_rate": 8.307726187934777e-05,
      "loss": 0.912,
      "step": 29280
    },
    {
      "epoch": 11.09,
      "learning_rate": 8.30186453839122e-05,
      "loss": 0.9015,
      "step": 29290
    },
    {
      "epoch": 11.09,
      "learning_rate": 8.296003489572053e-05,
      "loss": 0.9444,
      "step": 29300
    },
    {
      "epoch": 11.1,
      "learning_rate": 8.290143043550659e-05,
      "loss": 0.9178,
      "step": 29310
    },
    {
      "epoch": 11.1,
      "learning_rate": 8.284283202400208e-05,
      "loss": 0.8886,
      "step": 29320
    },
    {
      "epoch": 11.1,
      "learning_rate": 8.278423968193642e-05,
      "loss": 0.9135,
      "step": 29330
    },
    {
      "epoch": 11.11,
      "learning_rate": 8.2725653430037e-05,
      "loss": 0.8996,
      "step": 29340
    },
    {
      "epoch": 11.11,
      "learning_rate": 8.266707328902898e-05,
      "loss": 0.9288,
      "step": 29350
    },
    {
      "epoch": 11.12,
      "learning_rate": 8.260849927963541e-05,
      "loss": 0.976,
      "step": 29360
    },
    {
      "epoch": 11.12,
      "learning_rate": 8.25499314225772e-05,
      "loss": 0.8955,
      "step": 29370
    },
    {
      "epoch": 11.12,
      "learning_rate": 8.249136973857296e-05,
      "loss": 0.9162,
      "step": 29380
    },
    {
      "epoch": 11.13,
      "learning_rate": 8.243281424833926e-05,
      "loss": 0.9261,
      "step": 29390
    },
    {
      "epoch": 11.13,
      "learning_rate": 8.23742649725904e-05,
      "loss": 0.9647,
      "step": 29400
    },
    {
      "epoch": 11.13,
      "learning_rate": 8.231572193203847e-05,
      "loss": 0.917,
      "step": 29410
    },
    {
      "epoch": 11.14,
      "learning_rate": 8.225718514739338e-05,
      "loss": 0.9124,
      "step": 29420
    },
    {
      "epoch": 11.14,
      "learning_rate": 8.219865463936289e-05,
      "loss": 0.9337,
      "step": 29430
    },
    {
      "epoch": 11.15,
      "learning_rate": 8.21401304286524e-05,
      "loss": 0.9728,
      "step": 29440
    },
    {
      "epoch": 11.15,
      "learning_rate": 8.208161253596516e-05,
      "loss": 0.9191,
      "step": 29450
    },
    {
      "epoch": 11.15,
      "learning_rate": 8.20231009820023e-05,
      "loss": 0.9031,
      "step": 29460
    },
    {
      "epoch": 11.16,
      "learning_rate": 8.196459578746245e-05,
      "loss": 0.9002,
      "step": 29470
    },
    {
      "epoch": 11.16,
      "learning_rate": 8.19060969730422e-05,
      "loss": 0.9233,
      "step": 29480
    },
    {
      "epoch": 11.17,
      "learning_rate": 8.184760455943579e-05,
      "loss": 0.9262,
      "step": 29490
    },
    {
      "epoch": 11.17,
      "learning_rate": 8.178911856733522e-05,
      "loss": 0.9301,
      "step": 29500
    },
    {
      "epoch": 11.17,
      "learning_rate": 8.173063901743027e-05,
      "loss": 0.9531,
      "step": 29510
    },
    {
      "epoch": 11.18,
      "learning_rate": 8.167216593040832e-05,
      "loss": 0.9011,
      "step": 29520
    },
    {
      "epoch": 11.18,
      "learning_rate": 8.161369932695457e-05,
      "loss": 0.9457,
      "step": 29530
    },
    {
      "epoch": 11.18,
      "learning_rate": 8.15552392277519e-05,
      "loss": 0.9064,
      "step": 29540
    },
    {
      "epoch": 11.19,
      "learning_rate": 8.149678565348085e-05,
      "loss": 0.9232,
      "step": 29550
    },
    {
      "epoch": 11.19,
      "learning_rate": 8.14383386248197e-05,
      "loss": 0.9454,
      "step": 29560
    },
    {
      "epoch": 11.2,
      "learning_rate": 8.13798981624444e-05,
      "loss": 0.9659,
      "step": 29570
    },
    {
      "epoch": 11.2,
      "learning_rate": 8.132146428702854e-05,
      "loss": 0.9522,
      "step": 29580
    },
    {
      "epoch": 11.2,
      "learning_rate": 8.126303701924345e-05,
      "loss": 0.9287,
      "step": 29590
    },
    {
      "epoch": 11.21,
      "learning_rate": 8.120461637975808e-05,
      "loss": 0.9441,
      "step": 29600
    },
    {
      "epoch": 11.21,
      "learning_rate": 8.1146202389239e-05,
      "loss": 0.9557,
      "step": 29610
    },
    {
      "epoch": 11.21,
      "learning_rate": 8.108779506835054e-05,
      "loss": 0.9528,
      "step": 29620
    },
    {
      "epoch": 11.22,
      "learning_rate": 8.102939443775454e-05,
      "loss": 0.9145,
      "step": 29630
    },
    {
      "epoch": 11.22,
      "learning_rate": 8.097100051811053e-05,
      "loss": 0.9624,
      "step": 29640
    },
    {
      "epoch": 11.23,
      "learning_rate": 8.091261333007572e-05,
      "loss": 0.9422,
      "step": 29650
    },
    {
      "epoch": 11.23,
      "learning_rate": 8.085423289430483e-05,
      "loss": 0.896,
      "step": 29660
    },
    {
      "epoch": 11.23,
      "learning_rate": 8.079585923145026e-05,
      "loss": 0.96,
      "step": 29670
    },
    {
      "epoch": 11.24,
      "learning_rate": 8.073749236216204e-05,
      "loss": 0.9602,
      "step": 29680
    },
    {
      "epoch": 11.24,
      "learning_rate": 8.067913230708771e-05,
      "loss": 0.9043,
      "step": 29690
    },
    {
      "epoch": 11.24,
      "learning_rate": 8.062077908687247e-05,
      "loss": 0.8972,
      "step": 29700
    },
    {
      "epoch": 11.25,
      "learning_rate": 8.05624327221591e-05,
      "loss": 0.9231,
      "step": 29710
    },
    {
      "epoch": 11.25,
      "learning_rate": 8.050409323358788e-05,
      "loss": 0.8898,
      "step": 29720
    },
    {
      "epoch": 11.26,
      "learning_rate": 8.044576064179679e-05,
      "loss": 0.9069,
      "step": 29730
    },
    {
      "epoch": 11.26,
      "learning_rate": 8.038743496742121e-05,
      "loss": 0.9782,
      "step": 29740
    },
    {
      "epoch": 11.26,
      "learning_rate": 8.032911623109422e-05,
      "loss": 0.8891,
      "step": 29750
    },
    {
      "epoch": 11.27,
      "learning_rate": 8.027080445344635e-05,
      "loss": 0.909,
      "step": 29760
    },
    {
      "epoch": 11.27,
      "learning_rate": 8.02124996551057e-05,
      "loss": 0.9473,
      "step": 29770
    },
    {
      "epoch": 11.27,
      "learning_rate": 8.01542018566979e-05,
      "loss": 0.9089,
      "step": 29780
    },
    {
      "epoch": 11.28,
      "learning_rate": 8.009591107884613e-05,
      "loss": 0.9034,
      "step": 29790
    },
    {
      "epoch": 11.28,
      "learning_rate": 8.003762734217104e-05,
      "loss": 0.9531,
      "step": 29800
    },
    {
      "epoch": 11.29,
      "learning_rate": 7.997935066729079e-05,
      "loss": 0.9515,
      "step": 29810
    },
    {
      "epoch": 11.29,
      "learning_rate": 7.992108107482111e-05,
      "loss": 0.9651,
      "step": 29820
    },
    {
      "epoch": 11.29,
      "learning_rate": 7.986281858537513e-05,
      "loss": 0.9901,
      "step": 29830
    },
    {
      "epoch": 11.3,
      "learning_rate": 7.980456321956354e-05,
      "loss": 0.9352,
      "step": 29840
    },
    {
      "epoch": 11.3,
      "learning_rate": 7.97463149979945e-05,
      "loss": 0.952,
      "step": 29850
    },
    {
      "epoch": 11.31,
      "learning_rate": 7.968807394127358e-05,
      "loss": 0.8934,
      "step": 29860
    },
    {
      "epoch": 11.31,
      "learning_rate": 7.96298400700039e-05,
      "loss": 0.973,
      "step": 29870
    },
    {
      "epoch": 11.31,
      "learning_rate": 7.957161340478596e-05,
      "loss": 0.9663,
      "step": 29880
    },
    {
      "epoch": 11.32,
      "learning_rate": 7.951339396621779e-05,
      "loss": 0.9479,
      "step": 29890
    },
    {
      "epoch": 11.32,
      "learning_rate": 7.945518177489481e-05,
      "loss": 0.9829,
      "step": 29900
    },
    {
      "epoch": 11.32,
      "learning_rate": 7.93969768514099e-05,
      "loss": 0.9349,
      "step": 29910
    },
    {
      "epoch": 11.33,
      "learning_rate": 7.933877921635333e-05,
      "loss": 0.8946,
      "step": 29920
    },
    {
      "epoch": 11.33,
      "learning_rate": 7.928058889031286e-05,
      "loss": 0.8787,
      "step": 29930
    },
    {
      "epoch": 11.34,
      "learning_rate": 7.92224058938736e-05,
      "loss": 0.9388,
      "step": 29940
    },
    {
      "epoch": 11.34,
      "learning_rate": 7.916423024761808e-05,
      "loss": 0.8629,
      "step": 29950
    },
    {
      "epoch": 11.34,
      "learning_rate": 7.91060619721263e-05,
      "loss": 0.9049,
      "step": 29960
    },
    {
      "epoch": 11.35,
      "learning_rate": 7.904790108797552e-05,
      "loss": 0.9768,
      "step": 29970
    },
    {
      "epoch": 11.35,
      "learning_rate": 7.89897476157405e-05,
      "loss": 0.9587,
      "step": 29980
    },
    {
      "epoch": 11.35,
      "learning_rate": 7.893160157599336e-05,
      "loss": 0.9027,
      "step": 29990
    },
    {
      "epoch": 11.36,
      "learning_rate": 7.887346298930353e-05,
      "loss": 0.9471,
      "step": 30000
    },
    {
      "epoch": 11.36,
      "learning_rate": 7.881533187623789e-05,
      "loss": 0.8803,
      "step": 30010
    },
    {
      "epoch": 11.37,
      "learning_rate": 7.875720825736053e-05,
      "loss": 0.9293,
      "step": 30020
    },
    {
      "epoch": 11.37,
      "learning_rate": 7.869909215323308e-05,
      "loss": 0.9285,
      "step": 30030
    },
    {
      "epoch": 11.37,
      "learning_rate": 7.864098358441443e-05,
      "loss": 0.9388,
      "step": 30040
    },
    {
      "epoch": 11.38,
      "learning_rate": 7.85828825714607e-05,
      "loss": 0.9063,
      "step": 30050
    },
    {
      "epoch": 11.38,
      "learning_rate": 7.852478913492549e-05,
      "loss": 0.9075,
      "step": 30060
    },
    {
      "epoch": 11.38,
      "learning_rate": 7.84667032953597e-05,
      "loss": 0.8852,
      "step": 30070
    },
    {
      "epoch": 11.39,
      "learning_rate": 7.84086250733114e-05,
      "loss": 0.9454,
      "step": 30080
    },
    {
      "epoch": 11.39,
      "learning_rate": 7.835055448932615e-05,
      "loss": 0.9336,
      "step": 30090
    },
    {
      "epoch": 11.4,
      "learning_rate": 7.829249156394675e-05,
      "loss": 0.9462,
      "step": 30100
    },
    {
      "epoch": 11.4,
      "learning_rate": 7.823443631771314e-05,
      "loss": 0.9414,
      "step": 30110
    },
    {
      "epoch": 11.4,
      "learning_rate": 7.817638877116278e-05,
      "loss": 0.9672,
      "step": 30120
    },
    {
      "epoch": 11.41,
      "learning_rate": 7.81183489448303e-05,
      "loss": 0.891,
      "step": 30130
    },
    {
      "epoch": 11.41,
      "learning_rate": 7.806031685924752e-05,
      "loss": 0.9164,
      "step": 30140
    },
    {
      "epoch": 11.42,
      "learning_rate": 7.800229253494369e-05,
      "loss": 0.8861,
      "step": 30150
    },
    {
      "epoch": 11.42,
      "learning_rate": 7.794427599244511e-05,
      "loss": 0.9542,
      "step": 30160
    },
    {
      "epoch": 11.42,
      "learning_rate": 7.78862672522755e-05,
      "loss": 0.9,
      "step": 30170
    },
    {
      "epoch": 11.43,
      "learning_rate": 7.782826633495581e-05,
      "loss": 0.8879,
      "step": 30180
    },
    {
      "epoch": 11.43,
      "learning_rate": 7.777027326100406e-05,
      "loss": 0.9406,
      "step": 30190
    },
    {
      "epoch": 11.43,
      "learning_rate": 7.771228805093569e-05,
      "loss": 0.9001,
      "step": 30200
    },
    {
      "epoch": 11.44,
      "learning_rate": 7.765431072526328e-05,
      "loss": 0.9427,
      "step": 30210
    },
    {
      "epoch": 11.44,
      "learning_rate": 7.759634130449654e-05,
      "loss": 0.9213,
      "step": 30220
    },
    {
      "epoch": 11.45,
      "learning_rate": 7.75383798091425e-05,
      "loss": 0.9725,
      "step": 30230
    },
    {
      "epoch": 11.45,
      "learning_rate": 7.748042625970541e-05,
      "loss": 0.926,
      "step": 30240
    },
    {
      "epoch": 11.45,
      "learning_rate": 7.742248067668652e-05,
      "loss": 0.9259,
      "step": 30250
    },
    {
      "epoch": 11.46,
      "learning_rate": 7.736454308058446e-05,
      "loss": 0.9017,
      "step": 30260
    },
    {
      "epoch": 11.46,
      "learning_rate": 7.7306613491895e-05,
      "loss": 0.9253,
      "step": 30270
    },
    {
      "epoch": 11.46,
      "learning_rate": 7.724869193111092e-05,
      "loss": 0.8811,
      "step": 30280
    },
    {
      "epoch": 11.47,
      "learning_rate": 7.719077841872242e-05,
      "loss": 0.8901,
      "step": 30290
    },
    {
      "epoch": 11.47,
      "learning_rate": 7.713287297521659e-05,
      "loss": 0.8958,
      "step": 30300
    },
    {
      "epoch": 11.48,
      "learning_rate": 7.707497562107781e-05,
      "loss": 0.8697,
      "step": 30310
    },
    {
      "epoch": 11.48,
      "learning_rate": 7.701708637678768e-05,
      "loss": 0.9154,
      "step": 30320
    },
    {
      "epoch": 11.48,
      "learning_rate": 7.69592052628247e-05,
      "loss": 0.9005,
      "step": 30330
    },
    {
      "epoch": 11.49,
      "learning_rate": 7.690133229966465e-05,
      "loss": 0.9536,
      "step": 30340
    },
    {
      "epoch": 11.49,
      "learning_rate": 7.684346750778046e-05,
      "loss": 0.9728,
      "step": 30350
    },
    {
      "epoch": 11.49,
      "learning_rate": 7.678561090764202e-05,
      "loss": 0.9032,
      "step": 30360
    },
    {
      "epoch": 11.5,
      "learning_rate": 7.672776251971643e-05,
      "loss": 0.9351,
      "step": 30370
    },
    {
      "epoch": 11.5,
      "learning_rate": 7.666992236446795e-05,
      "loss": 0.9224,
      "step": 30380
    },
    {
      "epoch": 11.51,
      "learning_rate": 7.661209046235773e-05,
      "loss": 0.8874,
      "step": 30390
    },
    {
      "epoch": 11.51,
      "learning_rate": 7.655426683384412e-05,
      "loss": 0.9347,
      "step": 30400
    },
    {
      "epoch": 11.51,
      "learning_rate": 7.649645149938265e-05,
      "loss": 0.902,
      "step": 30410
    },
    {
      "epoch": 11.52,
      "learning_rate": 7.643864447942565e-05,
      "loss": 0.9306,
      "step": 30420
    },
    {
      "epoch": 11.52,
      "learning_rate": 7.638084579442278e-05,
      "loss": 0.9417,
      "step": 30430
    },
    {
      "epoch": 11.52,
      "learning_rate": 7.632305546482053e-05,
      "loss": 0.918,
      "step": 30440
    },
    {
      "epoch": 11.53,
      "learning_rate": 7.626527351106258e-05,
      "loss": 0.9138,
      "step": 30450
    },
    {
      "epoch": 11.53,
      "learning_rate": 7.620749995358965e-05,
      "loss": 0.9494,
      "step": 30460
    },
    {
      "epoch": 11.54,
      "learning_rate": 7.614973481283935e-05,
      "loss": 0.9184,
      "step": 30470
    },
    {
      "epoch": 11.54,
      "learning_rate": 7.609197810924644e-05,
      "loss": 0.9193,
      "step": 30480
    },
    {
      "epoch": 11.54,
      "learning_rate": 7.603422986324271e-05,
      "loss": 0.9286,
      "step": 30490
    },
    {
      "epoch": 11.55,
      "learning_rate": 7.597649009525684e-05,
      "loss": 0.9071,
      "step": 30500
    },
    {
      "epoch": 11.55,
      "learning_rate": 7.59187588257146e-05,
      "loss": 0.9423,
      "step": 30510
    },
    {
      "epoch": 11.56,
      "learning_rate": 7.586103607503873e-05,
      "loss": 0.8761,
      "step": 30520
    },
    {
      "epoch": 11.56,
      "learning_rate": 7.580332186364898e-05,
      "loss": 0.9166,
      "step": 30530
    },
    {
      "epoch": 11.56,
      "learning_rate": 7.574561621196202e-05,
      "loss": 0.9605,
      "step": 30540
    },
    {
      "epoch": 11.57,
      "learning_rate": 7.568791914039159e-05,
      "loss": 0.9505,
      "step": 30550
    },
    {
      "epoch": 11.57,
      "learning_rate": 7.563023066934824e-05,
      "loss": 0.8937,
      "step": 30560
    },
    {
      "epoch": 11.57,
      "learning_rate": 7.557255081923967e-05,
      "loss": 0.9035,
      "step": 30570
    },
    {
      "epoch": 11.58,
      "learning_rate": 7.551487961047037e-05,
      "loss": 0.9197,
      "step": 30580
    },
    {
      "epoch": 11.58,
      "learning_rate": 7.545721706344183e-05,
      "loss": 0.8785,
      "step": 30590
    },
    {
      "epoch": 11.59,
      "learning_rate": 7.539956319855255e-05,
      "loss": 0.9635,
      "step": 30600
    },
    {
      "epoch": 11.59,
      "learning_rate": 7.53419180361978e-05,
      "loss": 0.9361,
      "step": 30610
    },
    {
      "epoch": 11.59,
      "learning_rate": 7.528428159676992e-05,
      "loss": 0.9671,
      "step": 30620
    },
    {
      "epoch": 11.6,
      "learning_rate": 7.52266539006581e-05,
      "loss": 0.9347,
      "step": 30630
    },
    {
      "epoch": 11.6,
      "learning_rate": 7.516903496824841e-05,
      "loss": 0.9398,
      "step": 30640
    },
    {
      "epoch": 11.6,
      "learning_rate": 7.511142481992387e-05,
      "loss": 0.9628,
      "step": 30650
    },
    {
      "epoch": 11.61,
      "learning_rate": 7.50538234760644e-05,
      "loss": 0.9328,
      "step": 30660
    },
    {
      "epoch": 11.61,
      "learning_rate": 7.499623095704674e-05,
      "loss": 0.9626,
      "step": 30670
    },
    {
      "epoch": 11.62,
      "learning_rate": 7.493864728324456e-05,
      "loss": 0.9385,
      "step": 30680
    },
    {
      "epoch": 11.62,
      "learning_rate": 7.488107247502842e-05,
      "loss": 0.9493,
      "step": 30690
    },
    {
      "epoch": 11.62,
      "learning_rate": 7.482350655276566e-05,
      "loss": 0.9043,
      "step": 30700
    },
    {
      "epoch": 11.63,
      "learning_rate": 7.476594953682058e-05,
      "loss": 0.9327,
      "step": 30710
    },
    {
      "epoch": 11.63,
      "learning_rate": 7.470840144755424e-05,
      "loss": 0.954,
      "step": 30720
    },
    {
      "epoch": 11.63,
      "learning_rate": 7.46508623053246e-05,
      "loss": 0.9581,
      "step": 30730
    },
    {
      "epoch": 11.64,
      "learning_rate": 7.459333213048645e-05,
      "loss": 0.9737,
      "step": 30740
    },
    {
      "epoch": 11.64,
      "learning_rate": 7.453581094339135e-05,
      "loss": 0.9566,
      "step": 30750
    },
    {
      "epoch": 11.65,
      "learning_rate": 7.447829876438774e-05,
      "loss": 0.8972,
      "step": 30760
    },
    {
      "epoch": 11.65,
      "learning_rate": 7.442079561382089e-05,
      "loss": 0.9423,
      "step": 30770
    },
    {
      "epoch": 11.65,
      "learning_rate": 7.436330151203281e-05,
      "loss": 0.9308,
      "step": 30780
    },
    {
      "epoch": 11.66,
      "learning_rate": 7.430581647936234e-05,
      "loss": 0.935,
      "step": 30790
    },
    {
      "epoch": 11.66,
      "learning_rate": 7.424834053614515e-05,
      "loss": 0.9242,
      "step": 30800
    },
    {
      "epoch": 11.66,
      "learning_rate": 7.419087370271363e-05,
      "loss": 0.9346,
      "step": 30810
    },
    {
      "epoch": 11.67,
      "learning_rate": 7.413341599939699e-05,
      "loss": 0.95,
      "step": 30820
    },
    {
      "epoch": 11.67,
      "learning_rate": 7.407596744652117e-05,
      "loss": 0.9074,
      "step": 30830
    },
    {
      "epoch": 11.68,
      "learning_rate": 7.401852806440893e-05,
      "loss": 0.9219,
      "step": 30840
    },
    {
      "epoch": 11.68,
      "learning_rate": 7.396109787337974e-05,
      "loss": 0.9578,
      "step": 30850
    },
    {
      "epoch": 11.68,
      "learning_rate": 7.390367689374982e-05,
      "loss": 0.9085,
      "step": 30860
    },
    {
      "epoch": 11.69,
      "learning_rate": 7.384626514583217e-05,
      "loss": 0.9335,
      "step": 30870
    },
    {
      "epoch": 11.69,
      "learning_rate": 7.37888626499365e-05,
      "loss": 0.9447,
      "step": 30880
    },
    {
      "epoch": 11.7,
      "learning_rate": 7.373146942636921e-05,
      "loss": 0.9154,
      "step": 30890
    },
    {
      "epoch": 11.7,
      "learning_rate": 7.367408549543351e-05,
      "loss": 0.94,
      "step": 30900
    },
    {
      "epoch": 11.7,
      "learning_rate": 7.361671087742925e-05,
      "loss": 0.9719,
      "step": 30910
    },
    {
      "epoch": 11.71,
      "learning_rate": 7.355934559265297e-05,
      "loss": 0.9618,
      "step": 30920
    },
    {
      "epoch": 11.71,
      "learning_rate": 7.350198966139797e-05,
      "loss": 1.0217,
      "step": 30930
    },
    {
      "epoch": 11.71,
      "learning_rate": 7.344464310395424e-05,
      "loss": 0.9724,
      "step": 30940
    },
    {
      "epoch": 11.72,
      "learning_rate": 7.338730594060839e-05,
      "loss": 0.9303,
      "step": 30950
    },
    {
      "epoch": 11.72,
      "learning_rate": 7.332997819164375e-05,
      "loss": 0.9226,
      "step": 30960
    },
    {
      "epoch": 11.73,
      "learning_rate": 7.327265987734031e-05,
      "loss": 1.0077,
      "step": 30970
    },
    {
      "epoch": 11.73,
      "learning_rate": 7.321535101797475e-05,
      "loss": 0.9478,
      "step": 30980
    },
    {
      "epoch": 11.73,
      "learning_rate": 7.315805163382037e-05,
      "loss": 0.9452,
      "step": 30990
    },
    {
      "epoch": 11.74,
      "learning_rate": 7.310076174514712e-05,
      "loss": 0.9107,
      "step": 31000
    },
    {
      "epoch": 11.74,
      "learning_rate": 7.304348137222161e-05,
      "loss": 0.9535,
      "step": 31010
    },
    {
      "epoch": 11.74,
      "learning_rate": 7.298621053530709e-05,
      "loss": 0.9258,
      "step": 31020
    },
    {
      "epoch": 11.75,
      "learning_rate": 7.292894925466338e-05,
      "loss": 0.9252,
      "step": 31030
    },
    {
      "epoch": 11.75,
      "learning_rate": 7.287169755054699e-05,
      "loss": 0.9247,
      "step": 31040
    },
    {
      "epoch": 11.76,
      "learning_rate": 7.281445544321104e-05,
      "loss": 0.938,
      "step": 31050
    },
    {
      "epoch": 11.76,
      "learning_rate": 7.276294576859235e-05,
      "loss": 0.9172,
      "step": 31060
    },
    {
      "epoch": 11.76,
      "learning_rate": 7.270572195092428e-05,
      "loss": 0.9434,
      "step": 31070
    },
    {
      "epoch": 11.77,
      "learning_rate": 7.264850778875134e-05,
      "loss": 0.9779,
      "step": 31080
    },
    {
      "epoch": 11.77,
      "learning_rate": 7.259130330231337e-05,
      "loss": 0.9406,
      "step": 31090
    },
    {
      "epoch": 11.77,
      "learning_rate": 7.253410851184679e-05,
      "loss": 0.9079,
      "step": 31100
    },
    {
      "epoch": 11.78,
      "learning_rate": 7.247692343758447e-05,
      "loss": 0.9332,
      "step": 31110
    },
    {
      "epoch": 11.78,
      "learning_rate": 7.241974809975602e-05,
      "loss": 0.9688,
      "step": 31120
    },
    {
      "epoch": 11.79,
      "learning_rate": 7.236258251858751e-05,
      "loss": 0.8349,
      "step": 31130
    },
    {
      "epoch": 11.79,
      "learning_rate": 7.230542671430151e-05,
      "loss": 0.9481,
      "step": 31140
    },
    {
      "epoch": 11.79,
      "learning_rate": 7.224828070711722e-05,
      "loss": 0.9245,
      "step": 31150
    },
    {
      "epoch": 11.8,
      "learning_rate": 7.219114451725038e-05,
      "loss": 0.93,
      "step": 31160
    },
    {
      "epoch": 11.8,
      "learning_rate": 7.213401816491315e-05,
      "loss": 0.9343,
      "step": 31170
    },
    {
      "epoch": 11.81,
      "learning_rate": 7.20769016703143e-05,
      "loss": 0.9081,
      "step": 31180
    },
    {
      "epoch": 11.81,
      "learning_rate": 7.201979505365914e-05,
      "loss": 0.8731,
      "step": 31190
    },
    {
      "epoch": 11.81,
      "learning_rate": 7.196269833514938e-05,
      "loss": 0.9579,
      "step": 31200
    },
    {
      "epoch": 11.82,
      "learning_rate": 7.190561153498335e-05,
      "loss": 0.922,
      "step": 31210
    },
    {
      "epoch": 11.82,
      "learning_rate": 7.18485346733557e-05,
      "loss": 0.9206,
      "step": 31220
    },
    {
      "epoch": 11.82,
      "learning_rate": 7.179146777045775e-05,
      "loss": 0.9483,
      "step": 31230
    },
    {
      "epoch": 11.83,
      "learning_rate": 7.173441084647726e-05,
      "loss": 0.917,
      "step": 31240
    },
    {
      "epoch": 11.83,
      "learning_rate": 7.16773639215983e-05,
      "loss": 0.9069,
      "step": 31250
    },
    {
      "epoch": 11.84,
      "learning_rate": 7.162032701600158e-05,
      "loss": 0.9212,
      "step": 31260
    },
    {
      "epoch": 11.84,
      "learning_rate": 7.156330014986428e-05,
      "loss": 0.9454,
      "step": 31270
    },
    {
      "epoch": 11.84,
      "learning_rate": 7.150628334335983e-05,
      "loss": 0.9254,
      "step": 31280
    },
    {
      "epoch": 11.85,
      "learning_rate": 7.144927661665828e-05,
      "loss": 0.9918,
      "step": 31290
    },
    {
      "epoch": 11.85,
      "learning_rate": 7.139227998992612e-05,
      "loss": 0.9714,
      "step": 31300
    },
    {
      "epoch": 11.85,
      "learning_rate": 7.133529348332608e-05,
      "loss": 0.9511,
      "step": 31310
    },
    {
      "epoch": 11.86,
      "learning_rate": 7.127831711701755e-05,
      "loss": 0.8929,
      "step": 31320
    },
    {
      "epoch": 11.86,
      "learning_rate": 7.12213509111562e-05,
      "loss": 0.9075,
      "step": 31330
    },
    {
      "epoch": 11.87,
      "learning_rate": 7.116439488589407e-05,
      "loss": 0.9322,
      "step": 31340
    },
    {
      "epoch": 11.87,
      "learning_rate": 7.110744906137974e-05,
      "loss": 0.9299,
      "step": 31350
    },
    {
      "epoch": 11.87,
      "learning_rate": 7.105051345775802e-05,
      "loss": 0.9163,
      "step": 31360
    },
    {
      "epoch": 11.88,
      "learning_rate": 7.099358809517018e-05,
      "loss": 0.9506,
      "step": 31370
    },
    {
      "epoch": 11.88,
      "learning_rate": 7.093667299375395e-05,
      "loss": 0.9412,
      "step": 31380
    },
    {
      "epoch": 11.88,
      "learning_rate": 7.087976817364328e-05,
      "loss": 0.9387,
      "step": 31390
    },
    {
      "epoch": 11.89,
      "learning_rate": 7.082287365496853e-05,
      "loss": 0.9108,
      "step": 31400
    },
    {
      "epoch": 11.89,
      "learning_rate": 7.076598945785653e-05,
      "loss": 0.9,
      "step": 31410
    },
    {
      "epoch": 11.9,
      "learning_rate": 7.070911560243027e-05,
      "loss": 0.909,
      "step": 31420
    },
    {
      "epoch": 11.9,
      "learning_rate": 7.065225210880921e-05,
      "loss": 0.9474,
      "step": 31430
    },
    {
      "epoch": 11.9,
      "learning_rate": 7.059539899710918e-05,
      "loss": 0.9366,
      "step": 31440
    },
    {
      "epoch": 11.91,
      "learning_rate": 7.053855628744213e-05,
      "loss": 0.9168,
      "step": 31450
    },
    {
      "epoch": 11.91,
      "learning_rate": 7.048172399991657e-05,
      "loss": 0.8451,
      "step": 31460
    },
    {
      "epoch": 11.91,
      "learning_rate": 7.042490215463725e-05,
      "loss": 0.9396,
      "step": 31470
    },
    {
      "epoch": 11.92,
      "learning_rate": 7.036809077170508e-05,
      "loss": 0.8949,
      "step": 31480
    },
    {
      "epoch": 11.92,
      "learning_rate": 7.031128987121751e-05,
      "loss": 0.9609,
      "step": 31490
    },
    {
      "epoch": 11.93,
      "learning_rate": 7.025449947326807e-05,
      "loss": 0.8972,
      "step": 31500
    },
    {
      "epoch": 11.93,
      "learning_rate": 7.019771959794667e-05,
      "loss": 0.9328,
      "step": 31510
    },
    {
      "epoch": 11.93,
      "learning_rate": 7.014095026533958e-05,
      "loss": 0.936,
      "step": 31520
    },
    {
      "epoch": 11.94,
      "learning_rate": 7.008419149552914e-05,
      "loss": 0.9877,
      "step": 31530
    },
    {
      "epoch": 11.94,
      "learning_rate": 7.002744330859408e-05,
      "loss": 0.9898,
      "step": 31540
    },
    {
      "epoch": 11.95,
      "learning_rate": 6.997070572460948e-05,
      "loss": 0.9372,
      "step": 31550
    },
    {
      "epoch": 11.95,
      "learning_rate": 6.991397876364644e-05,
      "loss": 0.9423,
      "step": 31560
    },
    {
      "epoch": 11.95,
      "learning_rate": 6.985726244577246e-05,
      "loss": 0.9257,
      "step": 31570
    },
    {
      "epoch": 11.96,
      "learning_rate": 6.980055679105131e-05,
      "loss": 0.9003,
      "step": 31580
    },
    {
      "epoch": 11.96,
      "learning_rate": 6.974386181954279e-05,
      "loss": 0.9403,
      "step": 31590
    },
    {
      "epoch": 11.96,
      "learning_rate": 6.968717755130309e-05,
      "loss": 0.9227,
      "step": 31600
    },
    {
      "epoch": 11.97,
      "learning_rate": 6.963050400638465e-05,
      "loss": 0.9024,
      "step": 31610
    },
    {
      "epoch": 11.97,
      "learning_rate": 6.957384120483592e-05,
      "loss": 0.8884,
      "step": 31620
    },
    {
      "epoch": 11.98,
      "learning_rate": 6.951718916670173e-05,
      "loss": 0.9403,
      "step": 31630
    },
    {
      "epoch": 11.98,
      "learning_rate": 6.946054791202303e-05,
      "loss": 0.9456,
      "step": 31640
    },
    {
      "epoch": 11.98,
      "learning_rate": 6.940391746083694e-05,
      "loss": 0.9639,
      "step": 31650
    },
    {
      "epoch": 11.99,
      "learning_rate": 6.934729783317682e-05,
      "loss": 0.9348,
      "step": 31660
    },
    {
      "epoch": 11.99,
      "learning_rate": 6.929068904907212e-05,
      "loss": 0.9572,
      "step": 31670
    },
    {
      "epoch": 11.99,
      "learning_rate": 6.923409112854852e-05,
      "loss": 0.8832,
      "step": 31680
    },
    {
      "epoch": 12.0,
      "learning_rate": 6.917750409162786e-05,
      "loss": 0.9395,
      "step": 31690
    },
    {
      "epoch": 12.0,
      "learning_rate": 6.912092795832805e-05,
      "loss": 0.9543,
      "step": 31700
    },
    {
      "epoch": 12.01,
      "learning_rate": 6.906436274866324e-05,
      "loss": 0.9295,
      "step": 31710
    },
    {
      "epoch": 12.01,
      "learning_rate": 6.900780848264364e-05,
      "loss": 0.8887,
      "step": 31720
    },
    {
      "epoch": 12.01,
      "learning_rate": 6.895126518027563e-05,
      "loss": 0.8746,
      "step": 31730
    },
    {
      "epoch": 12.02,
      "learning_rate": 6.889473286156171e-05,
      "loss": 0.9016,
      "step": 31740
    },
    {
      "epoch": 12.02,
      "learning_rate": 6.88382115465005e-05,
      "loss": 0.9454,
      "step": 31750
    },
    {
      "epoch": 12.02,
      "learning_rate": 6.878170125508668e-05,
      "loss": 0.9284,
      "step": 31760
    },
    {
      "epoch": 12.03,
      "learning_rate": 6.87252020073111e-05,
      "loss": 0.9496,
      "step": 31770
    },
    {
      "epoch": 12.03,
      "learning_rate": 6.866871382316063e-05,
      "loss": 0.9344,
      "step": 31780
    },
    {
      "epoch": 12.04,
      "learning_rate": 6.861223672261827e-05,
      "loss": 0.9125,
      "step": 31790
    },
    {
      "epoch": 12.04,
      "learning_rate": 6.855577072566314e-05,
      "loss": 0.9403,
      "step": 31800
    },
    {
      "epoch": 12.04,
      "learning_rate": 6.849931585227032e-05,
      "loss": 0.933,
      "step": 31810
    },
    {
      "epoch": 12.05,
      "learning_rate": 6.844287212241107e-05,
      "loss": 0.9062,
      "step": 31820
    },
    {
      "epoch": 12.05,
      "learning_rate": 6.838643955605264e-05,
      "loss": 0.9678,
      "step": 31830
    },
    {
      "epoch": 12.05,
      "learning_rate": 6.833001817315832e-05,
      "loss": 0.9202,
      "step": 31840
    },
    {
      "epoch": 12.06,
      "learning_rate": 6.827360799368752e-05,
      "loss": 0.8767,
      "step": 31850
    },
    {
      "epoch": 12.06,
      "learning_rate": 6.821720903759562e-05,
      "loss": 0.9073,
      "step": 31860
    },
    {
      "epoch": 12.07,
      "learning_rate": 6.816082132483404e-05,
      "loss": 0.9341,
      "step": 31870
    },
    {
      "epoch": 12.07,
      "learning_rate": 6.810444487535023e-05,
      "loss": 0.9068,
      "step": 31880
    },
    {
      "epoch": 12.07,
      "learning_rate": 6.804807970908772e-05,
      "loss": 0.9241,
      "step": 31890
    },
    {
      "epoch": 12.08,
      "learning_rate": 6.799172584598588e-05,
      "loss": 0.9361,
      "step": 31900
    },
    {
      "epoch": 12.08,
      "learning_rate": 6.793538330598026e-05,
      "loss": 0.8976,
      "step": 31910
    },
    {
      "epoch": 12.09,
      "learning_rate": 6.78790521090023e-05,
      "loss": 0.8982,
      "step": 31920
    },
    {
      "epoch": 12.09,
      "learning_rate": 6.782273227497945e-05,
      "loss": 0.8807,
      "step": 31930
    },
    {
      "epoch": 12.09,
      "learning_rate": 6.77664238238352e-05,
      "loss": 0.9207,
      "step": 31940
    },
    {
      "epoch": 12.1,
      "learning_rate": 6.771012677548891e-05,
      "loss": 0.9281,
      "step": 31950
    },
    {
      "epoch": 12.1,
      "learning_rate": 6.765384114985598e-05,
      "loss": 0.8702,
      "step": 31960
    },
    {
      "epoch": 12.1,
      "learning_rate": 6.759756696684776e-05,
      "loss": 0.9282,
      "step": 31970
    },
    {
      "epoch": 12.11,
      "learning_rate": 6.75413042463715e-05,
      "loss": 0.8543,
      "step": 31980
    },
    {
      "epoch": 12.11,
      "learning_rate": 6.748505300833048e-05,
      "loss": 0.8959,
      "step": 31990
    },
    {
      "epoch": 12.12,
      "learning_rate": 6.742881327262387e-05,
      "loss": 0.8983,
      "step": 32000
    },
    {
      "epoch": 12.12,
      "learning_rate": 6.737258505914674e-05,
      "loss": 0.915,
      "step": 32010
    },
    {
      "epoch": 12.12,
      "learning_rate": 6.731636838779014e-05,
      "loss": 0.9585,
      "step": 32020
    },
    {
      "epoch": 12.13,
      "learning_rate": 6.7260163278441e-05,
      "loss": 0.979,
      "step": 32030
    },
    {
      "epoch": 12.13,
      "learning_rate": 6.720396975098218e-05,
      "loss": 0.9051,
      "step": 32040
    },
    {
      "epoch": 12.13,
      "learning_rate": 6.714778782529246e-05,
      "loss": 0.9244,
      "step": 32050
    },
    {
      "epoch": 12.14,
      "learning_rate": 6.709161752124646e-05,
      "loss": 0.9109,
      "step": 32060
    },
    {
      "epoch": 12.14,
      "learning_rate": 6.703545885871473e-05,
      "loss": 0.8502,
      "step": 32070
    },
    {
      "epoch": 12.15,
      "learning_rate": 6.697931185756374e-05,
      "loss": 0.9101,
      "step": 32080
    },
    {
      "epoch": 12.15,
      "learning_rate": 6.69231765376557e-05,
      "loss": 0.9364,
      "step": 32090
    },
    {
      "epoch": 12.15,
      "learning_rate": 6.686705291884885e-05,
      "loss": 0.9412,
      "step": 32100
    },
    {
      "epoch": 12.16,
      "learning_rate": 6.681094102099721e-05,
      "loss": 0.9548,
      "step": 32110
    },
    {
      "epoch": 12.16,
      "learning_rate": 6.67548408639506e-05,
      "loss": 0.9099,
      "step": 32120
    },
    {
      "epoch": 12.16,
      "learning_rate": 6.669875246755481e-05,
      "loss": 0.888,
      "step": 32130
    },
    {
      "epoch": 12.17,
      "learning_rate": 6.664267585165142e-05,
      "loss": 0.9066,
      "step": 32140
    },
    {
      "epoch": 12.17,
      "learning_rate": 6.658661103607775e-05,
      "loss": 0.9351,
      "step": 32150
    },
    {
      "epoch": 12.18,
      "learning_rate": 6.653055804066712e-05,
      "loss": 0.9281,
      "step": 32160
    },
    {
      "epoch": 12.18,
      "learning_rate": 6.647451688524846e-05,
      "loss": 0.914,
      "step": 32170
    },
    {
      "epoch": 12.18,
      "learning_rate": 6.641848758964673e-05,
      "loss": 0.9436,
      "step": 32180
    },
    {
      "epoch": 12.19,
      "learning_rate": 6.636247017368254e-05,
      "loss": 0.8762,
      "step": 32190
    },
    {
      "epoch": 12.19,
      "learning_rate": 6.630646465717236e-05,
      "loss": 0.8743,
      "step": 32200
    },
    {
      "epoch": 12.19,
      "learning_rate": 6.625047105992842e-05,
      "loss": 0.9519,
      "step": 32210
    },
    {
      "epoch": 12.2,
      "learning_rate": 6.619448940175878e-05,
      "loss": 0.8461,
      "step": 32220
    },
    {
      "epoch": 12.2,
      "learning_rate": 6.613851970246723e-05,
      "loss": 0.9315,
      "step": 32230
    },
    {
      "epoch": 12.21,
      "learning_rate": 6.608256198185334e-05,
      "loss": 0.9031,
      "step": 32240
    },
    {
      "epoch": 12.21,
      "learning_rate": 6.602661625971247e-05,
      "loss": 0.9305,
      "step": 32250
    },
    {
      "epoch": 12.21,
      "learning_rate": 6.59706825558357e-05,
      "loss": 0.8533,
      "step": 32260
    },
    {
      "epoch": 12.22,
      "learning_rate": 6.591476089000987e-05,
      "loss": 0.9243,
      "step": 32270
    },
    {
      "epoch": 12.22,
      "learning_rate": 6.585885128201758e-05,
      "loss": 0.9181,
      "step": 32280
    },
    {
      "epoch": 12.23,
      "learning_rate": 6.580295375163715e-05,
      "loss": 0.9501,
      "step": 32290
    },
    {
      "epoch": 12.23,
      "learning_rate": 6.574706831864263e-05,
      "loss": 0.8883,
      "step": 32300
    },
    {
      "epoch": 12.23,
      "learning_rate": 6.569119500280373e-05,
      "loss": 0.84,
      "step": 32310
    },
    {
      "epoch": 12.24,
      "learning_rate": 6.563533382388599e-05,
      "loss": 0.8801,
      "step": 32320
    },
    {
      "epoch": 12.24,
      "learning_rate": 6.557948480165064e-05,
      "loss": 0.8884,
      "step": 32330
    },
    {
      "epoch": 12.24,
      "learning_rate": 6.552364795585442e-05,
      "loss": 0.9666,
      "step": 32340
    },
    {
      "epoch": 12.25,
      "learning_rate": 6.546782330625004e-05,
      "loss": 0.9271,
      "step": 32350
    },
    {
      "epoch": 12.25,
      "learning_rate": 6.541201087258577e-05,
      "loss": 0.8604,
      "step": 32360
    },
    {
      "epoch": 12.26,
      "learning_rate": 6.535621067460545e-05,
      "loss": 0.899,
      "step": 32370
    },
    {
      "epoch": 12.26,
      "learning_rate": 6.530042273204875e-05,
      "loss": 0.8988,
      "step": 32380
    },
    {
      "epoch": 12.26,
      "learning_rate": 6.5244647064651e-05,
      "loss": 0.9259,
      "step": 32390
    },
    {
      "epoch": 12.27,
      "learning_rate": 6.518888369214305e-05,
      "loss": 0.9406,
      "step": 32400
    },
    {
      "epoch": 12.27,
      "learning_rate": 6.513313263425154e-05,
      "loss": 0.9222,
      "step": 32410
    },
    {
      "epoch": 12.27,
      "learning_rate": 6.507739391069872e-05,
      "loss": 0.8849,
      "step": 32420
    },
    {
      "epoch": 12.28,
      "learning_rate": 6.502166754120238e-05,
      "loss": 0.9082,
      "step": 32430
    },
    {
      "epoch": 12.28,
      "learning_rate": 6.496595354547613e-05,
      "loss": 0.9326,
      "step": 32440
    },
    {
      "epoch": 12.29,
      "learning_rate": 6.491025194322897e-05,
      "loss": 0.9501,
      "step": 32450
    },
    {
      "epoch": 12.29,
      "learning_rate": 6.485456275416567e-05,
      "loss": 0.8972,
      "step": 32460
    },
    {
      "epoch": 12.29,
      "learning_rate": 6.479888599798667e-05,
      "loss": 0.9053,
      "step": 32470
    },
    {
      "epoch": 12.3,
      "learning_rate": 6.47432216943878e-05,
      "loss": 0.9333,
      "step": 32480
    },
    {
      "epoch": 12.3,
      "learning_rate": 6.468756986306063e-05,
      "loss": 0.8906,
      "step": 32490
    },
    {
      "epoch": 12.3,
      "learning_rate": 6.463193052369236e-05,
      "loss": 0.8845,
      "step": 32500
    },
    {
      "epoch": 12.31,
      "learning_rate": 6.45763036959656e-05,
      "loss": 0.9157,
      "step": 32510
    },
    {
      "epoch": 12.31,
      "learning_rate": 6.452068939955868e-05,
      "loss": 0.9605,
      "step": 32520
    },
    {
      "epoch": 12.32,
      "learning_rate": 6.44650876541455e-05,
      "loss": 0.9543,
      "step": 32530
    },
    {
      "epoch": 12.32,
      "learning_rate": 6.440949847939537e-05,
      "loss": 0.9063,
      "step": 32540
    },
    {
      "epoch": 12.32,
      "learning_rate": 6.435392189497331e-05,
      "loss": 0.9485,
      "step": 32550
    },
    {
      "epoch": 12.33,
      "learning_rate": 6.429835792053989e-05,
      "loss": 0.9499,
      "step": 32560
    },
    {
      "epoch": 12.33,
      "learning_rate": 6.424280657575104e-05,
      "loss": 0.9318,
      "step": 32570
    },
    {
      "epoch": 12.34,
      "learning_rate": 6.418726788025842e-05,
      "loss": 0.899,
      "step": 32580
    },
    {
      "epoch": 12.34,
      "learning_rate": 6.41317418537091e-05,
      "loss": 0.863,
      "step": 32590
    },
    {
      "epoch": 12.34,
      "learning_rate": 6.40762285157457e-05,
      "loss": 0.9358,
      "step": 32600
    },
    {
      "epoch": 12.35,
      "learning_rate": 6.402072788600646e-05,
      "loss": 0.93,
      "step": 32610
    },
    {
      "epoch": 12.35,
      "learning_rate": 6.396523998412489e-05,
      "loss": 0.8843,
      "step": 32620
    },
    {
      "epoch": 12.35,
      "learning_rate": 6.390976482973015e-05,
      "loss": 0.9249,
      "step": 32630
    },
    {
      "epoch": 12.36,
      "learning_rate": 6.385430244244697e-05,
      "loss": 0.9209,
      "step": 32640
    },
    {
      "epoch": 12.36,
      "learning_rate": 6.379885284189533e-05,
      "loss": 0.8999,
      "step": 32650
    },
    {
      "epoch": 12.37,
      "learning_rate": 6.374341604769088e-05,
      "loss": 0.9008,
      "step": 32660
    },
    {
      "epoch": 12.37,
      "learning_rate": 6.368799207944473e-05,
      "loss": 0.9005,
      "step": 32670
    },
    {
      "epoch": 12.37,
      "learning_rate": 6.36325809567633e-05,
      "loss": 0.9118,
      "step": 32680
    },
    {
      "epoch": 12.38,
      "learning_rate": 6.357718269924861e-05,
      "loss": 0.9106,
      "step": 32690
    },
    {
      "epoch": 12.38,
      "learning_rate": 6.352179732649816e-05,
      "loss": 0.9107,
      "step": 32700
    },
    {
      "epoch": 12.38,
      "learning_rate": 6.346642485810472e-05,
      "loss": 0.9328,
      "step": 32710
    },
    {
      "epoch": 12.39,
      "learning_rate": 6.341106531365664e-05,
      "loss": 0.9361,
      "step": 32720
    },
    {
      "epoch": 12.39,
      "learning_rate": 6.335571871273762e-05,
      "loss": 0.9414,
      "step": 32730
    },
    {
      "epoch": 12.4,
      "learning_rate": 6.330038507492681e-05,
      "loss": 0.9227,
      "step": 32740
    },
    {
      "epoch": 12.4,
      "learning_rate": 6.324506441979885e-05,
      "loss": 0.8471,
      "step": 32750
    },
    {
      "epoch": 12.4,
      "learning_rate": 6.318975676692363e-05,
      "loss": 0.9106,
      "step": 32760
    },
    {
      "epoch": 12.41,
      "learning_rate": 6.313446213586654e-05,
      "loss": 0.8804,
      "step": 32770
    },
    {
      "epoch": 12.41,
      "learning_rate": 6.30791805461884e-05,
      "loss": 0.9315,
      "step": 32780
    },
    {
      "epoch": 12.41,
      "learning_rate": 6.302391201744531e-05,
      "loss": 0.9057,
      "step": 32790
    },
    {
      "epoch": 12.42,
      "learning_rate": 6.296865656918883e-05,
      "loss": 0.8787,
      "step": 32800
    },
    {
      "epoch": 12.42,
      "learning_rate": 6.291341422096586e-05,
      "loss": 0.9261,
      "step": 32810
    },
    {
      "epoch": 12.43,
      "learning_rate": 6.285818499231866e-05,
      "loss": 0.9651,
      "step": 32820
    },
    {
      "epoch": 12.43,
      "learning_rate": 6.280296890278488e-05,
      "loss": 0.9376,
      "step": 32830
    },
    {
      "epoch": 12.43,
      "learning_rate": 6.274776597189754e-05,
      "loss": 0.9339,
      "step": 32840
    },
    {
      "epoch": 12.44,
      "learning_rate": 6.269257621918488e-05,
      "loss": 0.9544,
      "step": 32850
    },
    {
      "epoch": 12.44,
      "learning_rate": 6.263739966417063e-05,
      "loss": 0.9184,
      "step": 32860
    },
    {
      "epoch": 12.44,
      "learning_rate": 6.258223632637377e-05,
      "loss": 0.9342,
      "step": 32870
    },
    {
      "epoch": 12.45,
      "learning_rate": 6.252708622530861e-05,
      "loss": 0.9096,
      "step": 32880
    },
    {
      "epoch": 12.45,
      "learning_rate": 6.247194938048482e-05,
      "loss": 0.9115,
      "step": 32890
    },
    {
      "epoch": 12.46,
      "learning_rate": 6.241682581140733e-05,
      "loss": 0.9233,
      "step": 32900
    },
    {
      "epoch": 12.46,
      "learning_rate": 6.23617155375764e-05,
      "loss": 0.9401,
      "step": 32910
    },
    {
      "epoch": 12.46,
      "learning_rate": 6.230661857848758e-05,
      "loss": 0.9534,
      "step": 32920
    },
    {
      "epoch": 12.47,
      "learning_rate": 6.225153495363171e-05,
      "loss": 0.8951,
      "step": 32930
    },
    {
      "epoch": 12.47,
      "learning_rate": 6.21964646824949e-05,
      "loss": 0.9417,
      "step": 32940
    },
    {
      "epoch": 12.48,
      "learning_rate": 6.214140778455859e-05,
      "loss": 0.9549,
      "step": 32950
    },
    {
      "epoch": 12.48,
      "learning_rate": 6.20863642792994e-05,
      "loss": 0.9193,
      "step": 32960
    },
    {
      "epoch": 12.48,
      "learning_rate": 6.203133418618928e-05,
      "loss": 0.9274,
      "step": 32970
    },
    {
      "epoch": 12.49,
      "learning_rate": 6.197631752469544e-05,
      "loss": 0.893,
      "step": 32980
    },
    {
      "epoch": 12.49,
      "learning_rate": 6.192131431428027e-05,
      "loss": 0.9541,
      "step": 32990
    },
    {
      "epoch": 12.49,
      "learning_rate": 6.18663245744015e-05,
      "loss": 0.8887,
      "step": 33000
    },
    {
      "epoch": 12.5,
      "learning_rate": 6.181134832451198e-05,
      "loss": 0.9164,
      "step": 33010
    },
    {
      "epoch": 12.5,
      "learning_rate": 6.175638558405989e-05,
      "loss": 0.9517,
      "step": 33020
    },
    {
      "epoch": 12.51,
      "learning_rate": 6.17014363724886e-05,
      "loss": 0.9545,
      "step": 33030
    },
    {
      "epoch": 12.51,
      "learning_rate": 6.164650070923663e-05,
      "loss": 0.9307,
      "step": 33040
    },
    {
      "epoch": 12.51,
      "learning_rate": 6.159157861373782e-05,
      "loss": 0.8921,
      "step": 33050
    },
    {
      "epoch": 12.52,
      "learning_rate": 6.153667010542112e-05,
      "loss": 0.912,
      "step": 33060
    },
    {
      "epoch": 12.52,
      "learning_rate": 6.148177520371073e-05,
      "loss": 0.9211,
      "step": 33070
    },
    {
      "epoch": 12.52,
      "learning_rate": 6.142689392802597e-05,
      "loss": 0.9243,
      "step": 33080
    },
    {
      "epoch": 12.53,
      "learning_rate": 6.137202629778141e-05,
      "loss": 0.9215,
      "step": 33090
    },
    {
      "epoch": 12.53,
      "learning_rate": 6.131717233238676e-05,
      "loss": 0.9136,
      "step": 33100
    },
    {
      "epoch": 12.54,
      "learning_rate": 6.126233205124692e-05,
      "loss": 0.9133,
      "step": 33110
    },
    {
      "epoch": 12.54,
      "learning_rate": 6.120750547376189e-05,
      "loss": 0.9149,
      "step": 33120
    },
    {
      "epoch": 12.54,
      "learning_rate": 6.115269261932687e-05,
      "loss": 0.9206,
      "step": 33130
    },
    {
      "epoch": 12.55,
      "learning_rate": 6.109789350733224e-05,
      "loss": 0.9306,
      "step": 33140
    },
    {
      "epoch": 12.55,
      "learning_rate": 6.10431081571634e-05,
      "loss": 0.9302,
      "step": 33150
    },
    {
      "epoch": 12.55,
      "learning_rate": 6.0988336588201036e-05,
      "loss": 0.931,
      "step": 33160
    },
    {
      "epoch": 12.56,
      "learning_rate": 6.0933578819820844e-05,
      "loss": 0.9273,
      "step": 33170
    },
    {
      "epoch": 12.56,
      "learning_rate": 6.0878834871393666e-05,
      "loss": 0.9646,
      "step": 33180
    },
    {
      "epoch": 12.57,
      "learning_rate": 6.082410476228546e-05,
      "loss": 0.9685,
      "step": 33190
    },
    {
      "epoch": 12.57,
      "learning_rate": 6.0769388511857336e-05,
      "loss": 0.9167,
      "step": 33200
    },
    {
      "epoch": 12.57,
      "learning_rate": 6.07146861394654e-05,
      "loss": 0.9349,
      "step": 33210
    },
    {
      "epoch": 12.58,
      "learning_rate": 6.0659997664460935e-05,
      "loss": 0.9094,
      "step": 33220
    },
    {
      "epoch": 12.58,
      "learning_rate": 6.060532310619028e-05,
      "loss": 0.9787,
      "step": 33230
    },
    {
      "epoch": 12.58,
      "learning_rate": 6.0550662483994835e-05,
      "loss": 0.9617,
      "step": 33240
    },
    {
      "epoch": 12.59,
      "learning_rate": 6.049601581721112e-05,
      "loss": 0.9445,
      "step": 33250
    },
    {
      "epoch": 12.59,
      "learning_rate": 6.0441383125170606e-05,
      "loss": 0.9297,
      "step": 33260
    },
    {
      "epoch": 12.6,
      "learning_rate": 6.0386764427199946e-05,
      "loss": 0.9259,
      "step": 33270
    },
    {
      "epoch": 12.6,
      "learning_rate": 6.0332159742620855e-05,
      "loss": 0.903,
      "step": 33280
    },
    {
      "epoch": 12.6,
      "learning_rate": 6.0277569090749886e-05,
      "loss": 0.9036,
      "step": 33290
    },
    {
      "epoch": 12.61,
      "learning_rate": 6.022299249089889e-05,
      "loss": 0.9988,
      "step": 33300
    },
    {
      "epoch": 12.61,
      "learning_rate": 6.016842996237461e-05,
      "loss": 0.9377,
      "step": 33310
    },
    {
      "epoch": 12.62,
      "learning_rate": 6.0113881524478744e-05,
      "loss": 0.9061,
      "step": 33320
    },
    {
      "epoch": 12.62,
      "learning_rate": 6.0059347196508186e-05,
      "loss": 0.9352,
      "step": 33330
    },
    {
      "epoch": 12.62,
      "learning_rate": 6.000482699775472e-05,
      "loss": 0.9528,
      "step": 33340
    },
    {
      "epoch": 12.63,
      "learning_rate": 5.9950320947505125e-05,
      "loss": 0.9028,
      "step": 33350
    },
    {
      "epoch": 12.63,
      "learning_rate": 5.989582906504123e-05,
      "loss": 0.8991,
      "step": 33360
    },
    {
      "epoch": 12.63,
      "learning_rate": 5.9841351369639844e-05,
      "loss": 0.9393,
      "step": 33370
    },
    {
      "epoch": 12.64,
      "learning_rate": 5.978688788057269e-05,
      "loss": 0.8979,
      "step": 33380
    },
    {
      "epoch": 12.64,
      "learning_rate": 5.973243861710658e-05,
      "loss": 0.9517,
      "step": 33390
    },
    {
      "epoch": 12.65,
      "learning_rate": 5.967800359850313e-05,
      "loss": 0.9115,
      "step": 33400
    },
    {
      "epoch": 12.65,
      "learning_rate": 5.962358284401909e-05,
      "loss": 0.9523,
      "step": 33410
    },
    {
      "epoch": 12.65,
      "learning_rate": 5.956917637290612e-05,
      "loss": 0.931,
      "step": 33420
    },
    {
      "epoch": 12.66,
      "learning_rate": 5.951478420441069e-05,
      "loss": 0.9269,
      "step": 33430
    },
    {
      "epoch": 12.66,
      "learning_rate": 5.94604063577744e-05,
      "loss": 0.8978,
      "step": 33440
    },
    {
      "epoch": 12.66,
      "learning_rate": 5.9406042852233724e-05,
      "loss": 0.9197,
      "step": 33450
    },
    {
      "epoch": 12.67,
      "learning_rate": 5.935169370701993e-05,
      "loss": 0.904,
      "step": 33460
    },
    {
      "epoch": 12.67,
      "learning_rate": 5.92973589413594e-05,
      "loss": 0.917,
      "step": 33470
    },
    {
      "epoch": 12.68,
      "learning_rate": 5.924303857447338e-05,
      "loss": 0.9267,
      "step": 33480
    },
    {
      "epoch": 12.68,
      "learning_rate": 5.918873262557785e-05,
      "loss": 0.9042,
      "step": 33490
    },
    {
      "epoch": 12.68,
      "learning_rate": 5.9134441113883945e-05,
      "loss": 0.9014,
      "step": 33500
    },
    {
      "epoch": 12.69,
      "learning_rate": 5.9080164058597575e-05,
      "loss": 0.876,
      "step": 33510
    },
    {
      "epoch": 12.69,
      "learning_rate": 5.902590147891942e-05,
      "loss": 0.9582,
      "step": 33520
    },
    {
      "epoch": 12.69,
      "learning_rate": 5.897165339404531e-05,
      "loss": 0.8577,
      "step": 33530
    },
    {
      "epoch": 12.7,
      "learning_rate": 5.891741982316568e-05,
      "loss": 0.9753,
      "step": 33540
    },
    {
      "epoch": 12.7,
      "learning_rate": 5.886320078546595e-05,
      "loss": 0.9018,
      "step": 33550
    },
    {
      "epoch": 12.71,
      "learning_rate": 5.880899630012648e-05,
      "loss": 0.8947,
      "step": 33560
    },
    {
      "epoch": 12.71,
      "learning_rate": 5.875480638632229e-05,
      "loss": 0.9219,
      "step": 33570
    },
    {
      "epoch": 12.71,
      "learning_rate": 5.870063106322337e-05,
      "loss": 0.9364,
      "step": 33580
    },
    {
      "epoch": 12.72,
      "learning_rate": 5.8646470349994596e-05,
      "loss": 0.9245,
      "step": 33590
    },
    {
      "epoch": 12.72,
      "learning_rate": 5.859232426579553e-05,
      "loss": 0.9029,
      "step": 33600
    },
    {
      "epoch": 12.73,
      "learning_rate": 5.853819282978065e-05,
      "loss": 0.9611,
      "step": 33610
    },
    {
      "epoch": 12.73,
      "learning_rate": 5.848407606109929e-05,
      "loss": 0.8882,
      "step": 33620
    },
    {
      "epoch": 12.73,
      "learning_rate": 5.842997397889548e-05,
      "loss": 0.9321,
      "step": 33630
    },
    {
      "epoch": 12.74,
      "learning_rate": 5.837588660230811e-05,
      "loss": 0.881,
      "step": 33640
    },
    {
      "epoch": 12.74,
      "learning_rate": 5.832181395047098e-05,
      "loss": 0.9227,
      "step": 33650
    },
    {
      "epoch": 12.74,
      "learning_rate": 5.826775604251245e-05,
      "loss": 0.9221,
      "step": 33660
    },
    {
      "epoch": 12.75,
      "learning_rate": 5.821371289755586e-05,
      "loss": 0.9907,
      "step": 33670
    },
    {
      "epoch": 12.75,
      "learning_rate": 5.816508670526275e-05,
      "loss": 0.9126,
      "step": 33680
    },
    {
      "epoch": 12.76,
      "learning_rate": 5.811107166267571e-05,
      "loss": 0.9335,
      "step": 33690
    },
    {
      "epoch": 12.76,
      "learning_rate": 5.805707143851853e-05,
      "loss": 0.9359,
      "step": 33700
    },
    {
      "epoch": 12.76,
      "learning_rate": 5.800308605189404e-05,
      "loss": 0.9078,
      "step": 33710
    },
    {
      "epoch": 12.77,
      "learning_rate": 5.79491155218999e-05,
      "loss": 0.9014,
      "step": 33720
    },
    {
      "epoch": 12.77,
      "learning_rate": 5.78951598676285e-05,
      "loss": 0.9134,
      "step": 33730
    },
    {
      "epoch": 12.77,
      "learning_rate": 5.7841219108166836e-05,
      "loss": 0.8906,
      "step": 33740
    },
    {
      "epoch": 12.78,
      "learning_rate": 5.77872932625968e-05,
      "loss": 0.9189,
      "step": 33750
    },
    {
      "epoch": 12.78,
      "learning_rate": 5.7733382349994925e-05,
      "loss": 0.8866,
      "step": 33760
    },
    {
      "epoch": 12.79,
      "learning_rate": 5.76794863894325e-05,
      "loss": 0.9747,
      "step": 33770
    },
    {
      "epoch": 12.79,
      "learning_rate": 5.762560539997554e-05,
      "loss": 0.9276,
      "step": 33780
    },
    {
      "epoch": 12.79,
      "learning_rate": 5.757173940068464e-05,
      "loss": 0.9146,
      "step": 33790
    },
    {
      "epoch": 12.8,
      "learning_rate": 5.751788841061524e-05,
      "loss": 0.937,
      "step": 33800
    },
    {
      "epoch": 12.8,
      "learning_rate": 5.746405244881741e-05,
      "loss": 0.9186,
      "step": 33810
    },
    {
      "epoch": 12.8,
      "learning_rate": 5.741023153433588e-05,
      "loss": 0.9637,
      "step": 33820
    },
    {
      "epoch": 12.81,
      "learning_rate": 5.7356425686210115e-05,
      "loss": 0.8823,
      "step": 33830
    },
    {
      "epoch": 12.81,
      "learning_rate": 5.7302634923474244e-05,
      "loss": 0.9624,
      "step": 33840
    },
    {
      "epoch": 12.82,
      "learning_rate": 5.724885926515695e-05,
      "loss": 0.9309,
      "step": 33850
    },
    {
      "epoch": 12.82,
      "learning_rate": 5.7195098730281705e-05,
      "loss": 0.8688,
      "step": 33860
    },
    {
      "epoch": 12.82,
      "learning_rate": 5.7141353337866575e-05,
      "loss": 0.928,
      "step": 33870
    },
    {
      "epoch": 12.83,
      "learning_rate": 5.7087623106924284e-05,
      "loss": 0.9281,
      "step": 33880
    },
    {
      "epoch": 12.83,
      "learning_rate": 5.7033908056462184e-05,
      "loss": 0.9368,
      "step": 33890
    },
    {
      "epoch": 12.83,
      "learning_rate": 5.698020820548229e-05,
      "loss": 0.9449,
      "step": 33900
    },
    {
      "epoch": 12.84,
      "learning_rate": 5.692652357298114e-05,
      "loss": 0.9019,
      "step": 33910
    },
    {
      "epoch": 12.84,
      "learning_rate": 5.687285417795003e-05,
      "loss": 0.8896,
      "step": 33920
    },
    {
      "epoch": 12.85,
      "learning_rate": 5.6819200039374665e-05,
      "loss": 0.9369,
      "step": 33930
    },
    {
      "epoch": 12.85,
      "learning_rate": 5.676556117623562e-05,
      "loss": 0.9042,
      "step": 33940
    },
    {
      "epoch": 12.85,
      "learning_rate": 5.67119376075079e-05,
      "loss": 0.9204,
      "step": 33950
    },
    {
      "epoch": 12.86,
      "learning_rate": 5.665832935216107e-05,
      "loss": 0.9431,
      "step": 33960
    },
    {
      "epoch": 12.86,
      "learning_rate": 5.660473642915937e-05,
      "loss": 0.9243,
      "step": 33970
    },
    {
      "epoch": 12.87,
      "learning_rate": 5.65511588574616e-05,
      "loss": 0.9599,
      "step": 33980
    },
    {
      "epoch": 12.87,
      "learning_rate": 5.6497596656021016e-05,
      "loss": 0.9338,
      "step": 33990
    },
    {
      "epoch": 12.87,
      "learning_rate": 5.644404984378563e-05,
      "loss": 0.96,
      "step": 34000
    },
    {
      "epoch": 12.88,
      "learning_rate": 5.639051843969792e-05,
      "loss": 0.8898,
      "step": 34010
    },
    {
      "epoch": 12.88,
      "learning_rate": 5.633700246269482e-05,
      "loss": 0.9245,
      "step": 34020
    },
    {
      "epoch": 12.88,
      "learning_rate": 5.6283501931707924e-05,
      "loss": 0.9226,
      "step": 34030
    },
    {
      "epoch": 12.89,
      "learning_rate": 5.6230016865663334e-05,
      "loss": 0.9511,
      "step": 34040
    },
    {
      "epoch": 12.89,
      "learning_rate": 5.617654728348168e-05,
      "loss": 0.8965,
      "step": 34050
    },
    {
      "epoch": 12.9,
      "learning_rate": 5.612309320407815e-05,
      "loss": 0.9738,
      "step": 34060
    },
    {
      "epoch": 12.9,
      "learning_rate": 5.6069654646362314e-05,
      "loss": 0.9522,
      "step": 34070
    },
    {
      "epoch": 12.9,
      "learning_rate": 5.6016231629238393e-05,
      "loss": 0.9061,
      "step": 34080
    },
    {
      "epoch": 12.91,
      "learning_rate": 5.5962824171605085e-05,
      "loss": 0.9137,
      "step": 34090
    },
    {
      "epoch": 12.91,
      "learning_rate": 5.590943229235548e-05,
      "loss": 0.857,
      "step": 34100
    },
    {
      "epoch": 12.91,
      "learning_rate": 5.5856056010377314e-05,
      "loss": 0.9448,
      "step": 34110
    },
    {
      "epoch": 12.92,
      "learning_rate": 5.5802695344552755e-05,
      "loss": 0.9623,
      "step": 34120
    },
    {
      "epoch": 12.92,
      "learning_rate": 5.574935031375834e-05,
      "loss": 0.9193,
      "step": 34130
    },
    {
      "epoch": 12.93,
      "learning_rate": 5.569602093686519e-05,
      "loss": 0.939,
      "step": 34140
    },
    {
      "epoch": 12.93,
      "learning_rate": 5.564270723273888e-05,
      "loss": 0.9498,
      "step": 34150
    },
    {
      "epoch": 12.93,
      "learning_rate": 5.558940922023932e-05,
      "loss": 0.9953,
      "step": 34160
    },
    {
      "epoch": 12.94,
      "learning_rate": 5.5536126918221096e-05,
      "loss": 0.9212,
      "step": 34170
    },
    {
      "epoch": 12.94,
      "learning_rate": 5.548286034553302e-05,
      "loss": 0.9558,
      "step": 34180
    },
    {
      "epoch": 12.94,
      "learning_rate": 5.5429609521018436e-05,
      "loss": 0.8805,
      "step": 34190
    },
    {
      "epoch": 12.95,
      "learning_rate": 5.537637446351515e-05,
      "loss": 0.9035,
      "step": 34200
    },
    {
      "epoch": 12.95,
      "learning_rate": 5.532315519185527e-05,
      "loss": 0.9453,
      "step": 34210
    },
    {
      "epoch": 12.96,
      "learning_rate": 5.526995172486539e-05,
      "loss": 0.9212,
      "step": 34220
    },
    {
      "epoch": 12.96,
      "learning_rate": 5.522208213312315e-05,
      "loss": 0.9398,
      "step": 34230
    },
    {
      "epoch": 12.96,
      "learning_rate": 5.516890874685361e-05,
      "loss": 0.8936,
      "step": 34240
    },
    {
      "epoch": 12.97,
      "learning_rate": 5.511575121981964e-05,
      "loss": 0.8981,
      "step": 34250
    },
    {
      "epoch": 12.97,
      "learning_rate": 5.506260957082599e-05,
      "loss": 0.8683,
      "step": 34260
    },
    {
      "epoch": 12.97,
      "learning_rate": 5.5009483818671746e-05,
      "loss": 0.9096,
      "step": 34270
    },
    {
      "epoch": 12.98,
      "learning_rate": 5.495637398215048e-05,
      "loss": 0.9537,
      "step": 34280
    },
    {
      "epoch": 12.98,
      "learning_rate": 5.4903280080050026e-05,
      "loss": 0.8882,
      "step": 34290
    },
    {
      "epoch": 12.99,
      "learning_rate": 5.4850202131152594e-05,
      "loss": 0.9795,
      "step": 34300
    },
    {
      "epoch": 12.99,
      "learning_rate": 5.4797140154234935e-05,
      "loss": 0.9395,
      "step": 34310
    },
    {
      "epoch": 12.99,
      "learning_rate": 5.474409416806789e-05,
      "loss": 0.9283,
      "step": 34320
    },
    {
      "epoch": 13.0,
      "learning_rate": 5.4691064191416785e-05,
      "loss": 0.9651,
      "step": 34330
    },
    {
      "epoch": 13.0,
      "learning_rate": 5.463805024304128e-05,
      "loss": 0.9063,
      "step": 34340
    },
    {
      "epoch": 13.01,
      "learning_rate": 5.458505234169529e-05,
      "loss": 0.8801,
      "step": 34350
    },
    {
      "epoch": 13.01,
      "learning_rate": 5.453207050612707e-05,
      "loss": 0.9841,
      "step": 34360
    },
    {
      "epoch": 13.01,
      "learning_rate": 5.447910475507938e-05,
      "loss": 0.9167,
      "step": 34370
    },
    {
      "epoch": 13.02,
      "learning_rate": 5.442615510728899e-05,
      "loss": 0.9281,
      "step": 34380
    },
    {
      "epoch": 13.02,
      "learning_rate": 5.437322158148716e-05,
      "loss": 0.9615,
      "step": 34390
    },
    {
      "epoch": 13.02,
      "learning_rate": 5.432030419639944e-05,
      "loss": 0.9212,
      "step": 34400
    },
    {
      "epoch": 13.03,
      "learning_rate": 5.426740297074557e-05,
      "loss": 0.9043,
      "step": 34410
    },
    {
      "epoch": 13.03,
      "learning_rate": 5.421451792323968e-05,
      "loss": 0.9426,
      "step": 34420
    },
    {
      "epoch": 13.04,
      "learning_rate": 5.416164907259013e-05,
      "loss": 0.8864,
      "step": 34430
    },
    {
      "epoch": 13.04,
      "learning_rate": 5.410879643749954e-05,
      "loss": 0.8787,
      "step": 34440
    },
    {
      "epoch": 13.04,
      "learning_rate": 5.405596003666487e-05,
      "loss": 0.9558,
      "step": 34450
    },
    {
      "epoch": 13.05,
      "learning_rate": 5.4003139888777175e-05,
      "loss": 0.9365,
      "step": 34460
    },
    {
      "epoch": 13.05,
      "learning_rate": 5.395033601252193e-05,
      "loss": 0.8765,
      "step": 34470
    },
    {
      "epoch": 13.05,
      "learning_rate": 5.389754842657875e-05,
      "loss": 0.9217,
      "step": 34480
    },
    {
      "epoch": 13.06,
      "learning_rate": 5.3844777149621554e-05,
      "loss": 0.9756,
      "step": 34490
    },
    {
      "epoch": 13.06,
      "learning_rate": 5.379202220031845e-05,
      "loss": 0.9029,
      "step": 34500
    },
    {
      "epoch": 13.07,
      "learning_rate": 5.373928359733181e-05,
      "loss": 0.9039,
      "step": 34510
    },
    {
      "epoch": 13.07,
      "learning_rate": 5.3686561359318134e-05,
      "loss": 0.883,
      "step": 34520
    },
    {
      "epoch": 13.07,
      "learning_rate": 5.363385550492821e-05,
      "loss": 0.9795,
      "step": 34530
    },
    {
      "epoch": 13.08,
      "learning_rate": 5.358116605280702e-05,
      "loss": 0.8848,
      "step": 34540
    },
    {
      "epoch": 13.08,
      "learning_rate": 5.352849302159375e-05,
      "loss": 0.9435,
      "step": 34550
    },
    {
      "epoch": 13.08,
      "learning_rate": 5.3475836429921776e-05,
      "loss": 0.9465,
      "step": 34560
    },
    {
      "epoch": 13.09,
      "learning_rate": 5.34231962964186e-05,
      "loss": 0.9203,
      "step": 34570
    },
    {
      "epoch": 13.09,
      "learning_rate": 5.3370572639705964e-05,
      "loss": 0.8984,
      "step": 34580
    },
    {
      "epoch": 13.1,
      "learning_rate": 5.331796547839977e-05,
      "loss": 0.8955,
      "step": 34590
    },
    {
      "epoch": 13.1,
      "learning_rate": 5.326537483111007e-05,
      "loss": 0.8871,
      "step": 34600
    },
    {
      "epoch": 13.1,
      "learning_rate": 5.32128007164411e-05,
      "loss": 0.9478,
      "step": 34610
    },
    {
      "epoch": 13.11,
      "learning_rate": 5.316024315299127e-05,
      "loss": 0.8671,
      "step": 34620
    },
    {
      "epoch": 13.11,
      "learning_rate": 5.310770215935301e-05,
      "loss": 0.8996,
      "step": 34630
    },
    {
      "epoch": 13.12,
      "learning_rate": 5.3055177754113016e-05,
      "loss": 0.8591,
      "step": 34640
    },
    {
      "epoch": 13.12,
      "learning_rate": 5.300266995585206e-05,
      "loss": 0.9425,
      "step": 34650
    },
    {
      "epoch": 13.12,
      "learning_rate": 5.2950178783145074e-05,
      "loss": 0.9011,
      "step": 34660
    },
    {
      "epoch": 13.13,
      "learning_rate": 5.2897704254561086e-05,
      "loss": 0.9126,
      "step": 34670
    },
    {
      "epoch": 13.13,
      "learning_rate": 5.284524638866326e-05,
      "loss": 0.9358,
      "step": 34680
    },
    {
      "epoch": 13.13,
      "learning_rate": 5.279280520400878e-05,
      "loss": 0.8916,
      "step": 34690
    },
    {
      "epoch": 13.14,
      "learning_rate": 5.274038071914902e-05,
      "loss": 0.8925,
      "step": 34700
    },
    {
      "epoch": 13.14,
      "learning_rate": 5.268797295262944e-05,
      "loss": 0.8917,
      "step": 34710
    },
    {
      "epoch": 13.15,
      "learning_rate": 5.263558192298954e-05,
      "loss": 0.9079,
      "step": 34720
    },
    {
      "epoch": 13.15,
      "learning_rate": 5.258320764876298e-05,
      "loss": 0.9544,
      "step": 34730
    },
    {
      "epoch": 13.15,
      "learning_rate": 5.253085014847734e-05,
      "loss": 0.9043,
      "step": 34740
    },
    {
      "epoch": 13.16,
      "learning_rate": 5.2478509440654424e-05,
      "loss": 0.8669,
      "step": 34750
    },
    {
      "epoch": 13.16,
      "learning_rate": 5.242618554381003e-05,
      "loss": 0.9283,
      "step": 34760
    },
    {
      "epoch": 13.16,
      "learning_rate": 5.237387847645398e-05,
      "loss": 0.9381,
      "step": 34770
    },
    {
      "epoch": 13.17,
      "learning_rate": 5.232158825709022e-05,
      "loss": 0.9253,
      "step": 34780
    },
    {
      "epoch": 13.17,
      "learning_rate": 5.2269314904216714e-05,
      "loss": 0.8567,
      "step": 34790
    },
    {
      "epoch": 13.18,
      "learning_rate": 5.221705843632535e-05,
      "loss": 0.9029,
      "step": 34800
    },
    {
      "epoch": 13.18,
      "learning_rate": 5.2164818871902175e-05,
      "loss": 0.9162,
      "step": 34810
    },
    {
      "epoch": 13.18,
      "learning_rate": 5.211259622942721e-05,
      "loss": 0.9035,
      "step": 34820
    },
    {
      "epoch": 13.19,
      "learning_rate": 5.2060390527374503e-05,
      "loss": 0.9728,
      "step": 34830
    },
    {
      "epoch": 13.19,
      "learning_rate": 5.200820178421213e-05,
      "loss": 0.9031,
      "step": 34840
    },
    {
      "epoch": 13.19,
      "learning_rate": 5.1956030018402046e-05,
      "loss": 0.9205,
      "step": 34850
    },
    {
      "epoch": 13.2,
      "learning_rate": 5.190387524840033e-05,
      "loss": 0.8988,
      "step": 34860
    },
    {
      "epoch": 13.2,
      "learning_rate": 5.185173749265701e-05,
      "loss": 0.9278,
      "step": 34870
    },
    {
      "epoch": 13.21,
      "learning_rate": 5.179961676961611e-05,
      "loss": 0.9485,
      "step": 34880
    },
    {
      "epoch": 13.21,
      "learning_rate": 5.174751309771559e-05,
      "loss": 0.8966,
      "step": 34890
    },
    {
      "epoch": 13.21,
      "learning_rate": 5.1695426495387434e-05,
      "loss": 0.9746,
      "step": 34900
    },
    {
      "epoch": 13.22,
      "learning_rate": 5.16433569810575e-05,
      "loss": 0.9095,
      "step": 34910
    },
    {
      "epoch": 13.22,
      "learning_rate": 5.159130457314567e-05,
      "loss": 0.9496,
      "step": 34920
    },
    {
      "epoch": 13.22,
      "learning_rate": 5.153926929006578e-05,
      "loss": 0.8565,
      "step": 34930
    },
    {
      "epoch": 13.23,
      "learning_rate": 5.1487251150225566e-05,
      "loss": 0.8738,
      "step": 34940
    },
    {
      "epoch": 13.23,
      "learning_rate": 5.143525017202673e-05,
      "loss": 0.9099,
      "step": 34950
    },
    {
      "epoch": 13.24,
      "learning_rate": 5.138326637386493e-05,
      "loss": 0.889,
      "step": 34960
    },
    {
      "epoch": 13.24,
      "learning_rate": 5.133129977412961e-05,
      "loss": 0.9033,
      "step": 34970
    },
    {
      "epoch": 13.24,
      "learning_rate": 5.127935039120431e-05,
      "loss": 0.8817,
      "step": 34980
    },
    {
      "epoch": 13.25,
      "learning_rate": 5.122741824346637e-05,
      "loss": 0.8972,
      "step": 34990
    },
    {
      "epoch": 13.25,
      "learning_rate": 5.117550334928708e-05,
      "loss": 0.9394,
      "step": 35000
    },
    {
      "epoch": 13.26,
      "learning_rate": 5.1123605727031635e-05,
      "loss": 0.8598,
      "step": 35010
    },
    {
      "epoch": 13.26,
      "learning_rate": 5.107172539505902e-05,
      "loss": 0.9047,
      "step": 35020
    },
    {
      "epoch": 13.26,
      "learning_rate": 5.10198623717222e-05,
      "loss": 0.8935,
      "step": 35030
    },
    {
      "epoch": 13.27,
      "learning_rate": 5.096801667536801e-05,
      "loss": 0.9132,
      "step": 35040
    },
    {
      "epoch": 13.27,
      "learning_rate": 5.0916188324337155e-05,
      "loss": 0.8776,
      "step": 35050
    },
    {
      "epoch": 13.27,
      "learning_rate": 5.086437733696415e-05,
      "loss": 0.8759,
      "step": 35060
    },
    {
      "epoch": 13.28,
      "learning_rate": 5.0812583731577466e-05,
      "loss": 0.9013,
      "step": 35070
    },
    {
      "epoch": 13.28,
      "learning_rate": 5.07608075264993e-05,
      "loss": 0.9156,
      "step": 35080
    },
    {
      "epoch": 13.29,
      "learning_rate": 5.0709048740045764e-05,
      "loss": 0.9377,
      "step": 35090
    },
    {
      "epoch": 13.29,
      "learning_rate": 5.065730739052683e-05,
      "loss": 0.9204,
      "step": 35100
    },
    {
      "epoch": 13.29,
      "learning_rate": 5.060558349624627e-05,
      "loss": 0.9115,
      "step": 35110
    },
    {
      "epoch": 13.3,
      "learning_rate": 5.05538770755017e-05,
      "loss": 0.8761,
      "step": 35120
    },
    {
      "epoch": 13.3,
      "learning_rate": 5.050218814658449e-05,
      "loss": 0.9228,
      "step": 35130
    },
    {
      "epoch": 13.3,
      "learning_rate": 5.045051672777991e-05,
      "loss": 0.8658,
      "step": 35140
    },
    {
      "epoch": 13.31,
      "learning_rate": 5.039886283736701e-05,
      "loss": 0.8726,
      "step": 35150
    },
    {
      "epoch": 13.31,
      "learning_rate": 5.0347226493618536e-05,
      "loss": 0.8901,
      "step": 35160
    },
    {
      "epoch": 13.32,
      "learning_rate": 5.029560771480123e-05,
      "loss": 0.8825,
      "step": 35170
    },
    {
      "epoch": 13.32,
      "learning_rate": 5.02440065191755e-05,
      "loss": 0.894,
      "step": 35180
    },
    {
      "epoch": 13.32,
      "learning_rate": 5.019242292499546e-05,
      "loss": 0.8816,
      "step": 35190
    },
    {
      "epoch": 13.33,
      "learning_rate": 5.014085695050914e-05,
      "loss": 0.9253,
      "step": 35200
    },
    {
      "epoch": 13.33,
      "learning_rate": 5.0089308613958296e-05,
      "loss": 0.9017,
      "step": 35210
    },
    {
      "epoch": 13.33,
      "learning_rate": 5.003777793357831e-05,
      "loss": 0.9061,
      "step": 35220
    },
    {
      "epoch": 13.34,
      "learning_rate": 4.998626492759856e-05,
      "loss": 0.9156,
      "step": 35230
    },
    {
      "epoch": 13.34,
      "learning_rate": 4.9934769614242025e-05,
      "loss": 0.891,
      "step": 35240
    },
    {
      "epoch": 13.35,
      "learning_rate": 4.988329201172538e-05,
      "loss": 0.9255,
      "step": 35250
    },
    {
      "epoch": 13.35,
      "learning_rate": 4.983183213825917e-05,
      "loss": 0.9297,
      "step": 35260
    },
    {
      "epoch": 13.35,
      "learning_rate": 4.978039001204754e-05,
      "loss": 0.9137,
      "step": 35270
    },
    {
      "epoch": 13.36,
      "learning_rate": 4.9728965651288385e-05,
      "loss": 0.9438,
      "step": 35280
    },
    {
      "epoch": 13.36,
      "learning_rate": 4.967755907417348e-05,
      "loss": 0.9069,
      "step": 35290
    },
    {
      "epoch": 13.36,
      "learning_rate": 4.9626170298888044e-05,
      "loss": 0.9135,
      "step": 35300
    },
    {
      "epoch": 13.37,
      "learning_rate": 4.9574799343611176e-05,
      "loss": 0.917,
      "step": 35310
    },
    {
      "epoch": 13.37,
      "learning_rate": 4.952344622651566e-05,
      "loss": 0.8976,
      "step": 35320
    },
    {
      "epoch": 13.38,
      "learning_rate": 4.9472110965767814e-05,
      "loss": 0.8963,
      "step": 35330
    },
    {
      "epoch": 13.38,
      "learning_rate": 4.942079357952789e-05,
      "loss": 0.9499,
      "step": 35340
    },
    {
      "epoch": 13.38,
      "learning_rate": 4.936949408594965e-05,
      "loss": 0.9259,
      "step": 35350
    },
    {
      "epoch": 13.39,
      "learning_rate": 4.9318212503180516e-05,
      "loss": 0.9471,
      "step": 35360
    },
    {
      "epoch": 13.39,
      "learning_rate": 4.9266948849361684e-05,
      "loss": 0.8978,
      "step": 35370
    },
    {
      "epoch": 13.4,
      "learning_rate": 4.9215703142627865e-05,
      "loss": 0.9325,
      "step": 35380
    },
    {
      "epoch": 13.4,
      "learning_rate": 4.9164475401107504e-05,
      "loss": 0.9093,
      "step": 35390
    },
    {
      "epoch": 13.4,
      "learning_rate": 4.911326564292279e-05,
      "loss": 0.9354,
      "step": 35400
    },
    {
      "epoch": 13.41,
      "learning_rate": 4.906207388618934e-05,
      "loss": 0.8757,
      "step": 35410
    },
    {
      "epoch": 13.41,
      "learning_rate": 4.901090014901655e-05,
      "loss": 0.8996,
      "step": 35420
    },
    {
      "epoch": 13.41,
      "learning_rate": 4.895974444950743e-05,
      "loss": 0.9152,
      "step": 35430
    },
    {
      "epoch": 13.42,
      "learning_rate": 4.890860680575849e-05,
      "loss": 0.9019,
      "step": 35440
    },
    {
      "epoch": 13.42,
      "learning_rate": 4.8857487235859965e-05,
      "loss": 0.9152,
      "step": 35450
    },
    {
      "epoch": 13.43,
      "learning_rate": 4.880638575789579e-05,
      "loss": 0.9404,
      "step": 35460
    },
    {
      "epoch": 13.43,
      "learning_rate": 4.875530238994325e-05,
      "loss": 0.9361,
      "step": 35470
    },
    {
      "epoch": 13.43,
      "learning_rate": 4.870423715007341e-05,
      "loss": 0.864,
      "step": 35480
    },
    {
      "epoch": 13.44,
      "learning_rate": 4.865319005635088e-05,
      "loss": 0.8882,
      "step": 35490
    },
    {
      "epoch": 13.44,
      "learning_rate": 4.86021611268338e-05,
      "loss": 0.9191,
      "step": 35500
    },
    {
      "epoch": 13.44,
      "learning_rate": 4.855115037957394e-05,
      "loss": 0.9132,
      "step": 35510
    },
    {
      "epoch": 13.45,
      "learning_rate": 4.850015783261662e-05,
      "loss": 0.9361,
      "step": 35520
    },
    {
      "epoch": 13.45,
      "learning_rate": 4.844918350400073e-05,
      "loss": 0.9755,
      "step": 35530
    },
    {
      "epoch": 13.46,
      "learning_rate": 4.839822741175874e-05,
      "loss": 0.8983,
      "step": 35540
    },
    {
      "epoch": 13.46,
      "learning_rate": 4.834728957391658e-05,
      "loss": 0.897,
      "step": 35550
    },
    {
      "epoch": 13.46,
      "learning_rate": 4.8296370008493794e-05,
      "loss": 0.9071,
      "step": 35560
    },
    {
      "epoch": 13.47,
      "learning_rate": 4.8245468733503464e-05,
      "loss": 0.9087,
      "step": 35570
    },
    {
      "epoch": 13.47,
      "learning_rate": 4.819458576695217e-05,
      "loss": 0.8786,
      "step": 35580
    },
    {
      "epoch": 13.47,
      "learning_rate": 4.814372112684005e-05,
      "loss": 0.9332,
      "step": 35590
    },
    {
      "epoch": 13.48,
      "learning_rate": 4.809287483116075e-05,
      "loss": 0.9324,
      "step": 35600
    },
    {
      "epoch": 13.48,
      "learning_rate": 4.804204689790136e-05,
      "loss": 0.8798,
      "step": 35610
    },
    {
      "epoch": 13.49,
      "learning_rate": 4.7991237345042574e-05,
      "loss": 0.9249,
      "step": 35620
    },
    {
      "epoch": 13.49,
      "learning_rate": 4.794044619055852e-05,
      "loss": 0.927,
      "step": 35630
    },
    {
      "epoch": 13.49,
      "learning_rate": 4.788967345241684e-05,
      "loss": 0.9131,
      "step": 35640
    },
    {
      "epoch": 13.5,
      "learning_rate": 4.783891914857871e-05,
      "loss": 0.894,
      "step": 35650
    },
    {
      "epoch": 13.5,
      "learning_rate": 4.7788183296998657e-05,
      "loss": 0.9156,
      "step": 35660
    },
    {
      "epoch": 13.5,
      "learning_rate": 4.773746591562478e-05,
      "loss": 0.9196,
      "step": 35670
    },
    {
      "epoch": 13.51,
      "learning_rate": 4.7686767022398636e-05,
      "loss": 0.8751,
      "step": 35680
    },
    {
      "epoch": 13.51,
      "learning_rate": 4.763608663525522e-05,
      "loss": 0.9186,
      "step": 35690
    },
    {
      "epoch": 13.52,
      "learning_rate": 4.758542477212298e-05,
      "loss": 0.9455,
      "step": 35700
    },
    {
      "epoch": 13.52,
      "learning_rate": 4.753478145092387e-05,
      "loss": 0.9372,
      "step": 35710
    },
    {
      "epoch": 13.52,
      "learning_rate": 4.748415668957314e-05,
      "loss": 0.9209,
      "step": 35720
    },
    {
      "epoch": 13.53,
      "learning_rate": 4.743355050597962e-05,
      "loss": 0.9208,
      "step": 35730
    },
    {
      "epoch": 13.53,
      "learning_rate": 4.738296291804551e-05,
      "loss": 0.8892,
      "step": 35740
    },
    {
      "epoch": 13.54,
      "learning_rate": 4.7332393943666445e-05,
      "loss": 0.9854,
      "step": 35750
    },
    {
      "epoch": 13.54,
      "learning_rate": 4.7281843600731436e-05,
      "loss": 0.9217,
      "step": 35760
    },
    {
      "epoch": 13.54,
      "learning_rate": 4.723131190712301e-05,
      "loss": 0.9679,
      "step": 35770
    },
    {
      "epoch": 13.55,
      "learning_rate": 4.718079888071693e-05,
      "loss": 0.9266,
      "step": 35780
    },
    {
      "epoch": 13.55,
      "learning_rate": 4.713030453938247e-05,
      "loss": 0.9248,
      "step": 35790
    },
    {
      "epoch": 13.55,
      "learning_rate": 4.707982890098229e-05,
      "loss": 0.949,
      "step": 35800
    },
    {
      "epoch": 13.56,
      "learning_rate": 4.702937198337241e-05,
      "loss": 0.9066,
      "step": 35810
    },
    {
      "epoch": 13.56,
      "learning_rate": 4.6978933804402255e-05,
      "loss": 0.9361,
      "step": 35820
    },
    {
      "epoch": 13.57,
      "learning_rate": 4.692851438191455e-05,
      "loss": 0.9603,
      "step": 35830
    },
    {
      "epoch": 13.57,
      "learning_rate": 4.6878113733745445e-05,
      "loss": 0.9261,
      "step": 35840
    },
    {
      "epoch": 13.57,
      "learning_rate": 4.682773187772444e-05,
      "loss": 0.9428,
      "step": 35850
    },
    {
      "epoch": 13.58,
      "learning_rate": 4.6777368831674386e-05,
      "loss": 0.8926,
      "step": 35860
    },
    {
      "epoch": 13.58,
      "learning_rate": 4.672702461341148e-05,
      "loss": 0.9166,
      "step": 35870
    },
    {
      "epoch": 13.58,
      "learning_rate": 4.6676699240745294e-05,
      "loss": 0.9028,
      "step": 35880
    },
    {
      "epoch": 13.59,
      "learning_rate": 4.662639273147861e-05,
      "loss": 0.9089,
      "step": 35890
    },
    {
      "epoch": 13.59,
      "learning_rate": 4.6576105103407676e-05,
      "loss": 0.8759,
      "step": 35900
    },
    {
      "epoch": 13.6,
      "learning_rate": 4.6525836374321985e-05,
      "loss": 0.8821,
      "step": 35910
    },
    {
      "epoch": 13.6,
      "learning_rate": 4.647558656200437e-05,
      "loss": 0.9317,
      "step": 35920
    },
    {
      "epoch": 13.6,
      "learning_rate": 4.642535568423102e-05,
      "loss": 0.9649,
      "step": 35930
    },
    {
      "epoch": 13.61,
      "learning_rate": 4.637514375877129e-05,
      "loss": 0.9475,
      "step": 35940
    },
    {
      "epoch": 13.61,
      "learning_rate": 4.632495080338796e-05,
      "loss": 0.8662,
      "step": 35950
    },
    {
      "epoch": 13.61,
      "learning_rate": 4.627477683583703e-05,
      "loss": 0.9126,
      "step": 35960
    },
    {
      "epoch": 13.62,
      "learning_rate": 4.622462187386783e-05,
      "loss": 0.8397,
      "step": 35970
    },
    {
      "epoch": 13.62,
      "learning_rate": 4.617448593522292e-05,
      "loss": 0.8728,
      "step": 35980
    },
    {
      "epoch": 13.63,
      "learning_rate": 4.6124369037638224e-05,
      "loss": 0.9074,
      "step": 35990
    },
    {
      "epoch": 13.63,
      "learning_rate": 4.6074271198842754e-05,
      "loss": 0.9402,
      "step": 36000
    },
    {
      "epoch": 13.63,
      "learning_rate": 4.6024192436558935e-05,
      "loss": 0.9291,
      "step": 36010
    },
    {
      "epoch": 13.64,
      "learning_rate": 4.59741327685024e-05,
      "loss": 0.8901,
      "step": 36020
    },
    {
      "epoch": 13.64,
      "learning_rate": 4.5924092212382007e-05,
      "loss": 0.8866,
      "step": 36030
    },
    {
      "epoch": 13.65,
      "learning_rate": 4.587407078589988e-05,
      "loss": 0.9278,
      "step": 36040
    },
    {
      "epoch": 13.65,
      "learning_rate": 4.5824068506751386e-05,
      "loss": 0.9551,
      "step": 36050
    },
    {
      "epoch": 13.65,
      "learning_rate": 4.577408539262503e-05,
      "loss": 0.921,
      "step": 36060
    },
    {
      "epoch": 13.66,
      "learning_rate": 4.572412146120265e-05,
      "loss": 0.884,
      "step": 36070
    },
    {
      "epoch": 13.66,
      "learning_rate": 4.567417673015924e-05,
      "loss": 0.9115,
      "step": 36080
    },
    {
      "epoch": 13.66,
      "learning_rate": 4.562425121716301e-05,
      "loss": 0.9678,
      "step": 36090
    },
    {
      "epoch": 13.67,
      "learning_rate": 4.557434493987541e-05,
      "loss": 0.884,
      "step": 36100
    },
    {
      "epoch": 13.67,
      "learning_rate": 4.5524457915950994e-05,
      "loss": 0.9436,
      "step": 36110
    },
    {
      "epoch": 13.68,
      "learning_rate": 4.5474590163037565e-05,
      "loss": 0.9054,
      "step": 36120
    },
    {
      "epoch": 13.68,
      "learning_rate": 4.542474169877613e-05,
      "loss": 0.9418,
      "step": 36130
    },
    {
      "epoch": 13.68,
      "learning_rate": 4.5374912540800854e-05,
      "loss": 0.8992,
      "step": 36140
    },
    {
      "epoch": 13.69,
      "learning_rate": 4.532510270673903e-05,
      "loss": 0.8736,
      "step": 36150
    },
    {
      "epoch": 13.69,
      "learning_rate": 4.527531221421122e-05,
      "loss": 0.976,
      "step": 36160
    },
    {
      "epoch": 13.69,
      "learning_rate": 4.522554108083098e-05,
      "loss": 0.9189,
      "step": 36170
    },
    {
      "epoch": 13.7,
      "learning_rate": 4.5175789324205166e-05,
      "loss": 0.8726,
      "step": 36180
    },
    {
      "epoch": 13.7,
      "learning_rate": 4.5126056961933706e-05,
      "loss": 0.8776,
      "step": 36190
    },
    {
      "epoch": 13.71,
      "learning_rate": 4.507634401160969e-05,
      "loss": 0.9084,
      "step": 36200
    },
    {
      "epoch": 13.71,
      "learning_rate": 4.502665049081939e-05,
      "loss": 0.9319,
      "step": 36210
    },
    {
      "epoch": 13.71,
      "learning_rate": 4.497697641714207e-05,
      "loss": 0.8837,
      "step": 36220
    },
    {
      "epoch": 13.72,
      "learning_rate": 4.492732180815022e-05,
      "loss": 0.9114,
      "step": 36230
    },
    {
      "epoch": 13.72,
      "learning_rate": 4.487768668140948e-05,
      "loss": 0.8916,
      "step": 36240
    },
    {
      "epoch": 13.72,
      "learning_rate": 4.482807105447841e-05,
      "loss": 0.9385,
      "step": 36250
    },
    {
      "epoch": 13.73,
      "learning_rate": 4.477847494490891e-05,
      "loss": 0.9407,
      "step": 36260
    },
    {
      "epoch": 13.73,
      "learning_rate": 4.472889837024587e-05,
      "loss": 0.9176,
      "step": 36270
    },
    {
      "epoch": 13.74,
      "learning_rate": 4.4679341348027206e-05,
      "loss": 0.945,
      "step": 36280
    },
    {
      "epoch": 13.74,
      "learning_rate": 4.4629803895783995e-05,
      "loss": 0.9289,
      "step": 36290
    },
    {
      "epoch": 13.74,
      "learning_rate": 4.4580286031040416e-05,
      "loss": 0.8873,
      "step": 36300
    },
    {
      "epoch": 13.75,
      "learning_rate": 4.4530787771313564e-05,
      "loss": 0.8785,
      "step": 36310
    },
    {
      "epoch": 13.75,
      "learning_rate": 4.4481309134113825e-05,
      "loss": 0.9337,
      "step": 36320
    },
    {
      "epoch": 13.75,
      "learning_rate": 4.443185013694452e-05,
      "loss": 0.9271,
      "step": 36330
    },
    {
      "epoch": 13.76,
      "learning_rate": 4.438241079730197e-05,
      "loss": 0.9378,
      "step": 36340
    },
    {
      "epoch": 13.76,
      "learning_rate": 4.433299113267565e-05,
      "loss": 0.8627,
      "step": 36350
    },
    {
      "epoch": 13.77,
      "learning_rate": 4.4283591160547986e-05,
      "loss": 0.9482,
      "step": 36360
    },
    {
      "epoch": 13.77,
      "learning_rate": 4.423421089839447e-05,
      "loss": 0.9065,
      "step": 36370
    },
    {
      "epoch": 13.77,
      "learning_rate": 4.418485036368373e-05,
      "loss": 0.9413,
      "step": 36380
    },
    {
      "epoch": 13.78,
      "learning_rate": 4.413550957387721e-05,
      "loss": 0.9548,
      "step": 36390
    },
    {
      "epoch": 13.78,
      "learning_rate": 4.408618854642952e-05,
      "loss": 0.9109,
      "step": 36400
    },
    {
      "epoch": 13.79,
      "learning_rate": 4.403688729878825e-05,
      "loss": 0.9557,
      "step": 36410
    },
    {
      "epoch": 13.79,
      "learning_rate": 4.3987605848393945e-05,
      "loss": 0.9906,
      "step": 36420
    },
    {
      "epoch": 13.79,
      "learning_rate": 4.393834421268014e-05,
      "loss": 0.8768,
      "step": 36430
    },
    {
      "epoch": 13.8,
      "learning_rate": 4.388910240907351e-05,
      "loss": 0.8934,
      "step": 36440
    },
    {
      "epoch": 13.8,
      "learning_rate": 4.383988045499352e-05,
      "loss": 0.9159,
      "step": 36450
    },
    {
      "epoch": 13.8,
      "learning_rate": 4.3790678367852755e-05,
      "loss": 0.9103,
      "step": 36460
    },
    {
      "epoch": 13.81,
      "learning_rate": 4.374149616505664e-05,
      "loss": 0.9836,
      "step": 36470
    },
    {
      "epoch": 13.81,
      "learning_rate": 4.369233386400363e-05,
      "loss": 0.9128,
      "step": 36480
    },
    {
      "epoch": 13.82,
      "learning_rate": 4.3643191482085276e-05,
      "loss": 0.894,
      "step": 36490
    },
    {
      "epoch": 13.82,
      "learning_rate": 4.3594069036685836e-05,
      "loss": 0.9255,
      "step": 36500
    },
    {
      "epoch": 13.82,
      "learning_rate": 4.3544966545182664e-05,
      "loss": 0.9506,
      "step": 36510
    },
    {
      "epoch": 13.83,
      "learning_rate": 4.349588402494609e-05,
      "loss": 0.9255,
      "step": 36520
    },
    {
      "epoch": 13.83,
      "learning_rate": 4.3446821493339205e-05,
      "loss": 0.9721,
      "step": 36530
    },
    {
      "epoch": 13.83,
      "learning_rate": 4.339777896771816e-05,
      "loss": 0.9519,
      "step": 36540
    },
    {
      "epoch": 13.84,
      "learning_rate": 4.334875646543213e-05,
      "loss": 0.9099,
      "step": 36550
    },
    {
      "epoch": 13.84,
      "learning_rate": 4.329975400382295e-05,
      "loss": 0.8665,
      "step": 36560
    },
    {
      "epoch": 13.85,
      "learning_rate": 4.3250771600225534e-05,
      "loss": 0.8855,
      "step": 36570
    },
    {
      "epoch": 13.85,
      "learning_rate": 4.320180927196773e-05,
      "loss": 0.9215,
      "step": 36580
    },
    {
      "epoch": 13.85,
      "learning_rate": 4.3152867036370126e-05,
      "loss": 0.9108,
      "step": 36590
    },
    {
      "epoch": 13.86,
      "learning_rate": 4.310394491074634e-05,
      "loss": 0.9163,
      "step": 36600
    },
    {
      "epoch": 13.86,
      "learning_rate": 4.305504291240283e-05,
      "loss": 0.9229,
      "step": 36610
    },
    {
      "epoch": 13.86,
      "learning_rate": 4.300616105863894e-05,
      "loss": 0.931,
      "step": 36620
    },
    {
      "epoch": 13.87,
      "learning_rate": 4.2957299366746916e-05,
      "loss": 0.9296,
      "step": 36630
    },
    {
      "epoch": 13.87,
      "learning_rate": 4.2908457854011774e-05,
      "loss": 0.8966,
      "step": 36640
    },
    {
      "epoch": 13.88,
      "learning_rate": 4.285963653771149e-05,
      "loss": 0.9848,
      "step": 36650
    },
    {
      "epoch": 13.88,
      "learning_rate": 4.281083543511686e-05,
      "loss": 0.9239,
      "step": 36660
    },
    {
      "epoch": 13.88,
      "learning_rate": 4.276205456349153e-05,
      "loss": 0.8948,
      "step": 36670
    },
    {
      "epoch": 13.89,
      "learning_rate": 4.2713293940092e-05,
      "loss": 0.9447,
      "step": 36680
    },
    {
      "epoch": 13.89,
      "learning_rate": 4.266455358216763e-05,
      "loss": 0.9257,
      "step": 36690
    },
    {
      "epoch": 13.89,
      "learning_rate": 4.26158335069605e-05,
      "loss": 0.8976,
      "step": 36700
    },
    {
      "epoch": 13.9,
      "learning_rate": 4.256713373170564e-05,
      "loss": 0.956,
      "step": 36710
    },
    {
      "epoch": 13.9,
      "learning_rate": 4.251845427363086e-05,
      "loss": 0.8909,
      "step": 36720
    },
    {
      "epoch": 13.91,
      "learning_rate": 4.246979514995676e-05,
      "loss": 0.8935,
      "step": 36730
    },
    {
      "epoch": 13.91,
      "learning_rate": 4.2421156377896796e-05,
      "loss": 0.9106,
      "step": 36740
    },
    {
      "epoch": 13.91,
      "learning_rate": 4.237253797465713e-05,
      "loss": 0.9175,
      "step": 36750
    },
    {
      "epoch": 13.92,
      "learning_rate": 4.232393995743682e-05,
      "loss": 0.9071,
      "step": 36760
    },
    {
      "epoch": 13.92,
      "learning_rate": 4.227536234342766e-05,
      "loss": 0.9182,
      "step": 36770
    },
    {
      "epoch": 13.93,
      "learning_rate": 4.2226805149814244e-05,
      "loss": 0.9617,
      "step": 36780
    },
    {
      "epoch": 13.93,
      "learning_rate": 4.217826839377392e-05,
      "loss": 0.8685,
      "step": 36790
    },
    {
      "epoch": 13.93,
      "learning_rate": 4.2129752092476895e-05,
      "loss": 0.9149,
      "step": 36800
    },
    {
      "epoch": 13.94,
      "learning_rate": 4.208125626308595e-05,
      "loss": 0.9161,
      "step": 36810
    },
    {
      "epoch": 13.94,
      "learning_rate": 4.203278092275681e-05,
      "loss": 0.8924,
      "step": 36820
    },
    {
      "epoch": 13.94,
      "learning_rate": 4.198432608863786e-05,
      "loss": 0.9131,
      "step": 36830
    },
    {
      "epoch": 13.95,
      "learning_rate": 4.1935891777870276e-05,
      "loss": 0.8819,
      "step": 36840
    },
    {
      "epoch": 13.95,
      "learning_rate": 4.188747800758793e-05,
      "loss": 0.9021,
      "step": 36850
    },
    {
      "epoch": 13.96,
      "learning_rate": 4.1839084794917504e-05,
      "loss": 0.925,
      "step": 36860
    },
    {
      "epoch": 13.96,
      "learning_rate": 4.179071215697827e-05,
      "loss": 0.9028,
      "step": 36870
    },
    {
      "epoch": 13.96,
      "learning_rate": 4.174236011088234e-05,
      "loss": 0.8965,
      "step": 36880
    },
    {
      "epoch": 13.97,
      "learning_rate": 4.1694028673734507e-05,
      "loss": 0.8684,
      "step": 36890
    },
    {
      "epoch": 13.97,
      "learning_rate": 4.1645717862632285e-05,
      "loss": 0.9348,
      "step": 36900
    },
    {
      "epoch": 13.97,
      "learning_rate": 4.1597427694665906e-05,
      "loss": 0.8874,
      "step": 36910
    },
    {
      "epoch": 13.98,
      "learning_rate": 4.154915818691818e-05,
      "loss": 0.909,
      "step": 36920
    },
    {
      "epoch": 13.98,
      "learning_rate": 4.150090935646477e-05,
      "loss": 0.952,
      "step": 36930
    },
    {
      "epoch": 13.99,
      "learning_rate": 4.1452681220373936e-05,
      "loss": 0.9517,
      "step": 36940
    },
    {
      "epoch": 13.99,
      "learning_rate": 4.140447379570663e-05,
      "loss": 0.8824,
      "step": 36950
    },
    {
      "epoch": 13.99,
      "learning_rate": 4.13562870995165e-05,
      "loss": 0.9106,
      "step": 36960
    },
    {
      "epoch": 14.0,
      "learning_rate": 4.1308121148849875e-05,
      "loss": 0.9063,
      "step": 36970
    },
    {
      "epoch": 14.0,
      "learning_rate": 4.125997596074564e-05,
      "loss": 0.8985,
      "step": 36980
    },
    {
      "epoch": 14.0,
      "learning_rate": 4.1211851552235446e-05,
      "loss": 0.9013,
      "step": 36990
    },
    {
      "epoch": 14.01,
      "learning_rate": 4.116374794034357e-05,
      "loss": 0.8388,
      "step": 37000
    },
    {
      "epoch": 14.01,
      "learning_rate": 4.111566514208689e-05,
      "loss": 0.8959,
      "step": 37010
    },
    {
      "epoch": 14.02,
      "learning_rate": 4.106760317447501e-05,
      "loss": 0.9469,
      "step": 37020
    },
    {
      "epoch": 14.02,
      "learning_rate": 4.101956205451003e-05,
      "loss": 0.8848,
      "step": 37030
    },
    {
      "epoch": 14.02,
      "learning_rate": 4.097154179918677e-05,
      "loss": 0.8937,
      "step": 37040
    },
    {
      "epoch": 14.03,
      "learning_rate": 4.092354242549268e-05,
      "loss": 0.9544,
      "step": 37050
    },
    {
      "epoch": 14.03,
      "learning_rate": 4.087556395040776e-05,
      "loss": 0.8689,
      "step": 37060
    },
    {
      "epoch": 14.04,
      "learning_rate": 4.0827606390904673e-05,
      "loss": 0.8949,
      "step": 37070
    },
    {
      "epoch": 14.04,
      "learning_rate": 4.077966976394868e-05,
      "loss": 0.9153,
      "step": 37080
    },
    {
      "epoch": 14.04,
      "learning_rate": 4.0731754086497544e-05,
      "loss": 0.9149,
      "step": 37090
    },
    {
      "epoch": 14.05,
      "learning_rate": 4.068385937550173e-05,
      "loss": 0.896,
      "step": 37100
    },
    {
      "epoch": 14.05,
      "learning_rate": 4.063598564790425e-05,
      "loss": 0.9521,
      "step": 37110
    },
    {
      "epoch": 14.05,
      "learning_rate": 4.0588132920640686e-05,
      "loss": 0.8537,
      "step": 37120
    },
    {
      "epoch": 14.06,
      "learning_rate": 4.0540301210639196e-05,
      "loss": 0.8775,
      "step": 37130
    },
    {
      "epoch": 14.06,
      "learning_rate": 4.0492490534820525e-05,
      "loss": 0.9092,
      "step": 37140
    },
    {
      "epoch": 14.07,
      "learning_rate": 4.044470091009789e-05,
      "loss": 0.9503,
      "step": 37150
    },
    {
      "epoch": 14.07,
      "learning_rate": 4.039693235337719e-05,
      "loss": 0.9195,
      "step": 37160
    },
    {
      "epoch": 14.07,
      "learning_rate": 4.03491848815567e-05,
      "loss": 0.8941,
      "step": 37170
    },
    {
      "epoch": 14.08,
      "learning_rate": 4.0301458511527444e-05,
      "loss": 0.9048,
      "step": 37180
    },
    {
      "epoch": 14.08,
      "learning_rate": 4.025375326017289e-05,
      "loss": 0.899,
      "step": 37190
    },
    {
      "epoch": 14.08,
      "learning_rate": 4.020606914436893e-05,
      "loss": 0.9228,
      "step": 37200
    },
    {
      "epoch": 14.09,
      "learning_rate": 4.015840618098412e-05,
      "loss": 0.9292,
      "step": 37210
    },
    {
      "epoch": 14.09,
      "learning_rate": 4.01107643868795e-05,
      "loss": 0.8849,
      "step": 37220
    },
    {
      "epoch": 14.1,
      "learning_rate": 4.0063143778908585e-05,
      "loss": 0.9352,
      "step": 37230
    },
    {
      "epoch": 14.1,
      "learning_rate": 4.001554437391741e-05,
      "loss": 0.9514,
      "step": 37240
    },
    {
      "epoch": 14.1,
      "learning_rate": 3.996796618874459e-05,
      "loss": 0.933,
      "step": 37250
    },
    {
      "epoch": 14.11,
      "learning_rate": 3.992040924022105e-05,
      "loss": 0.8978,
      "step": 37260
    },
    {
      "epoch": 14.11,
      "learning_rate": 3.9872873545170356e-05,
      "loss": 0.9362,
      "step": 37270
    },
    {
      "epoch": 14.11,
      "learning_rate": 3.9825359120408526e-05,
      "loss": 0.956,
      "step": 37280
    },
    {
      "epoch": 14.12,
      "learning_rate": 3.9777865982744026e-05,
      "loss": 0.9253,
      "step": 37290
    },
    {
      "epoch": 14.12,
      "learning_rate": 3.973039414897785e-05,
      "loss": 0.9068,
      "step": 37300
    },
    {
      "epoch": 14.13,
      "learning_rate": 3.9682943635903314e-05,
      "loss": 0.8499,
      "step": 37310
    },
    {
      "epoch": 14.13,
      "learning_rate": 3.9635514460306355e-05,
      "loss": 0.9104,
      "step": 37320
    },
    {
      "epoch": 14.13,
      "learning_rate": 3.958810663896532e-05,
      "loss": 0.8689,
      "step": 37330
    },
    {
      "epoch": 14.14,
      "learning_rate": 3.9540720188650874e-05,
      "loss": 0.8547,
      "step": 37340
    },
    {
      "epoch": 14.14,
      "learning_rate": 3.949335512612631e-05,
      "loss": 0.8935,
      "step": 37350
    },
    {
      "epoch": 14.14,
      "learning_rate": 3.944601146814728e-05,
      "loss": 0.9479,
      "step": 37360
    },
    {
      "epoch": 14.15,
      "learning_rate": 3.939868923146179e-05,
      "loss": 0.9408,
      "step": 37370
    },
    {
      "epoch": 14.15,
      "learning_rate": 3.9351388432810374e-05,
      "loss": 0.9293,
      "step": 37380
    },
    {
      "epoch": 14.16,
      "learning_rate": 3.930410908892596e-05,
      "loss": 0.9398,
      "step": 37390
    },
    {
      "epoch": 14.16,
      "learning_rate": 3.9256851216533754e-05,
      "loss": 0.9428,
      "step": 37400
    },
    {
      "epoch": 14.16,
      "learning_rate": 3.9209614832351606e-05,
      "loss": 0.8886,
      "step": 37410
    },
    {
      "epoch": 14.17,
      "learning_rate": 3.916239995308961e-05,
      "loss": 0.909,
      "step": 37420
    },
    {
      "epoch": 14.17,
      "learning_rate": 3.911520659545023e-05,
      "loss": 0.9178,
      "step": 37430
    },
    {
      "epoch": 14.18,
      "learning_rate": 3.906803477612843e-05,
      "loss": 0.9143,
      "step": 37440
    },
    {
      "epoch": 14.18,
      "learning_rate": 3.902088451181142e-05,
      "loss": 0.8766,
      "step": 37450
    },
    {
      "epoch": 14.18,
      "learning_rate": 3.8973755819178844e-05,
      "loss": 0.9265,
      "step": 37460
    },
    {
      "epoch": 14.19,
      "learning_rate": 3.892664871490286e-05,
      "loss": 0.9199,
      "step": 37470
    },
    {
      "epoch": 14.19,
      "learning_rate": 3.8879563215647716e-05,
      "loss": 0.8938,
      "step": 37480
    },
    {
      "epoch": 14.19,
      "learning_rate": 3.883249933807022e-05,
      "loss": 0.8738,
      "step": 37490
    },
    {
      "epoch": 14.2,
      "learning_rate": 3.878545709881948e-05,
      "loss": 0.9445,
      "step": 37500
    },
    {
      "epoch": 14.2,
      "learning_rate": 3.8738436514536866e-05,
      "loss": 0.8769,
      "step": 37510
    },
    {
      "epoch": 14.21,
      "learning_rate": 3.8691437601856186e-05,
      "loss": 0.9402,
      "step": 37520
    },
    {
      "epoch": 14.21,
      "learning_rate": 3.864446037740364e-05,
      "loss": 0.9037,
      "step": 37530
    },
    {
      "epoch": 14.21,
      "learning_rate": 3.859750485779756e-05,
      "loss": 0.8865,
      "step": 37540
    },
    {
      "epoch": 14.22,
      "learning_rate": 3.855057105964879e-05,
      "loss": 0.8856,
      "step": 37550
    },
    {
      "epoch": 14.22,
      "learning_rate": 3.850365899956033e-05,
      "loss": 0.8585,
      "step": 37560
    },
    {
      "epoch": 14.22,
      "learning_rate": 3.845676869412761e-05,
      "loss": 0.9014,
      "step": 37570
    },
    {
      "epoch": 14.23,
      "learning_rate": 3.8409900159938326e-05,
      "loss": 0.9345,
      "step": 37580
    },
    {
      "epoch": 14.23,
      "learning_rate": 3.836305341357246e-05,
      "loss": 0.8938,
      "step": 37590
    },
    {
      "epoch": 14.24,
      "learning_rate": 3.831622847160231e-05,
      "loss": 0.8825,
      "step": 37600
    },
    {
      "epoch": 14.24,
      "learning_rate": 3.826942535059247e-05,
      "loss": 0.9114,
      "step": 37610
    },
    {
      "epoch": 14.24,
      "learning_rate": 3.822264406709972e-05,
      "loss": 0.885,
      "step": 37620
    },
    {
      "epoch": 14.25,
      "learning_rate": 3.81758846376732e-05,
      "loss": 0.8943,
      "step": 37630
    },
    {
      "epoch": 14.25,
      "learning_rate": 3.81291470788544e-05,
      "loss": 0.8845,
      "step": 37640
    },
    {
      "epoch": 14.25,
      "learning_rate": 3.8082431407176874e-05,
      "loss": 0.9197,
      "step": 37650
    },
    {
      "epoch": 14.26,
      "learning_rate": 3.803573763916657e-05,
      "loss": 0.913,
      "step": 37660
    },
    {
      "epoch": 14.26,
      "learning_rate": 3.7989065791341706e-05,
      "loss": 0.9136,
      "step": 37670
    },
    {
      "epoch": 14.27,
      "learning_rate": 3.79424158802126e-05,
      "loss": 0.9418,
      "step": 37680
    },
    {
      "epoch": 14.27,
      "learning_rate": 3.789578792228197e-05,
      "loss": 0.8856,
      "step": 37690
    },
    {
      "epoch": 14.27,
      "learning_rate": 3.7849181934044676e-05,
      "loss": 0.9199,
      "step": 37700
    },
    {
      "epoch": 14.28,
      "learning_rate": 3.780259793198784e-05,
      "loss": 0.912,
      "step": 37710
    },
    {
      "epoch": 14.28,
      "learning_rate": 3.7756035932590835e-05,
      "loss": 0.8932,
      "step": 37720
    },
    {
      "epoch": 14.28,
      "learning_rate": 3.7709495952325155e-05,
      "loss": 0.8988,
      "step": 37730
    },
    {
      "epoch": 14.29,
      "learning_rate": 3.766297800765459e-05,
      "loss": 0.9208,
      "step": 37740
    },
    {
      "epoch": 14.29,
      "learning_rate": 3.76164821150351e-05,
      "loss": 0.9338,
      "step": 37750
    },
    {
      "epoch": 14.3,
      "learning_rate": 3.757000829091487e-05,
      "loss": 0.9105,
      "step": 37760
    },
    {
      "epoch": 14.3,
      "learning_rate": 3.752355655173425e-05,
      "loss": 0.8928,
      "step": 37770
    },
    {
      "epoch": 14.3,
      "learning_rate": 3.747712691392583e-05,
      "loss": 0.8769,
      "step": 37780
    },
    {
      "epoch": 14.31,
      "learning_rate": 3.743071939391426e-05,
      "loss": 0.9023,
      "step": 37790
    },
    {
      "epoch": 14.31,
      "learning_rate": 3.7384334008116494e-05,
      "loss": 0.868,
      "step": 37800
    },
    {
      "epoch": 14.32,
      "learning_rate": 3.733797077294159e-05,
      "loss": 0.908,
      "step": 37810
    },
    {
      "epoch": 14.32,
      "learning_rate": 3.7291629704790806e-05,
      "loss": 0.9273,
      "step": 37820
    },
    {
      "epoch": 14.32,
      "learning_rate": 3.7245310820057565e-05,
      "loss": 0.9306,
      "step": 37830
    },
    {
      "epoch": 14.33,
      "learning_rate": 3.719901413512734e-05,
      "loss": 0.8622,
      "step": 37840
    },
    {
      "epoch": 14.33,
      "learning_rate": 3.7152739666377876e-05,
      "loss": 0.9148,
      "step": 37850
    },
    {
      "epoch": 14.33,
      "learning_rate": 3.710648743017902e-05,
      "loss": 0.8584,
      "step": 37860
    },
    {
      "epoch": 14.34,
      "learning_rate": 3.706025744289272e-05,
      "loss": 0.9281,
      "step": 37870
    },
    {
      "epoch": 14.34,
      "learning_rate": 3.701404972087309e-05,
      "loss": 0.9486,
      "step": 37880
    },
    {
      "epoch": 14.35,
      "learning_rate": 3.696786428046639e-05,
      "loss": 0.9151,
      "step": 37890
    },
    {
      "epoch": 14.35,
      "learning_rate": 3.69217011380109e-05,
      "loss": 0.8914,
      "step": 37900
    },
    {
      "epoch": 14.35,
      "learning_rate": 3.68755603098371e-05,
      "loss": 0.8964,
      "step": 37910
    },
    {
      "epoch": 14.36,
      "learning_rate": 3.682944181226756e-05,
      "loss": 0.9091,
      "step": 37920
    },
    {
      "epoch": 14.36,
      "learning_rate": 3.678334566161694e-05,
      "loss": 0.9596,
      "step": 37930
    },
    {
      "epoch": 14.36,
      "learning_rate": 3.6737271874192e-05,
      "loss": 0.8878,
      "step": 37940
    },
    {
      "epoch": 14.37,
      "learning_rate": 3.669122046629162e-05,
      "loss": 0.9283,
      "step": 37950
    },
    {
      "epoch": 14.37,
      "learning_rate": 3.6645191454206654e-05,
      "loss": 0.9361,
      "step": 37960
    },
    {
      "epoch": 14.38,
      "learning_rate": 3.659918485422013e-05,
      "loss": 0.8873,
      "step": 37970
    },
    {
      "epoch": 14.38,
      "learning_rate": 3.655320068260717e-05,
      "loss": 0.8951,
      "step": 37980
    },
    {
      "epoch": 14.38,
      "learning_rate": 3.650723895563487e-05,
      "loss": 0.919,
      "step": 37990
    },
    {
      "epoch": 14.39,
      "learning_rate": 3.646129968956249e-05,
      "loss": 0.943,
      "step": 38000
    },
    {
      "epoch": 14.39,
      "learning_rate": 3.641538290064122e-05,
      "loss": 0.9489,
      "step": 38010
    },
    {
      "epoch": 14.39,
      "learning_rate": 3.636948860511441e-05,
      "loss": 0.8752,
      "step": 38020
    },
    {
      "epoch": 14.4,
      "learning_rate": 3.632361681921739e-05,
      "loss": 0.9229,
      "step": 38030
    },
    {
      "epoch": 14.4,
      "learning_rate": 3.6277767559177545e-05,
      "loss": 0.9162,
      "step": 38040
    },
    {
      "epoch": 14.41,
      "learning_rate": 3.6231940841214316e-05,
      "loss": 0.9243,
      "step": 38050
    },
    {
      "epoch": 14.41,
      "learning_rate": 3.618613668153916e-05,
      "loss": 0.913,
      "step": 38060
    },
    {
      "epoch": 14.41,
      "learning_rate": 3.6140355096355494e-05,
      "loss": 0.8933,
      "step": 38070
    },
    {
      "epoch": 14.42,
      "learning_rate": 3.60945961018588e-05,
      "loss": 0.8849,
      "step": 38080
    },
    {
      "epoch": 14.42,
      "learning_rate": 3.604885971423659e-05,
      "loss": 0.8982,
      "step": 38090
    },
    {
      "epoch": 14.42,
      "learning_rate": 3.600314594966834e-05,
      "loss": 0.9271,
      "step": 38100
    },
    {
      "epoch": 14.43,
      "learning_rate": 3.5957454824325576e-05,
      "loss": 0.8833,
      "step": 38110
    },
    {
      "epoch": 14.43,
      "learning_rate": 3.59117863543717e-05,
      "loss": 0.9106,
      "step": 38120
    },
    {
      "epoch": 14.44,
      "learning_rate": 3.5866140555962226e-05,
      "loss": 0.9052,
      "step": 38130
    },
    {
      "epoch": 14.44,
      "learning_rate": 3.582051744524457e-05,
      "loss": 0.907,
      "step": 38140
    },
    {
      "epoch": 14.44,
      "learning_rate": 3.577491703835817e-05,
      "loss": 0.8725,
      "step": 38150
    },
    {
      "epoch": 14.45,
      "learning_rate": 3.57293393514344e-05,
      "loss": 0.9466,
      "step": 38160
    },
    {
      "epoch": 14.45,
      "learning_rate": 3.568378440059665e-05,
      "loss": 0.8873,
      "step": 38170
    },
    {
      "epoch": 14.46,
      "learning_rate": 3.563825220196014e-05,
      "loss": 0.8924,
      "step": 38180
    },
    {
      "epoch": 14.46,
      "learning_rate": 3.559274277163219e-05,
      "loss": 0.8854,
      "step": 38190
    },
    {
      "epoch": 14.46,
      "learning_rate": 3.554725612571197e-05,
      "loss": 0.9221,
      "step": 38200
    },
    {
      "epoch": 14.47,
      "learning_rate": 3.550179228029065e-05,
      "loss": 0.9144,
      "step": 38210
    },
    {
      "epoch": 14.47,
      "learning_rate": 3.545635125145127e-05,
      "loss": 0.9155,
      "step": 38220
    },
    {
      "epoch": 14.47,
      "learning_rate": 3.54109330552689e-05,
      "loss": 0.8614,
      "step": 38230
    },
    {
      "epoch": 14.48,
      "learning_rate": 3.5365537707810384e-05,
      "loss": 0.9106,
      "step": 38240
    },
    {
      "epoch": 14.48,
      "learning_rate": 3.532016522513464e-05,
      "loss": 0.8994,
      "step": 38250
    },
    {
      "epoch": 14.49,
      "learning_rate": 3.527481562329232e-05,
      "loss": 0.9472,
      "step": 38260
    },
    {
      "epoch": 14.49,
      "learning_rate": 3.522948891832618e-05,
      "loss": 0.8827,
      "step": 38270
    },
    {
      "epoch": 14.49,
      "learning_rate": 3.51841851262708e-05,
      "loss": 0.8837,
      "step": 38280
    },
    {
      "epoch": 14.5,
      "learning_rate": 3.513890426315255e-05,
      "loss": 0.9118,
      "step": 38290
    },
    {
      "epoch": 14.5,
      "learning_rate": 3.5093646344989816e-05,
      "loss": 0.9202,
      "step": 38300
    },
    {
      "epoch": 14.5,
      "learning_rate": 3.504841138779286e-05,
      "loss": 0.9445,
      "step": 38310
    },
    {
      "epoch": 14.51,
      "learning_rate": 3.500319940756368e-05,
      "loss": 0.9137,
      "step": 38320
    },
    {
      "epoch": 14.51,
      "learning_rate": 3.495801042029636e-05,
      "loss": 0.8757,
      "step": 38330
    },
    {
      "epoch": 14.52,
      "learning_rate": 3.491284444197675e-05,
      "loss": 0.8838,
      "step": 38340
    },
    {
      "epoch": 14.52,
      "learning_rate": 3.486770148858247e-05,
      "loss": 0.8993,
      "step": 38350
    },
    {
      "epoch": 14.52,
      "learning_rate": 3.482258157608312e-05,
      "loss": 0.9262,
      "step": 38360
    },
    {
      "epoch": 14.53,
      "learning_rate": 3.477748472044011e-05,
      "loss": 0.8794,
      "step": 38370
    },
    {
      "epoch": 14.53,
      "learning_rate": 3.4732410937606696e-05,
      "loss": 0.9107,
      "step": 38380
    },
    {
      "epoch": 14.53,
      "learning_rate": 3.468736024352799e-05,
      "loss": 0.9134,
      "step": 38390
    },
    {
      "epoch": 14.54,
      "learning_rate": 3.4642332654140844e-05,
      "loss": 0.8696,
      "step": 38400
    },
    {
      "epoch": 14.54,
      "learning_rate": 3.459732818537405e-05,
      "loss": 0.891,
      "step": 38410
    },
    {
      "epoch": 14.55,
      "learning_rate": 3.455234685314821e-05,
      "loss": 0.8683,
      "step": 38420
    },
    {
      "epoch": 14.55,
      "learning_rate": 3.4507388673375596e-05,
      "loss": 0.9117,
      "step": 38430
    },
    {
      "epoch": 14.55,
      "learning_rate": 3.4462453661960506e-05,
      "loss": 0.9445,
      "step": 38440
    },
    {
      "epoch": 14.56,
      "learning_rate": 3.441754183479894e-05,
      "loss": 0.8844,
      "step": 38450
    },
    {
      "epoch": 14.56,
      "learning_rate": 3.437265320777864e-05,
      "loss": 0.8582,
      "step": 38460
    },
    {
      "epoch": 14.57,
      "learning_rate": 3.432778779677921e-05,
      "loss": 0.9194,
      "step": 38470
    },
    {
      "epoch": 14.57,
      "learning_rate": 3.428294561767206e-05,
      "loss": 0.9021,
      "step": 38480
    },
    {
      "epoch": 14.57,
      "learning_rate": 3.423812668632026e-05,
      "loss": 0.8793,
      "step": 38490
    },
    {
      "epoch": 14.58,
      "learning_rate": 3.4193331018578876e-05,
      "loss": 0.9355,
      "step": 38500
    },
    {
      "epoch": 14.58,
      "learning_rate": 3.41485586302945e-05,
      "loss": 0.928,
      "step": 38510
    },
    {
      "epoch": 14.58,
      "learning_rate": 3.410380953730564e-05,
      "loss": 0.876,
      "step": 38520
    },
    {
      "epoch": 14.59,
      "learning_rate": 3.405908375544258e-05,
      "loss": 0.9469,
      "step": 38530
    },
    {
      "epoch": 14.59,
      "learning_rate": 3.40143813005272e-05,
      "loss": 0.9158,
      "step": 38540
    },
    {
      "epoch": 14.6,
      "learning_rate": 3.396970218837324e-05,
      "loss": 0.9127,
      "step": 38550
    },
    {
      "epoch": 14.6,
      "learning_rate": 3.392504643478628e-05,
      "loss": 0.9111,
      "step": 38560
    },
    {
      "epoch": 14.6,
      "learning_rate": 3.388041405556344e-05,
      "loss": 0.9179,
      "step": 38570
    },
    {
      "epoch": 14.61,
      "learning_rate": 3.3835805066493664e-05,
      "loss": 0.8603,
      "step": 38580
    },
    {
      "epoch": 14.61,
      "learning_rate": 3.379121948335766e-05,
      "loss": 0.8899,
      "step": 38590
    },
    {
      "epoch": 14.61,
      "learning_rate": 3.374665732192777e-05,
      "loss": 0.9402,
      "step": 38600
    },
    {
      "epoch": 14.62,
      "learning_rate": 3.3702118597968066e-05,
      "loss": 0.9058,
      "step": 38610
    },
    {
      "epoch": 14.62,
      "learning_rate": 3.365760332723448e-05,
      "loss": 0.932,
      "step": 38620
    },
    {
      "epoch": 14.63,
      "learning_rate": 3.361311152547441e-05,
      "loss": 0.9112,
      "step": 38630
    },
    {
      "epoch": 14.63,
      "learning_rate": 3.356864320842713e-05,
      "loss": 0.928,
      "step": 38640
    },
    {
      "epoch": 14.63,
      "learning_rate": 3.3524198391823483e-05,
      "loss": 0.9135,
      "step": 38650
    },
    {
      "epoch": 14.64,
      "learning_rate": 3.347977709138609e-05,
      "loss": 0.895,
      "step": 38660
    },
    {
      "epoch": 14.64,
      "learning_rate": 3.343537932282922e-05,
      "loss": 0.9094,
      "step": 38670
    },
    {
      "epoch": 14.64,
      "learning_rate": 3.339544146386704e-05,
      "loss": 0.938,
      "step": 38680
    },
    {
      "epoch": 14.65,
      "learning_rate": 3.335108844914612e-05,
      "loss": 0.9254,
      "step": 38690
    },
    {
      "epoch": 14.65,
      "learning_rate": 3.330675901183009e-05,
      "loss": 0.8858,
      "step": 38700
    },
    {
      "epoch": 14.66,
      "learning_rate": 3.326245316760061e-05,
      "loss": 0.9064,
      "step": 38710
    },
    {
      "epoch": 14.66,
      "learning_rate": 3.321817093213112e-05,
      "loss": 0.9414,
      "step": 38720
    },
    {
      "epoch": 14.66,
      "learning_rate": 3.317391232108676e-05,
      "loss": 0.9159,
      "step": 38730
    },
    {
      "epoch": 14.67,
      "learning_rate": 3.312967735012418e-05,
      "loss": 0.931,
      "step": 38740
    },
    {
      "epoch": 14.67,
      "learning_rate": 3.3085466034891754e-05,
      "loss": 0.9037,
      "step": 38750
    },
    {
      "epoch": 14.67,
      "learning_rate": 3.3041278391029465e-05,
      "loss": 0.8753,
      "step": 38760
    },
    {
      "epoch": 14.68,
      "learning_rate": 3.299711443416893e-05,
      "loss": 0.8786,
      "step": 38770
    },
    {
      "epoch": 14.68,
      "learning_rate": 3.295297417993343e-05,
      "loss": 0.9357,
      "step": 38780
    },
    {
      "epoch": 14.69,
      "learning_rate": 3.290885764393773e-05,
      "loss": 0.9139,
      "step": 38790
    },
    {
      "epoch": 14.69,
      "learning_rate": 3.286476484178832e-05,
      "loss": 0.8856,
      "step": 38800
    },
    {
      "epoch": 14.69,
      "learning_rate": 3.282069578908328e-05,
      "loss": 0.8861,
      "step": 38810
    },
    {
      "epoch": 14.7,
      "learning_rate": 3.277665050141226e-05,
      "loss": 0.9238,
      "step": 38820
    },
    {
      "epoch": 14.7,
      "learning_rate": 3.2732628994356496e-05,
      "loss": 0.9392,
      "step": 38830
    },
    {
      "epoch": 14.71,
      "learning_rate": 3.268863128348888e-05,
      "loss": 0.8711,
      "step": 38840
    },
    {
      "epoch": 14.71,
      "learning_rate": 3.264465738437378e-05,
      "loss": 0.9442,
      "step": 38850
    },
    {
      "epoch": 14.71,
      "learning_rate": 3.26007073125672e-05,
      "loss": 0.877,
      "step": 38860
    },
    {
      "epoch": 14.72,
      "learning_rate": 3.255678108361673e-05,
      "loss": 0.9357,
      "step": 38870
    },
    {
      "epoch": 14.72,
      "learning_rate": 3.25128787130615e-05,
      "loss": 0.9106,
      "step": 38880
    },
    {
      "epoch": 14.72,
      "learning_rate": 3.246900021643224e-05,
      "loss": 0.9355,
      "step": 38890
    },
    {
      "epoch": 14.73,
      "learning_rate": 3.242514560925114e-05,
      "loss": 0.8815,
      "step": 38900
    },
    {
      "epoch": 14.73,
      "learning_rate": 3.2381314907032024e-05,
      "loss": 0.9234,
      "step": 38910
    },
    {
      "epoch": 14.74,
      "learning_rate": 3.233750812528023e-05,
      "loss": 0.8864,
      "step": 38920
    },
    {
      "epoch": 14.74,
      "learning_rate": 3.229372527949265e-05,
      "loss": 0.8863,
      "step": 38930
    },
    {
      "epoch": 14.74,
      "learning_rate": 3.2249966385157684e-05,
      "loss": 0.9156,
      "step": 38940
    },
    {
      "epoch": 14.75,
      "learning_rate": 3.220623145775532e-05,
      "loss": 0.9387,
      "step": 38950
    },
    {
      "epoch": 14.75,
      "learning_rate": 3.216252051275694e-05,
      "loss": 0.8998,
      "step": 38960
    },
    {
      "epoch": 14.75,
      "learning_rate": 3.2118833565625575e-05,
      "loss": 0.9071,
      "step": 38970
    },
    {
      "epoch": 14.76,
      "learning_rate": 3.207517063181569e-05,
      "loss": 0.9331,
      "step": 38980
    },
    {
      "epoch": 14.76,
      "learning_rate": 3.203153172677329e-05,
      "loss": 0.9206,
      "step": 38990
    },
    {
      "epoch": 14.77,
      "learning_rate": 3.198791686593587e-05,
      "loss": 0.8806,
      "step": 39000
    },
    {
      "epoch": 14.77,
      "learning_rate": 3.1944326064732456e-05,
      "loss": 0.9054,
      "step": 39010
    },
    {
      "epoch": 14.77,
      "learning_rate": 3.190075933858344e-05,
      "loss": 0.9214,
      "step": 39020
    },
    {
      "epoch": 14.78,
      "learning_rate": 3.1857216702900826e-05,
      "loss": 0.9204,
      "step": 39030
    },
    {
      "epoch": 14.78,
      "learning_rate": 3.181369817308805e-05,
      "loss": 0.9077,
      "step": 39040
    },
    {
      "epoch": 14.78,
      "learning_rate": 3.177020376454003e-05,
      "loss": 0.8715,
      "step": 39050
    },
    {
      "epoch": 14.79,
      "learning_rate": 3.172673349264316e-05,
      "loss": 0.9057,
      "step": 39060
    },
    {
      "epoch": 14.79,
      "learning_rate": 3.168328737277523e-05,
      "loss": 0.9494,
      "step": 39070
    },
    {
      "epoch": 14.8,
      "learning_rate": 3.163986542030555e-05,
      "loss": 0.8786,
      "step": 39080
    },
    {
      "epoch": 14.8,
      "learning_rate": 3.159646765059487e-05,
      "loss": 0.9026,
      "step": 39090
    },
    {
      "epoch": 14.8,
      "learning_rate": 3.1553094078995395e-05,
      "loss": 0.9137,
      "step": 39100
    },
    {
      "epoch": 14.81,
      "learning_rate": 3.150974472085074e-05,
      "loss": 0.9034,
      "step": 39110
    },
    {
      "epoch": 14.81,
      "learning_rate": 3.146641959149601e-05,
      "loss": 0.902,
      "step": 39120
    },
    {
      "epoch": 14.81,
      "learning_rate": 3.1423118706257627e-05,
      "loss": 0.9595,
      "step": 39130
    },
    {
      "epoch": 14.82,
      "learning_rate": 3.137984208045355e-05,
      "loss": 0.9105,
      "step": 39140
    },
    {
      "epoch": 14.82,
      "learning_rate": 3.133658972939309e-05,
      "loss": 0.8805,
      "step": 39150
    },
    {
      "epoch": 14.83,
      "learning_rate": 3.129336166837703e-05,
      "loss": 0.9807,
      "step": 39160
    },
    {
      "epoch": 14.83,
      "learning_rate": 3.125015791269754e-05,
      "loss": 0.9341,
      "step": 39170
    },
    {
      "epoch": 14.83,
      "learning_rate": 3.120697847763811e-05,
      "loss": 0.8997,
      "step": 39180
    },
    {
      "epoch": 14.84,
      "learning_rate": 3.116382337847373e-05,
      "loss": 0.9482,
      "step": 39190
    },
    {
      "epoch": 14.84,
      "learning_rate": 3.112069263047074e-05,
      "loss": 0.9041,
      "step": 39200
    },
    {
      "epoch": 14.85,
      "learning_rate": 3.107758624888687e-05,
      "loss": 0.9642,
      "step": 39210
    },
    {
      "epoch": 14.85,
      "learning_rate": 3.103450424897124e-05,
      "loss": 0.928,
      "step": 39220
    },
    {
      "epoch": 14.85,
      "learning_rate": 3.099144664596436e-05,
      "loss": 0.9268,
      "step": 39230
    },
    {
      "epoch": 14.86,
      "learning_rate": 3.0948413455098015e-05,
      "loss": 0.889,
      "step": 39240
    },
    {
      "epoch": 14.86,
      "learning_rate": 3.090540469159547e-05,
      "loss": 0.9281,
      "step": 39250
    },
    {
      "epoch": 14.86,
      "learning_rate": 3.086242037067129e-05,
      "loss": 0.9145,
      "step": 39260
    },
    {
      "epoch": 14.87,
      "learning_rate": 3.081946050753142e-05,
      "loss": 0.9148,
      "step": 39270
    },
    {
      "epoch": 14.87,
      "learning_rate": 3.077652511737311e-05,
      "loss": 0.8752,
      "step": 39280
    },
    {
      "epoch": 14.88,
      "learning_rate": 3.073361421538504e-05,
      "loss": 0.9426,
      "step": 39290
    },
    {
      "epoch": 14.88,
      "learning_rate": 3.06907278167471e-05,
      "loss": 0.9257,
      "step": 39300
    },
    {
      "epoch": 14.88,
      "learning_rate": 3.0647865936630615e-05,
      "loss": 0.8555,
      "step": 39310
    },
    {
      "epoch": 14.89,
      "learning_rate": 3.060502859019819e-05,
      "loss": 0.8802,
      "step": 39320
    },
    {
      "epoch": 14.89,
      "learning_rate": 3.056221579260377e-05,
      "loss": 0.9122,
      "step": 39330
    },
    {
      "epoch": 14.89,
      "learning_rate": 3.051942755899263e-05,
      "loss": 0.8672,
      "step": 39340
    },
    {
      "epoch": 14.9,
      "learning_rate": 3.047666390450129e-05,
      "loss": 0.9106,
      "step": 39350
    },
    {
      "epoch": 14.9,
      "learning_rate": 3.0433924844257633e-05,
      "loss": 0.9491,
      "step": 39360
    },
    {
      "epoch": 14.91,
      "learning_rate": 3.0391210393380832e-05,
      "loss": 0.889,
      "step": 39370
    },
    {
      "epoch": 14.91,
      "learning_rate": 3.0348520566981365e-05,
      "loss": 0.8213,
      "step": 39380
    },
    {
      "epoch": 14.91,
      "learning_rate": 3.030585538016095e-05,
      "loss": 0.9145,
      "step": 39390
    },
    {
      "epoch": 14.92,
      "learning_rate": 3.026321484801269e-05,
      "loss": 0.9462,
      "step": 39400
    },
    {
      "epoch": 14.92,
      "learning_rate": 3.0220598985620817e-05,
      "loss": 0.9041,
      "step": 39410
    },
    {
      "epoch": 14.92,
      "learning_rate": 3.017800780806096e-05,
      "loss": 0.9605,
      "step": 39420
    },
    {
      "epoch": 14.93,
      "learning_rate": 3.0135441330399948e-05,
      "loss": 0.9155,
      "step": 39430
    },
    {
      "epoch": 14.93,
      "learning_rate": 3.009289956769593e-05,
      "loss": 0.9572,
      "step": 39440
    },
    {
      "epoch": 14.94,
      "learning_rate": 3.005038253499829e-05,
      "loss": 0.9158,
      "step": 39450
    },
    {
      "epoch": 14.94,
      "learning_rate": 3.0007890247347604e-05,
      "loss": 0.9544,
      "step": 39460
    },
    {
      "epoch": 14.94,
      "learning_rate": 2.996542271977576e-05,
      "loss": 0.9204,
      "step": 39470
    },
    {
      "epoch": 14.95,
      "learning_rate": 2.9922979967305907e-05,
      "loss": 0.9153,
      "step": 39480
    },
    {
      "epoch": 14.95,
      "learning_rate": 2.9880562004952296e-05,
      "loss": 0.8954,
      "step": 39490
    },
    {
      "epoch": 14.96,
      "learning_rate": 2.9838168847720617e-05,
      "loss": 0.9194,
      "step": 39500
    },
    {
      "epoch": 14.96,
      "learning_rate": 2.9795800510607653e-05,
      "loss": 0.8903,
      "step": 39510
    },
    {
      "epoch": 14.96,
      "learning_rate": 2.975345700860137e-05,
      "loss": 0.9307,
      "step": 39520
    },
    {
      "epoch": 14.97,
      "learning_rate": 2.9711138356681046e-05,
      "loss": 0.9052,
      "step": 39530
    },
    {
      "epoch": 14.97,
      "learning_rate": 2.9668844569817156e-05,
      "loss": 0.8576,
      "step": 39540
    },
    {
      "epoch": 14.97,
      "learning_rate": 2.9626575662971245e-05,
      "loss": 0.9005,
      "step": 39550
    },
    {
      "epoch": 14.98,
      "learning_rate": 2.9584331651096265e-05,
      "loss": 0.8899,
      "step": 39560
    },
    {
      "epoch": 14.98,
      "learning_rate": 2.954211254913626e-05,
      "loss": 0.9287,
      "step": 39570
    },
    {
      "epoch": 14.99,
      "learning_rate": 2.9499918372026402e-05,
      "loss": 0.9321,
      "step": 39580
    },
    {
      "epoch": 14.99,
      "learning_rate": 2.9457749134693148e-05,
      "loss": 0.9094,
      "step": 39590
    },
    {
      "epoch": 14.99,
      "learning_rate": 2.9415604852054048e-05,
      "loss": 0.8881,
      "step": 39600
    },
    {
      "epoch": 15.0,
      "learning_rate": 2.9373485539017854e-05,
      "loss": 0.9216,
      "step": 39610
    },
    {
      "epoch": 15.0,
      "learning_rate": 2.9331391210484594e-05,
      "loss": 0.9072,
      "step": 39620
    },
    {
      "epoch": 15.0,
      "learning_rate": 2.9289321881345254e-05,
      "loss": 0.8848,
      "step": 39630
    },
    {
      "epoch": 15.01,
      "learning_rate": 2.9247277566482124e-05,
      "loss": 0.9054,
      "step": 39640
    },
    {
      "epoch": 15.01,
      "learning_rate": 2.920525828076863e-05,
      "loss": 0.9141,
      "step": 39650
    },
    {
      "epoch": 15.02,
      "learning_rate": 2.916326403906924e-05,
      "loss": 0.8828,
      "step": 39660
    },
    {
      "epoch": 15.02,
      "learning_rate": 2.91212948562397e-05,
      "loss": 0.8916,
      "step": 39670
    },
    {
      "epoch": 15.02,
      "learning_rate": 2.9079350747126856e-05,
      "loss": 0.8887,
      "step": 39680
    },
    {
      "epoch": 15.03,
      "learning_rate": 2.9037431726568574e-05,
      "loss": 0.853,
      "step": 39690
    },
    {
      "epoch": 15.03,
      "learning_rate": 2.8995537809394013e-05,
      "loss": 0.9015,
      "step": 39700
    },
    {
      "epoch": 15.03,
      "learning_rate": 2.89536690104233e-05,
      "loss": 0.9159,
      "step": 39710
    },
    {
      "epoch": 15.04,
      "learning_rate": 2.8911825344467735e-05,
      "loss": 0.9301,
      "step": 39720
    },
    {
      "epoch": 15.04,
      "learning_rate": 2.8870006826329842e-05,
      "loss": 0.9056,
      "step": 39730
    },
    {
      "epoch": 15.05,
      "learning_rate": 2.8828213470803035e-05,
      "loss": 0.9693,
      "step": 39740
    },
    {
      "epoch": 15.05,
      "learning_rate": 2.8786445292671983e-05,
      "loss": 0.9087,
      "step": 39750
    },
    {
      "epoch": 15.05,
      "learning_rate": 2.874470230671241e-05,
      "loss": 0.9171,
      "step": 39760
    },
    {
      "epoch": 15.06,
      "learning_rate": 2.870298452769107e-05,
      "loss": 0.926,
      "step": 39770
    },
    {
      "epoch": 15.06,
      "learning_rate": 2.8661291970365845e-05,
      "loss": 0.9112,
      "step": 39780
    },
    {
      "epoch": 15.06,
      "learning_rate": 2.8619624649485797e-05,
      "loss": 0.9539,
      "step": 39790
    },
    {
      "epoch": 15.07,
      "learning_rate": 2.857798257979085e-05,
      "loss": 0.8763,
      "step": 39800
    },
    {
      "epoch": 15.07,
      "learning_rate": 2.8536365776012163e-05,
      "loss": 0.9026,
      "step": 39810
    },
    {
      "epoch": 15.08,
      "learning_rate": 2.8494774252871914e-05,
      "loss": 0.9399,
      "step": 39820
    },
    {
      "epoch": 15.08,
      "learning_rate": 2.8453208025083257e-05,
      "loss": 0.8559,
      "step": 39830
    },
    {
      "epoch": 15.08,
      "learning_rate": 2.8411667107350514e-05,
      "loss": 0.8732,
      "step": 39840
    },
    {
      "epoch": 15.09,
      "learning_rate": 2.837015151436898e-05,
      "loss": 0.8645,
      "step": 39850
    },
    {
      "epoch": 15.09,
      "learning_rate": 2.832866126082505e-05,
      "loss": 0.9355,
      "step": 39860
    },
    {
      "epoch": 15.1,
      "learning_rate": 2.828719636139612e-05,
      "loss": 0.8893,
      "step": 39870
    },
    {
      "epoch": 15.1,
      "learning_rate": 2.8245756830750568e-05,
      "loss": 0.8728,
      "step": 39880
    },
    {
      "epoch": 15.1,
      "learning_rate": 2.820434268354788e-05,
      "loss": 0.8785,
      "step": 39890
    },
    {
      "epoch": 15.11,
      "learning_rate": 2.8162953934438517e-05,
      "loss": 0.903,
      "step": 39900
    },
    {
      "epoch": 15.11,
      "learning_rate": 2.8121590598063985e-05,
      "loss": 0.9308,
      "step": 39910
    },
    {
      "epoch": 15.11,
      "learning_rate": 2.8080252689056774e-05,
      "loss": 0.888,
      "step": 39920
    },
    {
      "epoch": 15.12,
      "learning_rate": 2.803894022204042e-05,
      "loss": 0.9635,
      "step": 39930
    },
    {
      "epoch": 15.12,
      "learning_rate": 2.7997653211629372e-05,
      "loss": 0.899,
      "step": 39940
    },
    {
      "epoch": 15.13,
      "learning_rate": 2.7956391672429137e-05,
      "loss": 0.9189,
      "step": 39950
    },
    {
      "epoch": 15.13,
      "learning_rate": 2.7915155619036225e-05,
      "loss": 0.883,
      "step": 39960
    },
    {
      "epoch": 15.13,
      "learning_rate": 2.7873945066038098e-05,
      "loss": 0.8979,
      "step": 39970
    },
    {
      "epoch": 15.14,
      "learning_rate": 2.783276002801325e-05,
      "loss": 0.889,
      "step": 39980
    },
    {
      "epoch": 15.14,
      "learning_rate": 2.7791600519531026e-05,
      "loss": 0.862,
      "step": 39990
    },
    {
      "epoch": 15.14,
      "learning_rate": 2.7750466555151867e-05,
      "loss": 0.8723,
      "step": 40000
    },
    {
      "epoch": 15.15,
      "learning_rate": 2.7709358149427113e-05,
      "loss": 0.9256,
      "step": 40010
    },
    {
      "epoch": 15.15,
      "learning_rate": 2.7668275316899094e-05,
      "loss": 0.9023,
      "step": 40020
    },
    {
      "epoch": 15.16,
      "learning_rate": 2.762721807210107e-05,
      "loss": 0.9044,
      "step": 40030
    },
    {
      "epoch": 15.16,
      "learning_rate": 2.758618642955729e-05,
      "loss": 0.9267,
      "step": 40040
    },
    {
      "epoch": 15.16,
      "learning_rate": 2.7545180403782866e-05,
      "loss": 0.8813,
      "step": 40050
    },
    {
      "epoch": 15.17,
      "learning_rate": 2.750420000928392e-05,
      "loss": 0.9204,
      "step": 40060
    },
    {
      "epoch": 15.17,
      "learning_rate": 2.746324526055747e-05,
      "loss": 0.9676,
      "step": 40070
    },
    {
      "epoch": 15.17,
      "learning_rate": 2.74223161720915e-05,
      "loss": 0.8998,
      "step": 40080
    },
    {
      "epoch": 15.18,
      "learning_rate": 2.7381412758364865e-05,
      "loss": 0.8906,
      "step": 40090
    },
    {
      "epoch": 15.18,
      "learning_rate": 2.7340535033847416e-05,
      "loss": 0.9241,
      "step": 40100
    },
    {
      "epoch": 15.19,
      "learning_rate": 2.7299683012999776e-05,
      "loss": 0.9066,
      "step": 40110
    },
    {
      "epoch": 15.19,
      "learning_rate": 2.7258856710273627e-05,
      "loss": 0.9274,
      "step": 40120
    },
    {
      "epoch": 15.19,
      "learning_rate": 2.721805614011147e-05,
      "loss": 0.8723,
      "step": 40130
    },
    {
      "epoch": 15.2,
      "learning_rate": 2.7177281316946735e-05,
      "loss": 0.8528,
      "step": 40140
    },
    {
      "epoch": 15.2,
      "learning_rate": 2.713653225520374e-05,
      "loss": 0.9013,
      "step": 40150
    },
    {
      "epoch": 15.2,
      "learning_rate": 2.709580896929764e-05,
      "loss": 0.8513,
      "step": 40160
    },
    {
      "epoch": 15.21,
      "learning_rate": 2.705511147363453e-05,
      "loss": 0.9006,
      "step": 40170
    },
    {
      "epoch": 15.21,
      "learning_rate": 2.701443978261138e-05,
      "loss": 0.9022,
      "step": 40180
    },
    {
      "epoch": 15.22,
      "learning_rate": 2.6973793910616007e-05,
      "loss": 0.8842,
      "step": 40190
    },
    {
      "epoch": 15.22,
      "learning_rate": 2.6933173872027095e-05,
      "loss": 0.8909,
      "step": 40200
    },
    {
      "epoch": 15.22,
      "learning_rate": 2.6892579681214237e-05,
      "loss": 0.8986,
      "step": 40210
    },
    {
      "epoch": 15.23,
      "learning_rate": 2.6852011352537776e-05,
      "loss": 0.8998,
      "step": 40220
    },
    {
      "epoch": 15.23,
      "learning_rate": 2.6811468900349014e-05,
      "loss": 0.9078,
      "step": 40230
    },
    {
      "epoch": 15.24,
      "learning_rate": 2.6770952338990053e-05,
      "loss": 0.9241,
      "step": 40240
    },
    {
      "epoch": 15.24,
      "learning_rate": 2.673046168279383e-05,
      "loss": 0.869,
      "step": 40250
    },
    {
      "epoch": 15.24,
      "learning_rate": 2.6689996946084173e-05,
      "loss": 0.9267,
      "step": 40260
    },
    {
      "epoch": 15.25,
      "learning_rate": 2.6649558143175634e-05,
      "loss": 0.9643,
      "step": 40270
    },
    {
      "epoch": 15.25,
      "learning_rate": 2.660914528837367e-05,
      "loss": 0.8804,
      "step": 40280
    },
    {
      "epoch": 15.25,
      "learning_rate": 2.6568758395974558e-05,
      "loss": 0.8839,
      "step": 40290
    },
    {
      "epoch": 15.26,
      "learning_rate": 2.6528397480265377e-05,
      "loss": 0.8671,
      "step": 40300
    },
    {
      "epoch": 15.26,
      "learning_rate": 2.6488062555523994e-05,
      "loss": 0.9263,
      "step": 40310
    },
    {
      "epoch": 15.27,
      "learning_rate": 2.6447753636019147e-05,
      "loss": 0.904,
      "step": 40320
    },
    {
      "epoch": 15.27,
      "learning_rate": 2.6407470736010274e-05,
      "loss": 0.8822,
      "step": 40330
    },
    {
      "epoch": 15.27,
      "learning_rate": 2.6367213869747677e-05,
      "loss": 0.9358,
      "step": 40340
    },
    {
      "epoch": 15.28,
      "learning_rate": 2.6326983051472455e-05,
      "loss": 0.8499,
      "step": 40350
    },
    {
      "epoch": 15.28,
      "learning_rate": 2.628677829541645e-05,
      "loss": 0.9089,
      "step": 40360
    },
    {
      "epoch": 15.28,
      "learning_rate": 2.6246599615802325e-05,
      "loss": 0.9397,
      "step": 40370
    },
    {
      "epoch": 15.29,
      "learning_rate": 2.6206447026843527e-05,
      "loss": 0.8859,
      "step": 40380
    },
    {
      "epoch": 15.29,
      "learning_rate": 2.6166320542744183e-05,
      "loss": 0.9188,
      "step": 40390
    },
    {
      "epoch": 15.3,
      "learning_rate": 2.6126220177699278e-05,
      "loss": 0.941,
      "step": 40400
    },
    {
      "epoch": 15.3,
      "learning_rate": 2.6086145945894537e-05,
      "loss": 0.9124,
      "step": 40410
    },
    {
      "epoch": 15.3,
      "learning_rate": 2.6046097861506412e-05,
      "loss": 0.9066,
      "step": 40420
    },
    {
      "epoch": 15.31,
      "learning_rate": 2.600607593870218e-05,
      "loss": 0.8836,
      "step": 40430
    },
    {
      "epoch": 15.31,
      "learning_rate": 2.596608019163973e-05,
      "loss": 0.9257,
      "step": 40440
    },
    {
      "epoch": 15.31,
      "learning_rate": 2.5926110634467803e-05,
      "loss": 0.8898,
      "step": 40450
    },
    {
      "epoch": 15.32,
      "learning_rate": 2.5886167281325835e-05,
      "loss": 0.8735,
      "step": 40460
    },
    {
      "epoch": 15.32,
      "learning_rate": 2.584625014634402e-05,
      "loss": 0.9428,
      "step": 40470
    },
    {
      "epoch": 15.33,
      "learning_rate": 2.580635924364323e-05,
      "loss": 0.909,
      "step": 40480
    },
    {
      "epoch": 15.33,
      "learning_rate": 2.5766494587335134e-05,
      "loss": 0.8869,
      "step": 40490
    },
    {
      "epoch": 15.33,
      "learning_rate": 2.572665619152198e-05,
      "loss": 0.9166,
      "step": 40500
    },
    {
      "epoch": 15.34,
      "learning_rate": 2.5686844070296867e-05,
      "loss": 0.9001,
      "step": 40510
    },
    {
      "epoch": 15.34,
      "learning_rate": 2.5647058237743526e-05,
      "loss": 0.9079,
      "step": 40520
    },
    {
      "epoch": 15.35,
      "learning_rate": 2.560729870793641e-05,
      "loss": 0.9345,
      "step": 40530
    },
    {
      "epoch": 15.35,
      "learning_rate": 2.5567565494940704e-05,
      "loss": 0.8868,
      "step": 40540
    },
    {
      "epoch": 15.35,
      "learning_rate": 2.552785861281217e-05,
      "loss": 0.873,
      "step": 40550
    },
    {
      "epoch": 15.36,
      "learning_rate": 2.5488178075597356e-05,
      "loss": 0.9062,
      "step": 40560
    },
    {
      "epoch": 15.36,
      "learning_rate": 2.54485238973335e-05,
      "loss": 0.9049,
      "step": 40570
    },
    {
      "epoch": 15.36,
      "learning_rate": 2.5408896092048384e-05,
      "loss": 0.9182,
      "step": 40580
    },
    {
      "epoch": 15.37,
      "learning_rate": 2.5369294673760636e-05,
      "loss": 0.8588,
      "step": 40590
    },
    {
      "epoch": 15.37,
      "learning_rate": 2.5329719656479477e-05,
      "loss": 0.8555,
      "step": 40600
    },
    {
      "epoch": 15.38,
      "learning_rate": 2.5290171054204716e-05,
      "loss": 0.9251,
      "step": 40610
    },
    {
      "epoch": 15.38,
      "learning_rate": 2.525064888092691e-05,
      "loss": 0.9118,
      "step": 40620
    },
    {
      "epoch": 15.38,
      "learning_rate": 2.5211153150627264e-05,
      "loss": 0.8754,
      "step": 40630
    },
    {
      "epoch": 15.39,
      "learning_rate": 2.5171683877277517e-05,
      "loss": 0.8939,
      "step": 40640
    },
    {
      "epoch": 15.39,
      "learning_rate": 2.5132241074840225e-05,
      "loss": 0.8946,
      "step": 40650
    },
    {
      "epoch": 15.39,
      "learning_rate": 2.5092824757268475e-05,
      "loss": 0.8606,
      "step": 40660
    },
    {
      "epoch": 15.4,
      "learning_rate": 2.505343493850595e-05,
      "loss": 0.909,
      "step": 40670
    },
    {
      "epoch": 15.4,
      "learning_rate": 2.5014071632487056e-05,
      "loss": 0.9247,
      "step": 40680
    },
    {
      "epoch": 15.41,
      "learning_rate": 2.4974734853136717e-05,
      "loss": 0.9214,
      "step": 40690
    },
    {
      "epoch": 15.41,
      "learning_rate": 2.4935424614370528e-05,
      "loss": 0.9391,
      "step": 40700
    },
    {
      "epoch": 15.41,
      "learning_rate": 2.489614093009479e-05,
      "loss": 0.8898,
      "step": 40710
    },
    {
      "epoch": 15.42,
      "learning_rate": 2.4856883814206212e-05,
      "loss": 0.8971,
      "step": 40720
    },
    {
      "epoch": 15.42,
      "learning_rate": 2.4817653280592233e-05,
      "loss": 0.9059,
      "step": 40730
    },
    {
      "epoch": 15.42,
      "learning_rate": 2.4778449343130906e-05,
      "loss": 0.8772,
      "step": 40740
    },
    {
      "epoch": 15.43,
      "learning_rate": 2.4739272015690762e-05,
      "loss": 0.8891,
      "step": 40750
    },
    {
      "epoch": 15.43,
      "learning_rate": 2.4700121312130985e-05,
      "loss": 0.9597,
      "step": 40760
    },
    {
      "epoch": 15.44,
      "learning_rate": 2.466099724630144e-05,
      "loss": 0.9166,
      "step": 40770
    },
    {
      "epoch": 15.44,
      "learning_rate": 2.4621899832042395e-05,
      "loss": 0.8675,
      "step": 40780
    },
    {
      "epoch": 15.44,
      "learning_rate": 2.45828290831848e-05,
      "loss": 0.918,
      "step": 40790
    },
    {
      "epoch": 15.45,
      "learning_rate": 2.454378501355009e-05,
      "loss": 0.9296,
      "step": 40800
    },
    {
      "epoch": 15.45,
      "learning_rate": 2.450476763695032e-05,
      "loss": 0.8837,
      "step": 40810
    },
    {
      "epoch": 15.45,
      "learning_rate": 2.446577696718817e-05,
      "loss": 0.9137,
      "step": 40820
    },
    {
      "epoch": 15.46,
      "learning_rate": 2.4426813018056703e-05,
      "loss": 0.9402,
      "step": 40830
    },
    {
      "epoch": 15.46,
      "learning_rate": 2.4387875803339677e-05,
      "loss": 0.8654,
      "step": 40840
    },
    {
      "epoch": 15.47,
      "learning_rate": 2.4348965336811336e-05,
      "loss": 0.9303,
      "step": 40850
    },
    {
      "epoch": 15.47,
      "learning_rate": 2.4310081632236425e-05,
      "loss": 0.8956,
      "step": 40860
    },
    {
      "epoch": 15.47,
      "learning_rate": 2.4271224703370255e-05,
      "loss": 0.8506,
      "step": 40870
    },
    {
      "epoch": 15.48,
      "learning_rate": 2.423239456395876e-05,
      "loss": 0.8856,
      "step": 40880
    },
    {
      "epoch": 15.48,
      "learning_rate": 2.419359122773821e-05,
      "loss": 0.9197,
      "step": 40890
    },
    {
      "epoch": 15.49,
      "learning_rate": 2.4154814708435524e-05,
      "loss": 0.904,
      "step": 40900
    },
    {
      "epoch": 15.49,
      "learning_rate": 2.411606501976813e-05,
      "loss": 0.8949,
      "step": 40910
    },
    {
      "epoch": 15.49,
      "learning_rate": 2.4077342175443883e-05,
      "loss": 0.9094,
      "step": 40920
    },
    {
      "epoch": 15.5,
      "learning_rate": 2.4038646189161217e-05,
      "loss": 0.8961,
      "step": 40930
    },
    {
      "epoch": 15.5,
      "learning_rate": 2.3999977074609048e-05,
      "loss": 0.9463,
      "step": 40940
    },
    {
      "epoch": 15.5,
      "learning_rate": 2.3961334845466767e-05,
      "loss": 0.9031,
      "step": 40950
    },
    {
      "epoch": 15.51,
      "learning_rate": 2.39227195154043e-05,
      "loss": 0.8938,
      "step": 40960
    },
    {
      "epoch": 15.51,
      "learning_rate": 2.3884131098081986e-05,
      "loss": 0.9053,
      "step": 40970
    },
    {
      "epoch": 15.52,
      "learning_rate": 2.3845569607150675e-05,
      "loss": 0.9304,
      "step": 40980
    },
    {
      "epoch": 15.52,
      "learning_rate": 2.3807035056251736e-05,
      "loss": 0.8409,
      "step": 40990
    },
    {
      "epoch": 15.52,
      "learning_rate": 2.3768527459016944e-05,
      "loss": 0.8955,
      "step": 41000
    },
    {
      "epoch": 15.53,
      "learning_rate": 2.3730046829068565e-05,
      "loss": 0.9178,
      "step": 41010
    },
    {
      "epoch": 15.53,
      "learning_rate": 2.3691593180019366e-05,
      "loss": 0.8756,
      "step": 41020
    },
    {
      "epoch": 15.53,
      "learning_rate": 2.365316652547247e-05,
      "loss": 0.9072,
      "step": 41030
    },
    {
      "epoch": 15.54,
      "learning_rate": 2.3614766879021533e-05,
      "loss": 0.8852,
      "step": 41040
    },
    {
      "epoch": 15.54,
      "learning_rate": 2.3576394254250644e-05,
      "loss": 0.8885,
      "step": 41050
    },
    {
      "epoch": 15.55,
      "learning_rate": 2.35380486647343e-05,
      "loss": 0.8647,
      "step": 41060
    },
    {
      "epoch": 15.55,
      "learning_rate": 2.34997301240375e-05,
      "loss": 0.9332,
      "step": 41070
    },
    {
      "epoch": 15.55,
      "learning_rate": 2.3461438645715583e-05,
      "loss": 0.9392,
      "step": 41080
    },
    {
      "epoch": 15.56,
      "learning_rate": 2.342317424331436e-05,
      "loss": 0.8749,
      "step": 41090
    },
    {
      "epoch": 15.56,
      "learning_rate": 2.3384936930370095e-05,
      "loss": 0.9123,
      "step": 41100
    },
    {
      "epoch": 15.56,
      "learning_rate": 2.334672672040943e-05,
      "loss": 0.8516,
      "step": 41110
    },
    {
      "epoch": 15.57,
      "learning_rate": 2.330854362694942e-05,
      "loss": 0.8574,
      "step": 41120
    },
    {
      "epoch": 15.57,
      "learning_rate": 2.327038766349757e-05,
      "loss": 0.8909,
      "step": 41130
    },
    {
      "epoch": 15.58,
      "learning_rate": 2.3232258843551702e-05,
      "loss": 0.9216,
      "step": 41140
    },
    {
      "epoch": 15.58,
      "learning_rate": 2.3194157180600107e-05,
      "loss": 0.9048,
      "step": 41150
    },
    {
      "epoch": 15.58,
      "learning_rate": 2.315608268812146e-05,
      "loss": 0.8898,
      "step": 41160
    },
    {
      "epoch": 15.59,
      "learning_rate": 2.3118035379584812e-05,
      "loss": 0.8918,
      "step": 41170
    },
    {
      "epoch": 15.59,
      "learning_rate": 2.3080015268449597e-05,
      "loss": 0.924,
      "step": 41180
    },
    {
      "epoch": 15.59,
      "learning_rate": 2.304202236816566e-05,
      "loss": 0.8889,
      "step": 41190
    },
    {
      "epoch": 15.6,
      "learning_rate": 2.3004056692173127e-05,
      "loss": 0.9057,
      "step": 41200
    },
    {
      "epoch": 15.6,
      "learning_rate": 2.296611825390259e-05,
      "loss": 0.8724,
      "step": 41210
    },
    {
      "epoch": 15.61,
      "learning_rate": 2.2928207066774976e-05,
      "loss": 0.8718,
      "step": 41220
    },
    {
      "epoch": 15.61,
      "learning_rate": 2.2890323144201565e-05,
      "loss": 0.8916,
      "step": 41230
    },
    {
      "epoch": 15.61,
      "learning_rate": 2.2852466499584012e-05,
      "loss": 0.9108,
      "step": 41240
    },
    {
      "epoch": 15.62,
      "learning_rate": 2.2814637146314267e-05,
      "loss": 0.8796,
      "step": 41250
    },
    {
      "epoch": 15.62,
      "learning_rate": 2.2776835097774684e-05,
      "loss": 0.9154,
      "step": 41260
    },
    {
      "epoch": 15.63,
      "learning_rate": 2.273906036733794e-05,
      "loss": 0.9506,
      "step": 41270
    },
    {
      "epoch": 15.63,
      "learning_rate": 2.2701312968367037e-05,
      "loss": 0.9166,
      "step": 41280
    },
    {
      "epoch": 15.63,
      "learning_rate": 2.2663592914215327e-05,
      "loss": 0.9247,
      "step": 41290
    },
    {
      "epoch": 15.64,
      "learning_rate": 2.2625900218226492e-05,
      "loss": 0.8951,
      "step": 41300
    },
    {
      "epoch": 15.64,
      "learning_rate": 2.2588234893734493e-05,
      "loss": 0.9129,
      "step": 41310
    },
    {
      "epoch": 15.64,
      "learning_rate": 2.255059695406364e-05,
      "loss": 0.8449,
      "step": 41320
    },
    {
      "epoch": 15.65,
      "learning_rate": 2.251298641252857e-05,
      "loss": 0.882,
      "step": 41330
    },
    {
      "epoch": 15.65,
      "learning_rate": 2.247540328243419e-05,
      "loss": 0.907,
      "step": 41340
    },
    {
      "epoch": 15.66,
      "learning_rate": 2.2437847577075787e-05,
      "loss": 0.9346,
      "step": 41350
    },
    {
      "epoch": 15.66,
      "learning_rate": 2.2400319309738815e-05,
      "loss": 0.8758,
      "step": 41360
    },
    {
      "epoch": 15.66,
      "learning_rate": 2.236281849369912e-05,
      "loss": 0.9385,
      "step": 41370
    },
    {
      "epoch": 15.67,
      "learning_rate": 2.232534514222283e-05,
      "loss": 0.9567,
      "step": 41380
    },
    {
      "epoch": 15.67,
      "learning_rate": 2.228789926856635e-05,
      "loss": 0.9252,
      "step": 41390
    },
    {
      "epoch": 15.67,
      "learning_rate": 2.2250480885976322e-05,
      "loss": 0.9001,
      "step": 41400
    },
    {
      "epoch": 15.68,
      "learning_rate": 2.2213090007689753e-05,
      "loss": 0.8748,
      "step": 41410
    },
    {
      "epoch": 15.68,
      "learning_rate": 2.2175726646933793e-05,
      "loss": 0.8608,
      "step": 41420
    },
    {
      "epoch": 15.69,
      "learning_rate": 2.2138390816925958e-05,
      "loss": 0.9396,
      "step": 41430
    },
    {
      "epoch": 15.69,
      "learning_rate": 2.2101082530874005e-05,
      "loss": 0.8938,
      "step": 41440
    },
    {
      "epoch": 15.69,
      "learning_rate": 2.2063801801975937e-05,
      "loss": 0.9878,
      "step": 41450
    },
    {
      "epoch": 15.7,
      "learning_rate": 2.2026548643419997e-05,
      "loss": 0.9529,
      "step": 41460
    },
    {
      "epoch": 15.7,
      "learning_rate": 2.1989323068384716e-05,
      "loss": 0.9551,
      "step": 41470
    },
    {
      "epoch": 15.7,
      "learning_rate": 2.195212509003879e-05,
      "loss": 0.9008,
      "step": 41480
    },
    {
      "epoch": 15.71,
      "learning_rate": 2.191495472154126e-05,
      "loss": 0.9411,
      "step": 41490
    },
    {
      "epoch": 15.71,
      "learning_rate": 2.187781197604124e-05,
      "loss": 0.9276,
      "step": 41500
    },
    {
      "epoch": 15.72,
      "learning_rate": 2.184069686667828e-05,
      "loss": 0.8862,
      "step": 41510
    },
    {
      "epoch": 15.72,
      "learning_rate": 2.180731690800064e-05,
      "loss": 0.9179,
      "step": 41520
    },
    {
      "epoch": 15.72,
      "learning_rate": 2.177025434346216e-05,
      "loss": 0.9415,
      "step": 41530
    },
    {
      "epoch": 15.73,
      "learning_rate": 2.1733219453109764e-05,
      "loss": 0.9009,
      "step": 41540
    },
    {
      "epoch": 15.73,
      "learning_rate": 2.16962122500448e-05,
      "loss": 0.9029,
      "step": 41550
    },
    {
      "epoch": 15.73,
      "learning_rate": 2.1659232747358682e-05,
      "loss": 0.934,
      "step": 41560
    },
    {
      "epoch": 15.74,
      "learning_rate": 2.1622280958133133e-05,
      "loss": 0.8836,
      "step": 41570
    },
    {
      "epoch": 15.74,
      "learning_rate": 2.158535689544007e-05,
      "loss": 0.8916,
      "step": 41580
    },
    {
      "epoch": 15.75,
      "learning_rate": 2.1548460572341544e-05,
      "loss": 0.8767,
      "step": 41590
    },
    {
      "epoch": 15.75,
      "learning_rate": 2.1511592001889856e-05,
      "loss": 0.9293,
      "step": 41600
    },
    {
      "epoch": 15.75,
      "learning_rate": 2.147475119712743e-05,
      "loss": 0.931,
      "step": 41610
    },
    {
      "epoch": 15.76,
      "learning_rate": 2.143793817108689e-05,
      "loss": 0.9204,
      "step": 41620
    },
    {
      "epoch": 15.76,
      "learning_rate": 2.140115293679108e-05,
      "loss": 0.9005,
      "step": 41630
    },
    {
      "epoch": 15.77,
      "learning_rate": 2.13643955072529e-05,
      "loss": 0.8757,
      "step": 41640
    },
    {
      "epoch": 15.77,
      "learning_rate": 2.1327665895475548e-05,
      "loss": 0.8809,
      "step": 41650
    },
    {
      "epoch": 15.77,
      "learning_rate": 2.1290964114452327e-05,
      "loss": 0.9083,
      "step": 41660
    },
    {
      "epoch": 15.78,
      "learning_rate": 2.1254290177166624e-05,
      "loss": 0.8995,
      "step": 41670
    },
    {
      "epoch": 15.78,
      "learning_rate": 2.1217644096592082e-05,
      "loss": 0.8825,
      "step": 41680
    },
    {
      "epoch": 15.78,
      "learning_rate": 2.118102588569243e-05,
      "loss": 0.9587,
      "step": 41690
    },
    {
      "epoch": 15.79,
      "learning_rate": 2.114443555742156e-05,
      "loss": 0.89,
      "step": 41700
    },
    {
      "epoch": 15.79,
      "learning_rate": 2.11078731247235e-05,
      "loss": 0.8523,
      "step": 41710
    },
    {
      "epoch": 15.8,
      "learning_rate": 2.107133860053242e-05,
      "loss": 0.8775,
      "step": 41720
    },
    {
      "epoch": 15.8,
      "learning_rate": 2.1034831997772552e-05,
      "loss": 0.9173,
      "step": 41730
    },
    {
      "epoch": 15.8,
      "learning_rate": 2.0998353329358357e-05,
      "loss": 0.8821,
      "step": 41740
    },
    {
      "epoch": 15.81,
      "learning_rate": 2.0961902608194263e-05,
      "loss": 0.9383,
      "step": 41750
    },
    {
      "epoch": 15.81,
      "learning_rate": 2.0925479847175e-05,
      "loss": 0.9126,
      "step": 41760
    },
    {
      "epoch": 15.81,
      "learning_rate": 2.0889085059185308e-05,
      "loss": 0.9281,
      "step": 41770
    },
    {
      "epoch": 15.82,
      "learning_rate": 2.085271825709999e-05,
      "loss": 0.9118,
      "step": 41780
    },
    {
      "epoch": 15.82,
      "learning_rate": 2.0816379453783995e-05,
      "loss": 0.9339,
      "step": 41790
    },
    {
      "epoch": 15.83,
      "learning_rate": 2.078006866209242e-05,
      "loss": 0.9263,
      "step": 41800
    },
    {
      "epoch": 15.83,
      "learning_rate": 2.0743785894870317e-05,
      "loss": 0.9219,
      "step": 41810
    },
    {
      "epoch": 15.83,
      "learning_rate": 2.0707531164952974e-05,
      "loss": 0.9119,
      "step": 41820
    },
    {
      "epoch": 15.84,
      "learning_rate": 2.067130448516571e-05,
      "loss": 0.9003,
      "step": 41830
    },
    {
      "epoch": 15.84,
      "learning_rate": 2.0635105868323824e-05,
      "loss": 0.8981,
      "step": 41840
    },
    {
      "epoch": 15.84,
      "learning_rate": 2.059893532723285e-05,
      "loss": 0.8994,
      "step": 41850
    },
    {
      "epoch": 15.85,
      "learning_rate": 2.056279287468824e-05,
      "loss": 0.8895,
      "step": 41860
    },
    {
      "epoch": 15.85,
      "learning_rate": 2.0526678523475585e-05,
      "loss": 0.8823,
      "step": 41870
    },
    {
      "epoch": 15.86,
      "learning_rate": 2.0490592286370602e-05,
      "loss": 0.8872,
      "step": 41880
    },
    {
      "epoch": 15.86,
      "learning_rate": 2.0454534176138907e-05,
      "loss": 0.9246,
      "step": 41890
    },
    {
      "epoch": 15.86,
      "learning_rate": 2.041850420553627e-05,
      "loss": 0.9065,
      "step": 41900
    },
    {
      "epoch": 15.87,
      "learning_rate": 2.0382502387308535e-05,
      "loss": 0.9049,
      "step": 41910
    },
    {
      "epoch": 15.87,
      "learning_rate": 2.034652873419145e-05,
      "loss": 0.8928,
      "step": 41920
    },
    {
      "epoch": 15.88,
      "learning_rate": 2.03105832589109e-05,
      "loss": 0.8531,
      "step": 41930
    },
    {
      "epoch": 15.88,
      "learning_rate": 2.027466597418287e-05,
      "loss": 0.928,
      "step": 41940
    },
    {
      "epoch": 15.88,
      "learning_rate": 2.0238776892713195e-05,
      "loss": 0.873,
      "step": 41950
    },
    {
      "epoch": 15.89,
      "learning_rate": 2.0202916027197882e-05,
      "loss": 0.9132,
      "step": 41960
    },
    {
      "epoch": 15.89,
      "learning_rate": 2.0167083390322895e-05,
      "loss": 0.9205,
      "step": 41970
    },
    {
      "epoch": 15.89,
      "learning_rate": 2.0131278994764192e-05,
      "loss": 0.8374,
      "step": 41980
    },
    {
      "epoch": 15.9,
      "learning_rate": 2.0095502853187776e-05,
      "loss": 0.9106,
      "step": 41990
    },
    {
      "epoch": 15.9,
      "learning_rate": 2.0059754978249655e-05,
      "loss": 0.9539,
      "step": 42000
    },
    {
      "epoch": 15.91,
      "learning_rate": 2.002403538259583e-05,
      "loss": 0.9517,
      "step": 42010
    },
    {
      "epoch": 15.91,
      "learning_rate": 1.9988344078862308e-05,
      "loss": 0.9094,
      "step": 42020
    },
    {
      "epoch": 15.91,
      "learning_rate": 1.995268107967505e-05,
      "loss": 0.8901,
      "step": 42030
    },
    {
      "epoch": 15.92,
      "learning_rate": 1.991704639765004e-05,
      "loss": 0.9168,
      "step": 42040
    },
    {
      "epoch": 15.92,
      "learning_rate": 1.988144004539323e-05,
      "loss": 0.9246,
      "step": 42050
    },
    {
      "epoch": 15.92,
      "learning_rate": 1.9845862035500572e-05,
      "loss": 0.9139,
      "step": 42060
    },
    {
      "epoch": 15.93,
      "learning_rate": 1.981031238055796e-05,
      "loss": 0.914,
      "step": 42070
    },
    {
      "epoch": 15.93,
      "learning_rate": 1.977479109314131e-05,
      "loss": 0.9287,
      "step": 42080
    },
    {
      "epoch": 15.94,
      "learning_rate": 1.9739298185816403e-05,
      "loss": 0.8852,
      "step": 42090
    },
    {
      "epoch": 15.94,
      "learning_rate": 1.970383367113905e-05,
      "loss": 0.9457,
      "step": 42100
    },
    {
      "epoch": 15.94,
      "learning_rate": 1.9668397561655084e-05,
      "loss": 0.9465,
      "step": 42110
    },
    {
      "epoch": 15.95,
      "learning_rate": 1.9632989869900143e-05,
      "loss": 0.9,
      "step": 42120
    },
    {
      "epoch": 15.95,
      "learning_rate": 1.959761060839993e-05,
      "loss": 0.9245,
      "step": 42130
    },
    {
      "epoch": 15.95,
      "learning_rate": 1.956225978967e-05,
      "loss": 0.9042,
      "step": 42140
    },
    {
      "epoch": 15.96,
      "learning_rate": 1.952693742621592e-05,
      "loss": 0.899,
      "step": 42150
    },
    {
      "epoch": 15.96,
      "learning_rate": 1.9491643530533153e-05,
      "loss": 0.9394,
      "step": 42160
    },
    {
      "epoch": 15.97,
      "learning_rate": 1.945637811510711e-05,
      "loss": 0.9084,
      "step": 42170
    },
    {
      "epoch": 15.97,
      "learning_rate": 1.9421141192413117e-05,
      "loss": 0.8649,
      "step": 42180
    },
    {
      "epoch": 15.97,
      "learning_rate": 1.9385932774916438e-05,
      "loss": 0.8957,
      "step": 42190
    },
    {
      "epoch": 15.98,
      "learning_rate": 1.9350752875072197e-05,
      "loss": 0.9212,
      "step": 42200
    },
    {
      "epoch": 15.98,
      "learning_rate": 1.9315601505325485e-05,
      "loss": 0.9078,
      "step": 42210
    },
    {
      "epoch": 15.98,
      "learning_rate": 1.9280478678111304e-05,
      "loss": 0.8755,
      "step": 42220
    },
    {
      "epoch": 15.99,
      "learning_rate": 1.9245384405854515e-05,
      "loss": 0.9028,
      "step": 42230
    },
    {
      "epoch": 15.99,
      "learning_rate": 1.921031870096992e-05,
      "loss": 0.916,
      "step": 42240
    },
    {
      "epoch": 16.0,
      "learning_rate": 1.9175281575862214e-05,
      "loss": 0.9347,
      "step": 42250
    },
    {
      "epoch": 16.0,
      "learning_rate": 1.9140273042925925e-05,
      "loss": 0.8608,
      "step": 42260
    },
    {
      "epoch": 16.0,
      "learning_rate": 1.9105293114545518e-05,
      "loss": 0.928,
      "step": 42270
    },
    {
      "epoch": 16.01,
      "learning_rate": 1.9070341803095337e-05,
      "loss": 0.951,
      "step": 42280
    },
    {
      "epoch": 16.01,
      "learning_rate": 1.903541912093959e-05,
      "loss": 0.8831,
      "step": 42290
    },
    {
      "epoch": 16.02,
      "learning_rate": 1.9000525080432386e-05,
      "loss": 0.9315,
      "step": 42300
    },
    {
      "epoch": 16.02,
      "learning_rate": 1.8965659693917625e-05,
      "loss": 0.9131,
      "step": 42310
    },
    {
      "epoch": 16.02,
      "learning_rate": 1.8930822973729146e-05,
      "loss": 0.9002,
      "step": 42320
    },
    {
      "epoch": 16.03,
      "learning_rate": 1.889601493219062e-05,
      "loss": 0.8602,
      "step": 42330
    },
    {
      "epoch": 16.03,
      "learning_rate": 1.8861235581615587e-05,
      "loss": 0.9538,
      "step": 42340
    },
    {
      "epoch": 16.03,
      "learning_rate": 1.882648493430742e-05,
      "loss": 0.8783,
      "step": 42350
    },
    {
      "epoch": 16.04,
      "learning_rate": 1.8791763002559372e-05,
      "loss": 0.8925,
      "step": 42360
    },
    {
      "epoch": 16.04,
      "learning_rate": 1.8757069798654446e-05,
      "loss": 0.9294,
      "step": 42370
    },
    {
      "epoch": 16.05,
      "learning_rate": 1.8722405334865588e-05,
      "loss": 0.9314,
      "step": 42380
    },
    {
      "epoch": 16.05,
      "learning_rate": 1.868776962345553e-05,
      "loss": 0.8591,
      "step": 42390
    },
    {
      "epoch": 16.05,
      "learning_rate": 1.865316267667684e-05,
      "loss": 0.9422,
      "step": 42400
    },
    {
      "epoch": 16.06,
      "learning_rate": 1.861858450677193e-05,
      "loss": 0.9379,
      "step": 42410
    },
    {
      "epoch": 16.06,
      "learning_rate": 1.8584035125972955e-05,
      "loss": 0.8435,
      "step": 42420
    },
    {
      "epoch": 16.06,
      "learning_rate": 1.854951454650198e-05,
      "loss": 0.9081,
      "step": 42430
    },
    {
      "epoch": 16.07,
      "learning_rate": 1.8515022780570834e-05,
      "loss": 0.86,
      "step": 42440
    },
    {
      "epoch": 16.07,
      "learning_rate": 1.8480559840381162e-05,
      "loss": 0.9351,
      "step": 42450
    },
    {
      "epoch": 16.08,
      "learning_rate": 1.8446125738124396e-05,
      "loss": 0.9085,
      "step": 42460
    },
    {
      "epoch": 16.08,
      "learning_rate": 1.8411720485981843e-05,
      "loss": 0.8926,
      "step": 42470
    },
    {
      "epoch": 16.08,
      "learning_rate": 1.837734409612446e-05,
      "loss": 0.899,
      "step": 42480
    },
    {
      "epoch": 16.09,
      "learning_rate": 1.8342996580713123e-05,
      "loss": 0.9233,
      "step": 42490
    },
    {
      "epoch": 16.09,
      "learning_rate": 1.8308677951898435e-05,
      "loss": 0.8854,
      "step": 42500
    },
    {
      "epoch": 16.09,
      "learning_rate": 1.827438822182079e-05,
      "loss": 0.9,
      "step": 42510
    },
    {
      "epoch": 16.1,
      "learning_rate": 1.8240127402610375e-05,
      "loss": 0.9018,
      "step": 42520
    },
    {
      "epoch": 16.1,
      "learning_rate": 1.820589550638714e-05,
      "loss": 0.8602,
      "step": 42530
    },
    {
      "epoch": 16.11,
      "learning_rate": 1.8171692545260776e-05,
      "loss": 0.864,
      "step": 42540
    },
    {
      "epoch": 16.11,
      "learning_rate": 1.8137518531330767e-05,
      "loss": 0.8782,
      "step": 42550
    },
    {
      "epoch": 16.11,
      "learning_rate": 1.8103373476686348e-05,
      "loss": 0.8893,
      "step": 42560
    },
    {
      "epoch": 16.12,
      "learning_rate": 1.8069257393406525e-05,
      "loss": 0.8808,
      "step": 42570
    },
    {
      "epoch": 16.12,
      "learning_rate": 1.8035170293560065e-05,
      "loss": 0.9057,
      "step": 42580
    },
    {
      "epoch": 16.12,
      "learning_rate": 1.8001112189205414e-05,
      "loss": 0.8557,
      "step": 42590
    },
    {
      "epoch": 16.13,
      "learning_rate": 1.7967083092390823e-05,
      "loss": 0.8833,
      "step": 42600
    },
    {
      "epoch": 16.13,
      "learning_rate": 1.7933083015154263e-05,
      "loss": 0.8767,
      "step": 42610
    },
    {
      "epoch": 16.14,
      "learning_rate": 1.7899111969523452e-05,
      "loss": 0.8613,
      "step": 42620
    },
    {
      "epoch": 16.14,
      "learning_rate": 1.7865169967515816e-05,
      "loss": 0.9039,
      "step": 42630
    },
    {
      "epoch": 16.14,
      "learning_rate": 1.7831257021138546e-05,
      "loss": 0.9107,
      "step": 42640
    },
    {
      "epoch": 16.15,
      "learning_rate": 1.7797373142388484e-05,
      "loss": 0.907,
      "step": 42650
    },
    {
      "epoch": 16.15,
      "learning_rate": 1.7763518343252238e-05,
      "loss": 0.9324,
      "step": 42660
    },
    {
      "epoch": 16.16,
      "learning_rate": 1.772969263570614e-05,
      "loss": 0.9327,
      "step": 42670
    },
    {
      "epoch": 16.16,
      "learning_rate": 1.769589603171622e-05,
      "loss": 0.9213,
      "step": 42680
    },
    {
      "epoch": 16.16,
      "learning_rate": 1.76621285432382e-05,
      "loss": 0.9142,
      "step": 42690
    },
    {
      "epoch": 16.17,
      "learning_rate": 1.762839018221748e-05,
      "loss": 0.9151,
      "step": 42700
    },
    {
      "epoch": 16.17,
      "learning_rate": 1.7594680960589204e-05,
      "loss": 0.8841,
      "step": 42710
    },
    {
      "epoch": 16.17,
      "learning_rate": 1.756100089027821e-05,
      "loss": 0.9023,
      "step": 42720
    },
    {
      "epoch": 16.18,
      "learning_rate": 1.7527349983198926e-05,
      "loss": 0.8458,
      "step": 42730
    },
    {
      "epoch": 16.18,
      "learning_rate": 1.7493728251255625e-05,
      "loss": 0.8955,
      "step": 42740
    },
    {
      "epoch": 16.19,
      "learning_rate": 1.7460135706342152e-05,
      "loss": 0.9184,
      "step": 42750
    },
    {
      "epoch": 16.19,
      "learning_rate": 1.742657236034201e-05,
      "loss": 0.8832,
      "step": 42760
    },
    {
      "epoch": 16.19,
      "learning_rate": 1.7393038225128433e-05,
      "loss": 0.907,
      "step": 42770
    },
    {
      "epoch": 16.2,
      "learning_rate": 1.7359533312564325e-05,
      "loss": 0.8755,
      "step": 42780
    },
    {
      "epoch": 16.2,
      "learning_rate": 1.7326057634502148e-05,
      "loss": 0.9054,
      "step": 42790
    },
    {
      "epoch": 16.2,
      "learning_rate": 1.729261120278418e-05,
      "loss": 0.8575,
      "step": 42800
    },
    {
      "epoch": 16.21,
      "learning_rate": 1.7259194029242263e-05,
      "loss": 0.88,
      "step": 42810
    },
    {
      "epoch": 16.21,
      "learning_rate": 1.7225806125697853e-05,
      "loss": 0.8974,
      "step": 42820
    },
    {
      "epoch": 16.22,
      "learning_rate": 1.719244750396216e-05,
      "loss": 0.9113,
      "step": 42830
    },
    {
      "epoch": 16.22,
      "learning_rate": 1.7159118175835877e-05,
      "loss": 0.8451,
      "step": 42840
    },
    {
      "epoch": 16.22,
      "learning_rate": 1.712581815310952e-05,
      "loss": 0.9399,
      "step": 42850
    },
    {
      "epoch": 16.23,
      "learning_rate": 1.7092547447563144e-05,
      "loss": 0.8719,
      "step": 42860
    },
    {
      "epoch": 16.23,
      "learning_rate": 1.7059306070966386e-05,
      "loss": 0.8876,
      "step": 42870
    },
    {
      "epoch": 16.23,
      "learning_rate": 1.702609403507859e-05,
      "loss": 0.8645,
      "step": 42880
    },
    {
      "epoch": 16.24,
      "learning_rate": 1.69929113516487e-05,
      "loss": 0.9111,
      "step": 42890
    },
    {
      "epoch": 16.24,
      "learning_rate": 1.6959758032415207e-05,
      "loss": 0.9243,
      "step": 42900
    },
    {
      "epoch": 16.25,
      "learning_rate": 1.692663408910633e-05,
      "loss": 0.867,
      "step": 42910
    },
    {
      "epoch": 16.25,
      "learning_rate": 1.689353953343985e-05,
      "loss": 0.8923,
      "step": 42920
    },
    {
      "epoch": 16.25,
      "learning_rate": 1.6860474377123105e-05,
      "loss": 0.9565,
      "step": 42930
    },
    {
      "epoch": 16.26,
      "learning_rate": 1.682743863185309e-05,
      "loss": 0.9003,
      "step": 42940
    },
    {
      "epoch": 16.26,
      "learning_rate": 1.679443230931633e-05,
      "loss": 0.8928,
      "step": 42950
    },
    {
      "epoch": 16.27,
      "learning_rate": 1.676145542118901e-05,
      "loss": 0.8852,
      "step": 42960
    },
    {
      "epoch": 16.27,
      "learning_rate": 1.672850797913694e-05,
      "loss": 0.9195,
      "step": 42970
    },
    {
      "epoch": 16.27,
      "learning_rate": 1.6695589994815365e-05,
      "loss": 0.8629,
      "step": 42980
    },
    {
      "epoch": 16.28,
      "learning_rate": 1.6662701479869235e-05,
      "loss": 0.9476,
      "step": 42990
    },
    {
      "epoch": 16.28,
      "learning_rate": 1.6629842445933065e-05,
      "loss": 0.9164,
      "step": 43000
    },
    {
      "epoch": 16.28,
      "learning_rate": 1.659701290463085e-05,
      "loss": 0.8986,
      "step": 43010
    },
    {
      "epoch": 16.29,
      "learning_rate": 1.6564212867576213e-05,
      "loss": 0.886,
      "step": 43020
    },
    {
      "epoch": 16.29,
      "learning_rate": 1.6531442346372417e-05,
      "loss": 0.8727,
      "step": 43030
    },
    {
      "epoch": 16.3,
      "learning_rate": 1.6498701352612133e-05,
      "loss": 0.9352,
      "step": 43040
    },
    {
      "epoch": 16.3,
      "learning_rate": 1.6465989897877697e-05,
      "loss": 0.9189,
      "step": 43050
    },
    {
      "epoch": 16.3,
      "learning_rate": 1.6433307993740975e-05,
      "loss": 0.895,
      "step": 43060
    },
    {
      "epoch": 16.31,
      "learning_rate": 1.640065565176331e-05,
      "loss": 0.8992,
      "step": 43070
    },
    {
      "epoch": 16.31,
      "learning_rate": 1.6368032883495677e-05,
      "loss": 0.9475,
      "step": 43080
    },
    {
      "epoch": 16.31,
      "learning_rate": 1.6335439700478537e-05,
      "loss": 0.9117,
      "step": 43090
    },
    {
      "epoch": 16.32,
      "learning_rate": 1.6302876114241906e-05,
      "loss": 0.8734,
      "step": 43100
    },
    {
      "epoch": 16.32,
      "learning_rate": 1.6270342136305362e-05,
      "loss": 0.854,
      "step": 43110
    },
    {
      "epoch": 16.33,
      "learning_rate": 1.62378377781779e-05,
      "loss": 0.9457,
      "step": 43120
    },
    {
      "epoch": 16.33,
      "learning_rate": 1.6205363051358157e-05,
      "loss": 0.8982,
      "step": 43130
    },
    {
      "epoch": 16.33,
      "learning_rate": 1.6172917967334223e-05,
      "loss": 0.8732,
      "step": 43140
    },
    {
      "epoch": 16.34,
      "learning_rate": 1.614050253758371e-05,
      "loss": 0.887,
      "step": 43150
    },
    {
      "epoch": 16.34,
      "learning_rate": 1.6108116773573777e-05,
      "loss": 0.8905,
      "step": 43160
    },
    {
      "epoch": 16.34,
      "learning_rate": 1.6075760686761066e-05,
      "loss": 0.8671,
      "step": 43170
    },
    {
      "epoch": 16.35,
      "learning_rate": 1.6043434288591663e-05,
      "loss": 0.9111,
      "step": 43180
    },
    {
      "epoch": 16.35,
      "learning_rate": 1.6011137590501234e-05,
      "loss": 0.9346,
      "step": 43190
    },
    {
      "epoch": 16.36,
      "learning_rate": 1.5978870603914896e-05,
      "loss": 0.9013,
      "step": 43200
    },
    {
      "epoch": 16.36,
      "learning_rate": 1.5946633340247274e-05,
      "loss": 0.8977,
      "step": 43210
    },
    {
      "epoch": 16.36,
      "learning_rate": 1.591442581090249e-05,
      "loss": 0.8863,
      "step": 43220
    },
    {
      "epoch": 16.37,
      "learning_rate": 1.5882248027274095e-05,
      "loss": 0.8854,
      "step": 43230
    },
    {
      "epoch": 16.37,
      "learning_rate": 1.585010000074515e-05,
      "loss": 0.8924,
      "step": 43240
    },
    {
      "epoch": 16.37,
      "learning_rate": 1.5817981742688203e-05,
      "loss": 0.8791,
      "step": 43250
    },
    {
      "epoch": 16.38,
      "learning_rate": 1.5785893264465257e-05,
      "loss": 0.8821,
      "step": 43260
    },
    {
      "epoch": 16.38,
      "learning_rate": 1.5753834577427782e-05,
      "loss": 0.9089,
      "step": 43270
    },
    {
      "epoch": 16.39,
      "learning_rate": 1.5721805692916725e-05,
      "loss": 0.8925,
      "step": 43280
    },
    {
      "epoch": 16.39,
      "learning_rate": 1.5689806622262438e-05,
      "loss": 0.9397,
      "step": 43290
    },
    {
      "epoch": 16.39,
      "learning_rate": 1.5657837376784767e-05,
      "loss": 0.9218,
      "step": 43300
    },
    {
      "epoch": 16.4,
      "learning_rate": 1.5625897967793012e-05,
      "loss": 0.8709,
      "step": 43310
    },
    {
      "epoch": 16.4,
      "learning_rate": 1.5593988406585912e-05,
      "loss": 0.8847,
      "step": 43320
    },
    {
      "epoch": 16.41,
      "learning_rate": 1.556210870445164e-05,
      "loss": 0.9067,
      "step": 43330
    },
    {
      "epoch": 16.41,
      "learning_rate": 1.5530258872667835e-05,
      "loss": 0.888,
      "step": 43340
    },
    {
      "epoch": 16.41,
      "learning_rate": 1.549843892250149e-05,
      "loss": 0.8839,
      "step": 43350
    },
    {
      "epoch": 16.42,
      "learning_rate": 1.54666488652091e-05,
      "loss": 0.9025,
      "step": 43360
    },
    {
      "epoch": 16.42,
      "learning_rate": 1.5434888712036577e-05,
      "loss": 0.8986,
      "step": 43370
    },
    {
      "epoch": 16.42,
      "learning_rate": 1.5403158474219236e-05,
      "loss": 0.9124,
      "step": 43380
    },
    {
      "epoch": 16.43,
      "learning_rate": 1.5371458162981843e-05,
      "loss": 0.855,
      "step": 43390
    },
    {
      "epoch": 16.43,
      "learning_rate": 1.5339787789538505e-05,
      "loss": 0.9021,
      "step": 43400
    },
    {
      "epoch": 16.44,
      "learning_rate": 1.5308147365092805e-05,
      "loss": 0.9084,
      "step": 43410
    },
    {
      "epoch": 16.44,
      "learning_rate": 1.5276536900837714e-05,
      "loss": 0.9106,
      "step": 43420
    },
    {
      "epoch": 16.44,
      "learning_rate": 1.5244956407955601e-05,
      "loss": 0.9263,
      "step": 43430
    },
    {
      "epoch": 16.45,
      "learning_rate": 1.5213405897618227e-05,
      "loss": 0.8995,
      "step": 43440
    },
    {
      "epoch": 16.45,
      "learning_rate": 1.5181885380986772e-05,
      "loss": 0.896,
      "step": 43450
    },
    {
      "epoch": 16.45,
      "learning_rate": 1.5150394869211748e-05,
      "loss": 0.9289,
      "step": 43460
    },
    {
      "epoch": 16.46,
      "learning_rate": 1.5118934373433103e-05,
      "loss": 0.936,
      "step": 43470
    },
    {
      "epoch": 16.46,
      "learning_rate": 1.5087503904780165e-05,
      "loss": 0.8905,
      "step": 43480
    },
    {
      "epoch": 16.47,
      "learning_rate": 1.505610347437163e-05,
      "loss": 0.8784,
      "step": 43490
    },
    {
      "epoch": 16.47,
      "learning_rate": 1.5024733093315579e-05,
      "loss": 0.9055,
      "step": 43500
    },
    {
      "epoch": 16.47,
      "learning_rate": 1.4993392772709402e-05,
      "loss": 0.8763,
      "step": 43510
    },
    {
      "epoch": 16.48,
      "learning_rate": 1.4962082523639931e-05,
      "loss": 0.9263,
      "step": 43520
    },
    {
      "epoch": 16.48,
      "learning_rate": 1.4930802357183348e-05,
      "loss": 0.9332,
      "step": 43530
    },
    {
      "epoch": 16.48,
      "learning_rate": 1.489955228440515e-05,
      "loss": 0.8947,
      "step": 43540
    },
    {
      "epoch": 16.49,
      "learning_rate": 1.4868332316360233e-05,
      "loss": 0.8988,
      "step": 43550
    },
    {
      "epoch": 16.49,
      "learning_rate": 1.4837142464092845e-05,
      "loss": 0.9323,
      "step": 43560
    },
    {
      "epoch": 16.5,
      "learning_rate": 1.4805982738636504e-05,
      "loss": 0.9153,
      "step": 43570
    },
    {
      "epoch": 16.5,
      "learning_rate": 1.4774853151014168e-05,
      "loss": 0.9,
      "step": 43580
    },
    {
      "epoch": 16.5,
      "learning_rate": 1.4743753712238085e-05,
      "loss": 0.885,
      "step": 43590
    },
    {
      "epoch": 16.51,
      "learning_rate": 1.4712684433309853e-05,
      "loss": 0.8758,
      "step": 43600
    },
    {
      "epoch": 16.51,
      "learning_rate": 1.4681645325220384e-05,
      "loss": 0.8805,
      "step": 43610
    },
    {
      "epoch": 16.51,
      "learning_rate": 1.4650636398949947e-05,
      "loss": 0.883,
      "step": 43620
    },
    {
      "epoch": 16.52,
      "learning_rate": 1.4619657665468078e-05,
      "loss": 0.9005,
      "step": 43630
    },
    {
      "epoch": 16.52,
      "learning_rate": 1.458870913573368e-05,
      "loss": 0.8806,
      "step": 43640
    },
    {
      "epoch": 16.53,
      "learning_rate": 1.4557790820694972e-05,
      "loss": 0.9342,
      "step": 43650
    },
    {
      "epoch": 16.53,
      "learning_rate": 1.452690273128946e-05,
      "loss": 0.9193,
      "step": 43660
    },
    {
      "epoch": 16.53,
      "learning_rate": 1.4496044878444004e-05,
      "loss": 0.945,
      "step": 43670
    },
    {
      "epoch": 16.54,
      "learning_rate": 1.4465217273074672e-05,
      "loss": 0.9052,
      "step": 43680
    },
    {
      "epoch": 16.54,
      "learning_rate": 1.443749829884793e-05,
      "loss": 0.9123,
      "step": 43690
    },
    {
      "epoch": 16.55,
      "learning_rate": 1.4406728193718933e-05,
      "loss": 0.8486,
      "step": 43700
    },
    {
      "epoch": 16.55,
      "learning_rate": 1.4375988367662308e-05,
      "loss": 0.9407,
      "step": 43710
    },
    {
      "epoch": 16.55,
      "learning_rate": 1.4345278831552456e-05,
      "loss": 0.8737,
      "step": 43720
    },
    {
      "epoch": 16.56,
      "learning_rate": 1.4314599596253054e-05,
      "loss": 0.9024,
      "step": 43730
    },
    {
      "epoch": 16.56,
      "learning_rate": 1.4283950672617031e-05,
      "loss": 0.9259,
      "step": 43740
    },
    {
      "epoch": 16.56,
      "learning_rate": 1.4253332071486625e-05,
      "loss": 0.95,
      "step": 43750
    },
    {
      "epoch": 16.57,
      "learning_rate": 1.4222743803693295e-05,
      "loss": 0.894,
      "step": 43760
    },
    {
      "epoch": 16.57,
      "learning_rate": 1.4192185880057818e-05,
      "loss": 0.9383,
      "step": 43770
    },
    {
      "epoch": 16.58,
      "learning_rate": 1.4161658311390225e-05,
      "loss": 0.9146,
      "step": 43780
    },
    {
      "epoch": 16.58,
      "learning_rate": 1.4131161108489799e-05,
      "loss": 0.935,
      "step": 43790
    },
    {
      "epoch": 16.58,
      "learning_rate": 1.41006942821451e-05,
      "loss": 0.8883,
      "step": 43800
    },
    {
      "epoch": 16.59,
      "learning_rate": 1.4070257843133926e-05,
      "loss": 0.872,
      "step": 43810
    },
    {
      "epoch": 16.59,
      "learning_rate": 1.4039851802223302e-05,
      "loss": 0.9212,
      "step": 43820
    },
    {
      "epoch": 16.59,
      "learning_rate": 1.4009476170169556e-05,
      "loss": 0.9052,
      "step": 43830
    },
    {
      "epoch": 16.6,
      "learning_rate": 1.39791309577182e-05,
      "loss": 0.8665,
      "step": 43840
    },
    {
      "epoch": 16.6,
      "learning_rate": 1.394881617560404e-05,
      "loss": 0.9264,
      "step": 43850
    },
    {
      "epoch": 16.61,
      "learning_rate": 1.3918531834551085e-05,
      "loss": 0.9216,
      "step": 43860
    },
    {
      "epoch": 16.61,
      "learning_rate": 1.3888277945272588e-05,
      "loss": 0.9387,
      "step": 43870
    },
    {
      "epoch": 16.61,
      "learning_rate": 1.3858054518470998e-05,
      "loss": 0.8896,
      "step": 43880
    },
    {
      "epoch": 16.62,
      "learning_rate": 1.3827861564838041e-05,
      "loss": 0.8856,
      "step": 43890
    },
    {
      "epoch": 16.62,
      "learning_rate": 1.3797699095054573e-05,
      "loss": 0.8587,
      "step": 43900
    },
    {
      "epoch": 16.62,
      "learning_rate": 1.3767567119790792e-05,
      "loss": 0.9223,
      "step": 43910
    },
    {
      "epoch": 16.63,
      "learning_rate": 1.3737465649706049e-05,
      "loss": 0.8743,
      "step": 43920
    },
    {
      "epoch": 16.63,
      "learning_rate": 1.370739469544885e-05,
      "loss": 0.8495,
      "step": 43930
    },
    {
      "epoch": 16.64,
      "learning_rate": 1.3677354267656983e-05,
      "loss": 0.9157,
      "step": 43940
    },
    {
      "epoch": 16.64,
      "learning_rate": 1.3647344376957416e-05,
      "loss": 0.8835,
      "step": 43950
    },
    {
      "epoch": 16.64,
      "learning_rate": 1.3617365033966245e-05,
      "loss": 0.8864,
      "step": 43960
    },
    {
      "epoch": 16.65,
      "learning_rate": 1.3587416249288898e-05,
      "loss": 0.9133,
      "step": 43970
    },
    {
      "epoch": 16.65,
      "learning_rate": 1.355749803351991e-05,
      "loss": 0.9072,
      "step": 43980
    },
    {
      "epoch": 16.65,
      "learning_rate": 1.3527610397242963e-05,
      "loss": 0.9166,
      "step": 43990
    },
    {
      "epoch": 16.66,
      "learning_rate": 1.3497753351030973e-05,
      "loss": 0.9575,
      "step": 44000
    },
    {
      "epoch": 16.66,
      "learning_rate": 1.3467926905446082e-05,
      "loss": 0.8949,
      "step": 44010
    },
    {
      "epoch": 16.67,
      "learning_rate": 1.3438131071039461e-05,
      "loss": 0.9299,
      "step": 44020
    },
    {
      "epoch": 16.67,
      "learning_rate": 1.3408365858351635e-05,
      "loss": 0.9299,
      "step": 44030
    },
    {
      "epoch": 16.67,
      "learning_rate": 1.3378631277912156e-05,
      "loss": 0.8809,
      "step": 44040
    },
    {
      "epoch": 16.68,
      "learning_rate": 1.3348927340239792e-05,
      "loss": 0.9064,
      "step": 44050
    },
    {
      "epoch": 16.68,
      "learning_rate": 1.3319254055842501e-05,
      "loss": 0.9039,
      "step": 44060
    },
    {
      "epoch": 16.69,
      "learning_rate": 1.328961143521732e-05,
      "loss": 0.8677,
      "step": 44070
    },
    {
      "epoch": 16.69,
      "learning_rate": 1.3259999488850472e-05,
      "loss": 0.9015,
      "step": 44080
    },
    {
      "epoch": 16.69,
      "learning_rate": 1.3230418227217422e-05,
      "loss": 0.8932,
      "step": 44090
    },
    {
      "epoch": 16.7,
      "learning_rate": 1.3200867660782612e-05,
      "loss": 0.9233,
      "step": 44100
    },
    {
      "epoch": 16.7,
      "learning_rate": 1.3171347799999756e-05,
      "loss": 0.9205,
      "step": 44110
    },
    {
      "epoch": 16.7,
      "learning_rate": 1.3141858655311656e-05,
      "loss": 0.9088,
      "step": 44120
    },
    {
      "epoch": 16.71,
      "learning_rate": 1.3112400237150213e-05,
      "loss": 0.9082,
      "step": 44130
    },
    {
      "epoch": 16.71,
      "learning_rate": 1.3082972555936578e-05,
      "loss": 0.8917,
      "step": 44140
    },
    {
      "epoch": 16.72,
      "learning_rate": 1.3053575622080871e-05,
      "loss": 0.901,
      "step": 44150
    },
    {
      "epoch": 16.72,
      "learning_rate": 1.302420944598245e-05,
      "loss": 0.8986,
      "step": 44160
    },
    {
      "epoch": 16.72,
      "learning_rate": 1.2994874038029759e-05,
      "loss": 0.9376,
      "step": 44170
    },
    {
      "epoch": 16.73,
      "learning_rate": 1.296556940860033e-05,
      "loss": 0.9125,
      "step": 44180
    },
    {
      "epoch": 16.73,
      "learning_rate": 1.293629556806082e-05,
      "loss": 0.8663,
      "step": 44190
    },
    {
      "epoch": 16.73,
      "learning_rate": 1.2907052526767072e-05,
      "loss": 0.8612,
      "step": 44200
    },
    {
      "epoch": 16.74,
      "learning_rate": 1.2877840295063903e-05,
      "loss": 0.8984,
      "step": 44210
    },
    {
      "epoch": 16.74,
      "learning_rate": 1.2848658883285313e-05,
      "loss": 0.87,
      "step": 44220
    },
    {
      "epoch": 16.75,
      "learning_rate": 1.2819508301754402e-05,
      "loss": 0.9276,
      "step": 44230
    },
    {
      "epoch": 16.75,
      "learning_rate": 1.2790388560783307e-05,
      "loss": 0.933,
      "step": 44240
    },
    {
      "epoch": 16.75,
      "learning_rate": 1.2761299670673276e-05,
      "loss": 0.8713,
      "step": 44250
    },
    {
      "epoch": 16.76,
      "learning_rate": 1.2732241641714738e-05,
      "loss": 0.9691,
      "step": 44260
    },
    {
      "epoch": 16.76,
      "learning_rate": 1.2703214484187042e-05,
      "loss": 0.8808,
      "step": 44270
    },
    {
      "epoch": 16.76,
      "learning_rate": 1.2674218208358757e-05,
      "loss": 0.9603,
      "step": 44280
    },
    {
      "epoch": 16.77,
      "learning_rate": 1.264525282448743e-05,
      "loss": 0.9206,
      "step": 44290
    },
    {
      "epoch": 16.77,
      "learning_rate": 1.2616318342819722e-05,
      "loss": 0.9123,
      "step": 44300
    },
    {
      "epoch": 16.78,
      "learning_rate": 1.2587414773591366e-05,
      "loss": 0.8889,
      "step": 44310
    },
    {
      "epoch": 16.78,
      "learning_rate": 1.2558542127027151e-05,
      "loss": 0.9138,
      "step": 44320
    },
    {
      "epoch": 16.78,
      "learning_rate": 1.252970041334094e-05,
      "loss": 0.9313,
      "step": 44330
    },
    {
      "epoch": 16.79,
      "learning_rate": 1.2500889642735647e-05,
      "loss": 0.9082,
      "step": 44340
    },
    {
      "epoch": 16.79,
      "learning_rate": 1.24721098254032e-05,
      "loss": 0.8881,
      "step": 44350
    },
    {
      "epoch": 16.8,
      "learning_rate": 1.2443360971524643e-05,
      "loss": 0.94,
      "step": 44360
    },
    {
      "epoch": 16.8,
      "learning_rate": 1.2414643091270006e-05,
      "loss": 0.9181,
      "step": 44370
    },
    {
      "epoch": 16.8,
      "learning_rate": 1.238595619479842e-05,
      "loss": 0.9257,
      "step": 44380
    },
    {
      "epoch": 16.81,
      "learning_rate": 1.2357300292258011e-05,
      "loss": 0.9021,
      "step": 44390
    },
    {
      "epoch": 16.81,
      "learning_rate": 1.2328675393785993e-05,
      "loss": 0.8838,
      "step": 44400
    },
    {
      "epoch": 16.81,
      "learning_rate": 1.230008150950851e-05,
      "loss": 0.9,
      "step": 44410
    },
    {
      "epoch": 16.82,
      "learning_rate": 1.2271518649540836e-05,
      "loss": 0.8438,
      "step": 44420
    },
    {
      "epoch": 16.82,
      "learning_rate": 1.2242986823987223e-05,
      "loss": 0.8865,
      "step": 44430
    },
    {
      "epoch": 16.83,
      "learning_rate": 1.2214486042940975e-05,
      "loss": 0.9192,
      "step": 44440
    },
    {
      "epoch": 16.83,
      "learning_rate": 1.2186016316484395e-05,
      "loss": 0.9095,
      "step": 44450
    },
    {
      "epoch": 16.83,
      "learning_rate": 1.2157577654688757e-05,
      "loss": 0.8661,
      "step": 44460
    },
    {
      "epoch": 16.84,
      "learning_rate": 1.2129170067614426e-05,
      "loss": 0.8932,
      "step": 44470
    },
    {
      "epoch": 16.84,
      "learning_rate": 1.210079356531072e-05,
      "loss": 0.8959,
      "step": 44480
    },
    {
      "epoch": 16.84,
      "learning_rate": 1.2072448157815985e-05,
      "loss": 0.9084,
      "step": 44490
    },
    {
      "epoch": 16.85,
      "learning_rate": 1.2044133855157558e-05,
      "loss": 0.9035,
      "step": 44500
    },
    {
      "epoch": 16.85,
      "learning_rate": 1.2015850667351792e-05,
      "loss": 0.8841,
      "step": 44510
    },
    {
      "epoch": 16.86,
      "learning_rate": 1.1987598604403971e-05,
      "loss": 0.8813,
      "step": 44520
    },
    {
      "epoch": 16.86,
      "learning_rate": 1.1959377676308447e-05,
      "loss": 0.8833,
      "step": 44530
    },
    {
      "epoch": 16.86,
      "learning_rate": 1.1931187893048501e-05,
      "loss": 0.9206,
      "step": 44540
    },
    {
      "epoch": 16.87,
      "learning_rate": 1.1903029264596422e-05,
      "loss": 0.8746,
      "step": 44550
    },
    {
      "epoch": 16.87,
      "learning_rate": 1.1874901800913507e-05,
      "loss": 0.9126,
      "step": 44560
    },
    {
      "epoch": 16.87,
      "learning_rate": 1.1846805511949944e-05,
      "loss": 0.8898,
      "step": 44570
    },
    {
      "epoch": 16.88,
      "learning_rate": 1.1818740407644969e-05,
      "loss": 0.8985,
      "step": 44580
    },
    {
      "epoch": 16.88,
      "learning_rate": 1.1790706497926751e-05,
      "loss": 0.934,
      "step": 44590
    },
    {
      "epoch": 16.89,
      "learning_rate": 1.1762703792712448e-05,
      "loss": 0.8983,
      "step": 44600
    },
    {
      "epoch": 16.89,
      "learning_rate": 1.1734732301908157e-05,
      "loss": 0.8986,
      "step": 44610
    },
    {
      "epoch": 16.89,
      "learning_rate": 1.1706792035408965e-05,
      "loss": 0.8906,
      "step": 44620
    },
    {
      "epoch": 16.9,
      "learning_rate": 1.1678883003098839e-05,
      "loss": 0.9252,
      "step": 44630
    },
    {
      "epoch": 16.9,
      "learning_rate": 1.1651005214850786e-05,
      "loss": 0.9064,
      "step": 44640
    },
    {
      "epoch": 16.9,
      "learning_rate": 1.1623158680526703e-05,
      "loss": 0.9036,
      "step": 44650
    },
    {
      "epoch": 16.91,
      "learning_rate": 1.1595343409977445e-05,
      "loss": 0.8842,
      "step": 44660
    },
    {
      "epoch": 16.91,
      "learning_rate": 1.1567559413042829e-05,
      "loss": 0.9213,
      "step": 44670
    },
    {
      "epoch": 16.92,
      "learning_rate": 1.1539806699551603e-05,
      "loss": 0.9161,
      "step": 44680
    },
    {
      "epoch": 16.92,
      "learning_rate": 1.1512085279321395e-05,
      "loss": 0.8936,
      "step": 44690
    },
    {
      "epoch": 16.92,
      "learning_rate": 1.1484395162158823e-05,
      "loss": 0.9516,
      "step": 44700
    },
    {
      "epoch": 16.93,
      "learning_rate": 1.145673635785941e-05,
      "loss": 0.9212,
      "step": 44710
    },
    {
      "epoch": 16.93,
      "learning_rate": 1.1429108876207617e-05,
      "loss": 0.8686,
      "step": 44720
    },
    {
      "epoch": 16.94,
      "learning_rate": 1.1401512726976815e-05,
      "loss": 0.8822,
      "step": 44730
    },
    {
      "epoch": 16.94,
      "learning_rate": 1.1373947919929262e-05,
      "loss": 0.9199,
      "step": 44740
    },
    {
      "epoch": 16.94,
      "learning_rate": 1.1346414464816169e-05,
      "loss": 0.8684,
      "step": 44750
    },
    {
      "epoch": 16.95,
      "learning_rate": 1.1318912371377632e-05,
      "loss": 0.9268,
      "step": 44760
    },
    {
      "epoch": 16.95,
      "learning_rate": 1.1291441649342671e-05,
      "loss": 0.8707,
      "step": 44770
    },
    {
      "epoch": 16.95,
      "learning_rate": 1.12640023084292e-05,
      "loss": 0.8791,
      "step": 44780
    },
    {
      "epoch": 16.96,
      "learning_rate": 1.1236594358344055e-05,
      "loss": 0.8758,
      "step": 44790
    },
    {
      "epoch": 16.96,
      "learning_rate": 1.120921780878289e-05,
      "loss": 0.8746,
      "step": 44800
    },
    {
      "epoch": 16.97,
      "learning_rate": 1.1181872669430327e-05,
      "loss": 0.9275,
      "step": 44810
    },
    {
      "epoch": 16.97,
      "learning_rate": 1.115455894995986e-05,
      "loss": 0.891,
      "step": 44820
    },
    {
      "epoch": 16.97,
      "learning_rate": 1.112727666003387e-05,
      "loss": 0.8652,
      "step": 44830
    },
    {
      "epoch": 16.98,
      "learning_rate": 1.1100025809303615e-05,
      "loss": 0.9021,
      "step": 44840
    },
    {
      "epoch": 16.98,
      "learning_rate": 1.1072806407409187e-05,
      "loss": 0.8669,
      "step": 44850
    },
    {
      "epoch": 16.98,
      "learning_rate": 1.1045618463979623e-05,
      "loss": 0.8606,
      "step": 44860
    },
    {
      "epoch": 16.99,
      "learning_rate": 1.10184619886328e-05,
      "loss": 0.8953,
      "step": 44870
    },
    {
      "epoch": 16.99,
      "learning_rate": 1.0991336990975464e-05,
      "loss": 0.8645,
      "step": 44880
    },
    {
      "epoch": 17.0,
      "learning_rate": 1.0964243480603232e-05,
      "loss": 0.8899,
      "step": 44890
    },
    {
      "epoch": 17.0,
      "learning_rate": 1.0937181467100577e-05,
      "loss": 0.9328,
      "step": 44900
    },
    {
      "epoch": 17.0,
      "learning_rate": 1.0910150960040811e-05,
      "loss": 0.9163,
      "step": 44910
    },
    {
      "epoch": 17.01,
      "learning_rate": 1.0883151968986127e-05,
      "loss": 0.9057,
      "step": 44920
    },
    {
      "epoch": 17.01,
      "learning_rate": 1.0856184503487565e-05,
      "loss": 0.9102,
      "step": 44930
    },
    {
      "epoch": 17.01,
      "learning_rate": 1.0829248573085005e-05,
      "loss": 0.8984,
      "step": 44940
    },
    {
      "epoch": 17.02,
      "learning_rate": 1.080234418730718e-05,
      "loss": 0.8969,
      "step": 44950
    },
    {
      "epoch": 17.02,
      "learning_rate": 1.0775471355671673e-05,
      "loss": 0.9288,
      "step": 44960
    },
    {
      "epoch": 17.03,
      "learning_rate": 1.0748630087684852e-05,
      "loss": 0.8786,
      "step": 44970
    },
    {
      "epoch": 17.03,
      "learning_rate": 1.0721820392842008e-05,
      "loss": 0.8633,
      "step": 44980
    },
    {
      "epoch": 17.03,
      "learning_rate": 1.0695042280627131e-05,
      "loss": 0.8926,
      "step": 44990
    },
    {
      "epoch": 17.04,
      "learning_rate": 1.0668295760513203e-05,
      "loss": 0.8892,
      "step": 45000
    },
    {
      "epoch": 17.04,
      "learning_rate": 1.0641580841961929e-05,
      "loss": 0.8842,
      "step": 45010
    },
    {
      "epoch": 17.04,
      "learning_rate": 1.0614897534423818e-05,
      "loss": 0.9643,
      "step": 45020
    },
    {
      "epoch": 17.05,
      "learning_rate": 1.0588245847338251e-05,
      "loss": 0.856,
      "step": 45030
    },
    {
      "epoch": 17.05,
      "learning_rate": 1.0561625790133434e-05,
      "loss": 0.91,
      "step": 45040
    },
    {
      "epoch": 17.06,
      "learning_rate": 1.0535037372226275e-05,
      "loss": 0.9077,
      "step": 45050
    },
    {
      "epoch": 17.06,
      "learning_rate": 1.0508480603022642e-05,
      "loss": 0.8784,
      "step": 45060
    },
    {
      "epoch": 17.06,
      "learning_rate": 1.0481955491917117e-05,
      "loss": 0.9325,
      "step": 45070
    },
    {
      "epoch": 17.07,
      "learning_rate": 1.0455462048293075e-05,
      "loss": 0.9113,
      "step": 45080
    },
    {
      "epoch": 17.07,
      "learning_rate": 1.0429000281522728e-05,
      "loss": 0.9084,
      "step": 45090
    },
    {
      "epoch": 17.08,
      "learning_rate": 1.0402570200967077e-05,
      "loss": 0.912,
      "step": 45100
    },
    {
      "epoch": 17.08,
      "learning_rate": 1.0376171815975844e-05,
      "loss": 0.8853,
      "step": 45110
    },
    {
      "epoch": 17.08,
      "learning_rate": 1.034980513588769e-05,
      "loss": 0.9217,
      "step": 45120
    },
    {
      "epoch": 17.09,
      "learning_rate": 1.0323470170029892e-05,
      "loss": 0.9031,
      "step": 45130
    },
    {
      "epoch": 17.09,
      "learning_rate": 1.0297166927718616e-05,
      "loss": 0.9214,
      "step": 45140
    },
    {
      "epoch": 17.09,
      "learning_rate": 1.0270895418258774e-05,
      "loss": 0.8974,
      "step": 45150
    },
    {
      "epoch": 17.1,
      "learning_rate": 1.0247278199014332e-05,
      "loss": 0.9134,
      "step": 45160
    },
    {
      "epoch": 17.1,
      "learning_rate": 1.022106700756702e-05,
      "loss": 0.8922,
      "step": 45170
    },
    {
      "epoch": 17.11,
      "learning_rate": 1.0194887575891898e-05,
      "loss": 0.8941,
      "step": 45180
    },
    {
      "epoch": 17.11,
      "learning_rate": 1.0168739913250025e-05,
      "loss": 0.8919,
      "step": 45190
    },
    {
      "epoch": 17.11,
      "learning_rate": 1.0142624028891334e-05,
      "loss": 0.8525,
      "step": 45200
    },
    {
      "epoch": 17.12,
      "learning_rate": 1.011653993205446e-05,
      "loss": 0.9147,
      "step": 45210
    },
    {
      "epoch": 17.12,
      "learning_rate": 1.0090487631966739e-05,
      "loss": 0.8478,
      "step": 45220
    },
    {
      "epoch": 17.12,
      "learning_rate": 1.006446713784437e-05,
      "loss": 0.8592,
      "step": 45230
    },
    {
      "epoch": 17.13,
      "learning_rate": 1.0038478458892175e-05,
      "loss": 0.9565,
      "step": 45240
    },
    {
      "epoch": 17.13,
      "learning_rate": 1.0012521604303815e-05,
      "loss": 0.9112,
      "step": 45250
    },
    {
      "epoch": 17.14,
      "learning_rate": 9.98659658326171e-06,
      "loss": 0.8843,
      "step": 45260
    },
    {
      "epoch": 17.14,
      "learning_rate": 9.9607034049369e-06,
      "loss": 0.8835,
      "step": 45270
    },
    {
      "epoch": 17.14,
      "learning_rate": 9.934842078489281e-06,
      "loss": 0.868,
      "step": 45280
    },
    {
      "epoch": 17.15,
      "learning_rate": 9.909012613067437e-06,
      "loss": 0.8357,
      "step": 45290
    },
    {
      "epoch": 17.15,
      "learning_rate": 9.883215017808634e-06,
      "loss": 0.9003,
      "step": 45300
    },
    {
      "epoch": 17.15,
      "learning_rate": 9.857449301838917e-06,
      "loss": 0.9578,
      "step": 45310
    },
    {
      "epoch": 17.16,
      "learning_rate": 9.831715474273107e-06,
      "loss": 0.8891,
      "step": 45320
    },
    {
      "epoch": 17.16,
      "learning_rate": 9.806013544214609e-06,
      "loss": 0.9238,
      "step": 45330
    },
    {
      "epoch": 17.17,
      "learning_rate": 9.780343520755674e-06,
      "loss": 0.9272,
      "step": 45340
    },
    {
      "epoch": 17.17,
      "learning_rate": 9.75470541297715e-06,
      "loss": 0.8605,
      "step": 45350
    },
    {
      "epoch": 17.17,
      "learning_rate": 9.729099229948668e-06,
      "loss": 0.8451,
      "step": 45360
    },
    {
      "epoch": 17.18,
      "learning_rate": 9.703524980728606e-06,
      "loss": 0.869,
      "step": 45370
    },
    {
      "epoch": 17.18,
      "learning_rate": 9.677982674363918e-06,
      "loss": 0.8888,
      "step": 45380
    },
    {
      "epoch": 17.19,
      "learning_rate": 9.652472319890371e-06,
      "loss": 0.9051,
      "step": 45390
    },
    {
      "epoch": 17.19,
      "learning_rate": 9.626993926332396e-06,
      "loss": 0.8982,
      "step": 45400
    },
    {
      "epoch": 17.19,
      "learning_rate": 9.601547502703068e-06,
      "loss": 0.9057,
      "step": 45410
    },
    {
      "epoch": 17.2,
      "learning_rate": 9.57613305800419e-06,
      "loss": 0.8986,
      "step": 45420
    },
    {
      "epoch": 17.2,
      "learning_rate": 9.550750601226332e-06,
      "loss": 0.9033,
      "step": 45430
    },
    {
      "epoch": 17.2,
      "learning_rate": 9.525400141348595e-06,
      "loss": 0.9331,
      "step": 45440
    },
    {
      "epoch": 17.21,
      "learning_rate": 9.500081687338868e-06,
      "loss": 0.8945,
      "step": 45450
    },
    {
      "epoch": 17.21,
      "learning_rate": 9.474795248153712e-06,
      "loss": 0.8615,
      "step": 45460
    },
    {
      "epoch": 17.22,
      "learning_rate": 9.44954083273828e-06,
      "loss": 0.8981,
      "step": 45470
    },
    {
      "epoch": 17.22,
      "learning_rate": 9.424318450026504e-06,
      "loss": 0.9049,
      "step": 45480
    },
    {
      "epoch": 17.22,
      "learning_rate": 9.399128108940901e-06,
      "loss": 0.9098,
      "step": 45490
    },
    {
      "epoch": 17.23,
      "learning_rate": 9.373969818392714e-06,
      "loss": 0.9059,
      "step": 45500
    },
    {
      "epoch": 17.23,
      "learning_rate": 9.34884358728183e-06,
      "loss": 0.8715,
      "step": 45510
    },
    {
      "epoch": 17.23,
      "learning_rate": 9.323749424496753e-06,
      "loss": 0.9326,
      "step": 45520
    },
    {
      "epoch": 17.24,
      "learning_rate": 9.298687338914691e-06,
      "loss": 0.9048,
      "step": 45530
    },
    {
      "epoch": 17.24,
      "learning_rate": 9.273657339401487e-06,
      "loss": 0.9208,
      "step": 45540
    },
    {
      "epoch": 17.25,
      "learning_rate": 9.248659434811636e-06,
      "loss": 0.8895,
      "step": 45550
    },
    {
      "epoch": 17.25,
      "learning_rate": 9.223693633988285e-06,
      "loss": 0.8627,
      "step": 45560
    },
    {
      "epoch": 17.25,
      "learning_rate": 9.198759945763225e-06,
      "loss": 0.9322,
      "step": 45570
    },
    {
      "epoch": 17.26,
      "learning_rate": 9.173858378956856e-06,
      "loss": 0.8839,
      "step": 45580
    },
    {
      "epoch": 17.26,
      "learning_rate": 9.148988942378256e-06,
      "loss": 0.8998,
      "step": 45590
    },
    {
      "epoch": 17.26,
      "learning_rate": 9.124151644825108e-06,
      "loss": 0.9291,
      "step": 45600
    },
    {
      "epoch": 17.27,
      "learning_rate": 9.09934649508375e-06,
      "loss": 0.907,
      "step": 45610
    },
    {
      "epoch": 17.27,
      "learning_rate": 9.074573501929152e-06,
      "loss": 0.9209,
      "step": 45620
    },
    {
      "epoch": 17.28,
      "learning_rate": 9.049832674124836e-06,
      "loss": 0.9024,
      "step": 45630
    },
    {
      "epoch": 17.28,
      "learning_rate": 9.025124020423049e-06,
      "loss": 0.9102,
      "step": 45640
    },
    {
      "epoch": 17.28,
      "learning_rate": 9.000447549564583e-06,
      "loss": 0.8519,
      "step": 45650
    },
    {
      "epoch": 17.29,
      "learning_rate": 8.975803270278882e-06,
      "loss": 0.8906,
      "step": 45660
    },
    {
      "epoch": 17.29,
      "learning_rate": 8.951191191283992e-06,
      "loss": 0.9219,
      "step": 45670
    },
    {
      "epoch": 17.29,
      "learning_rate": 8.926611321286572e-06,
      "loss": 0.9264,
      "step": 45680
    },
    {
      "epoch": 17.3,
      "learning_rate": 8.902063668981852e-06,
      "loss": 0.8509,
      "step": 45690
    },
    {
      "epoch": 17.3,
      "learning_rate": 8.877548243053723e-06,
      "loss": 0.8961,
      "step": 45700
    },
    {
      "epoch": 17.31,
      "learning_rate": 8.853065052174625e-06,
      "loss": 0.9498,
      "step": 45710
    },
    {
      "epoch": 17.31,
      "learning_rate": 8.828614105005628e-06,
      "loss": 0.8834,
      "step": 45720
    },
    {
      "epoch": 17.31,
      "learning_rate": 8.804195410196392e-06,
      "loss": 0.8504,
      "step": 45730
    },
    {
      "epoch": 17.32,
      "learning_rate": 8.779808976385162e-06,
      "loss": 0.8929,
      "step": 45740
    },
    {
      "epoch": 17.32,
      "learning_rate": 8.755454812198738e-06,
      "loss": 0.9312,
      "step": 45750
    },
    {
      "epoch": 17.33,
      "learning_rate": 8.73113292625255e-06,
      "loss": 0.9338,
      "step": 45760
    },
    {
      "epoch": 17.33,
      "learning_rate": 8.706843327150605e-06,
      "loss": 0.9178,
      "step": 45770
    },
    {
      "epoch": 17.33,
      "learning_rate": 8.682586023485461e-06,
      "loss": 0.9166,
      "step": 45780
    },
    {
      "epoch": 17.34,
      "learning_rate": 8.65836102383829e-06,
      "loss": 0.8698,
      "step": 45790
    },
    {
      "epoch": 17.34,
      "learning_rate": 8.634168336778792e-06,
      "loss": 0.9325,
      "step": 45800
    },
    {
      "epoch": 17.34,
      "learning_rate": 8.610007970865252e-06,
      "loss": 0.9331,
      "step": 45810
    },
    {
      "epoch": 17.35,
      "learning_rate": 8.585879934644548e-06,
      "loss": 0.925,
      "step": 45820
    },
    {
      "epoch": 17.35,
      "learning_rate": 8.561784236652092e-06,
      "loss": 0.8979,
      "step": 45830
    },
    {
      "epoch": 17.36,
      "learning_rate": 8.53772088541186e-06,
      "loss": 0.9279,
      "step": 45840
    },
    {
      "epoch": 17.36,
      "learning_rate": 8.513689889436415e-06,
      "loss": 0.9106,
      "step": 45850
    },
    {
      "epoch": 17.36,
      "learning_rate": 8.489691257226806e-06,
      "loss": 0.8916,
      "step": 45860
    },
    {
      "epoch": 17.37,
      "learning_rate": 8.465724997272706e-06,
      "loss": 0.8539,
      "step": 45870
    },
    {
      "epoch": 17.37,
      "learning_rate": 8.44179111805229e-06,
      "loss": 0.8576,
      "step": 45880
    },
    {
      "epoch": 17.37,
      "learning_rate": 8.417889628032305e-06,
      "loss": 0.9132,
      "step": 45890
    },
    {
      "epoch": 17.38,
      "learning_rate": 8.394020535668057e-06,
      "loss": 0.8647,
      "step": 45900
    },
    {
      "epoch": 17.38,
      "learning_rate": 8.370183849403301e-06,
      "loss": 0.9286,
      "step": 45910
    },
    {
      "epoch": 17.39,
      "learning_rate": 8.346379577670427e-06,
      "loss": 0.8332,
      "step": 45920
    },
    {
      "epoch": 17.39,
      "learning_rate": 8.32260772889032e-06,
      "loss": 0.8831,
      "step": 45930
    },
    {
      "epoch": 17.39,
      "learning_rate": 8.298868311472396e-06,
      "loss": 0.8603,
      "step": 45940
    },
    {
      "epoch": 17.4,
      "learning_rate": 8.275161333814597e-06,
      "loss": 0.9091,
      "step": 45950
    },
    {
      "epoch": 17.4,
      "learning_rate": 8.25148680430341e-06,
      "loss": 0.9059,
      "step": 45960
    },
    {
      "epoch": 17.4,
      "learning_rate": 8.227844731313794e-06,
      "loss": 0.9066,
      "step": 45970
    },
    {
      "epoch": 17.41,
      "learning_rate": 8.20423512320927e-06,
      "loss": 0.9273,
      "step": 45980
    },
    {
      "epoch": 17.41,
      "learning_rate": 8.180657988341867e-06,
      "loss": 0.8507,
      "step": 45990
    },
    {
      "epoch": 17.42,
      "learning_rate": 8.157113335052113e-06,
      "loss": 0.8509,
      "step": 46000
    },
    {
      "epoch": 17.42,
      "learning_rate": 8.133601171669059e-06,
      "loss": 0.9233,
      "step": 46010
    },
    {
      "epoch": 17.42,
      "learning_rate": 8.11012150651027e-06,
      "loss": 0.93,
      "step": 46020
    },
    {
      "epoch": 17.43,
      "learning_rate": 8.086674347881784e-06,
      "loss": 0.8863,
      "step": 46030
    },
    {
      "epoch": 17.43,
      "learning_rate": 8.063259704078162e-06,
      "loss": 0.8636,
      "step": 46040
    },
    {
      "epoch": 17.43,
      "learning_rate": 8.039877583382437e-06,
      "loss": 0.9112,
      "step": 46050
    },
    {
      "epoch": 17.44,
      "learning_rate": 8.016527994066192e-06,
      "loss": 0.8895,
      "step": 46060
    },
    {
      "epoch": 17.44,
      "learning_rate": 7.993210944389461e-06,
      "loss": 0.9318,
      "step": 46070
    },
    {
      "epoch": 17.45,
      "learning_rate": 7.969926442600762e-06,
      "loss": 0.8996,
      "step": 46080
    },
    {
      "epoch": 17.45,
      "learning_rate": 7.946674496937112e-06,
      "loss": 0.9364,
      "step": 46090
    },
    {
      "epoch": 17.45,
      "learning_rate": 7.923455115624012e-06,
      "loss": 0.9079,
      "step": 46100
    },
    {
      "epoch": 17.46,
      "learning_rate": 7.900268306875436e-06,
      "loss": 0.8805,
      "step": 46110
    },
    {
      "epoch": 17.46,
      "learning_rate": 7.877114078893854e-06,
      "loss": 0.8914,
      "step": 46120
    },
    {
      "epoch": 17.47,
      "learning_rate": 7.853992439870206e-06,
      "loss": 0.9173,
      "step": 46130
    },
    {
      "epoch": 17.47,
      "learning_rate": 7.830903397983858e-06,
      "loss": 0.9006,
      "step": 46140
    },
    {
      "epoch": 17.47,
      "learning_rate": 7.807846961402698e-06,
      "loss": 0.9081,
      "step": 46150
    },
    {
      "epoch": 17.48,
      "learning_rate": 7.78482313828306e-06,
      "loss": 0.9341,
      "step": 46160
    },
    {
      "epoch": 17.48,
      "learning_rate": 7.761831936769748e-06,
      "loss": 0.8349,
      "step": 46170
    },
    {
      "epoch": 17.48,
      "learning_rate": 7.738873364996035e-06,
      "loss": 0.8718,
      "step": 46180
    },
    {
      "epoch": 17.49,
      "learning_rate": 7.715947431083614e-06,
      "loss": 0.9078,
      "step": 46190
    },
    {
      "epoch": 17.49,
      "learning_rate": 7.693054143142652e-06,
      "loss": 0.9242,
      "step": 46200
    },
    {
      "epoch": 17.5,
      "learning_rate": 7.670193509271806e-06,
      "loss": 0.8999,
      "step": 46210
    },
    {
      "epoch": 17.5,
      "learning_rate": 7.647365537558083e-06,
      "loss": 0.913,
      "step": 46220
    },
    {
      "epoch": 17.5,
      "learning_rate": 7.624570236077055e-06,
      "loss": 0.948,
      "step": 46230
    },
    {
      "epoch": 17.51,
      "learning_rate": 7.601807612892686e-06,
      "loss": 0.877,
      "step": 46240
    },
    {
      "epoch": 17.51,
      "learning_rate": 7.579077676057333e-06,
      "loss": 0.9042,
      "step": 46250
    },
    {
      "epoch": 17.51,
      "learning_rate": 7.556380433611843e-06,
      "loss": 0.8844,
      "step": 46260
    },
    {
      "epoch": 17.52,
      "learning_rate": 7.5337158935855136e-06,
      "loss": 0.8675,
      "step": 46270
    },
    {
      "epoch": 17.52,
      "learning_rate": 7.511084063995988e-06,
      "loss": 0.8923,
      "step": 46280
    },
    {
      "epoch": 17.53,
      "learning_rate": 7.488484952849461e-06,
      "loss": 0.9092,
      "step": 46290
    },
    {
      "epoch": 17.53,
      "learning_rate": 7.465918568140451e-06,
      "loss": 0.8901,
      "step": 46300
    },
    {
      "epoch": 17.53,
      "learning_rate": 7.443384917851936e-06,
      "loss": 0.8892,
      "step": 46310
    },
    {
      "epoch": 17.54,
      "learning_rate": 7.4208840099553425e-06,
      "loss": 0.8834,
      "step": 46320
    },
    {
      "epoch": 17.54,
      "learning_rate": 7.3984158524104456e-06,
      "loss": 0.9078,
      "step": 46330
    },
    {
      "epoch": 17.54,
      "learning_rate": 7.375980453165488e-06,
      "loss": 0.8167,
      "step": 46340
    },
    {
      "epoch": 17.55,
      "learning_rate": 7.353577820157131e-06,
      "loss": 0.8671,
      "step": 46350
    },
    {
      "epoch": 17.55,
      "learning_rate": 7.331207961310404e-06,
      "loss": 0.9213,
      "step": 46360
    },
    {
      "epoch": 17.56,
      "learning_rate": 7.308870884538766e-06,
      "loss": 0.9092,
      "step": 46370
    },
    {
      "epoch": 17.56,
      "learning_rate": 7.2865665977440936e-06,
      "loss": 0.8952,
      "step": 46380
    },
    {
      "epoch": 17.56,
      "learning_rate": 7.264295108816621e-06,
      "loss": 0.9339,
      "step": 46390
    },
    {
      "epoch": 17.57,
      "learning_rate": 7.242056425634991e-06,
      "loss": 0.8723,
      "step": 46400
    },
    {
      "epoch": 17.57,
      "learning_rate": 7.21985055606631e-06,
      "loss": 0.9136,
      "step": 46410
    },
    {
      "epoch": 17.58,
      "learning_rate": 7.197677507965983e-06,
      "loss": 0.9168,
      "step": 46420
    },
    {
      "epoch": 17.58,
      "learning_rate": 7.1755372891778695e-06,
      "loss": 0.9066,
      "step": 46430
    },
    {
      "epoch": 17.58,
      "learning_rate": 7.1534299075341485e-06,
      "loss": 0.9252,
      "step": 46440
    },
    {
      "epoch": 17.59,
      "learning_rate": 7.131355370855441e-06,
      "loss": 0.9045,
      "step": 46450
    },
    {
      "epoch": 17.59,
      "learning_rate": 7.109313686950747e-06,
      "loss": 0.8708,
      "step": 46460
    },
    {
      "epoch": 17.59,
      "learning_rate": 7.087304863617405e-06,
      "loss": 0.8958,
      "step": 46470
    },
    {
      "epoch": 17.6,
      "learning_rate": 7.065328908641178e-06,
      "loss": 0.8839,
      "step": 46480
    },
    {
      "epoch": 17.6,
      "learning_rate": 7.043385829796167e-06,
      "loss": 0.8966,
      "step": 46490
    },
    {
      "epoch": 17.61,
      "learning_rate": 7.021475634844843e-06,
      "loss": 0.9336,
      "step": 46500
    },
    {
      "epoch": 17.61,
      "learning_rate": 6.999598331538038e-06,
      "loss": 0.9016,
      "step": 46510
    },
    {
      "epoch": 17.61,
      "learning_rate": 6.977753927615016e-06,
      "loss": 0.8737,
      "step": 46520
    },
    {
      "epoch": 17.62,
      "learning_rate": 6.955942430803297e-06,
      "loss": 0.8817,
      "step": 46530
    },
    {
      "epoch": 17.62,
      "learning_rate": 6.934163848818842e-06,
      "loss": 0.8749,
      "step": 46540
    },
    {
      "epoch": 17.62,
      "learning_rate": 6.9124181893659435e-06,
      "loss": 0.9059,
      "step": 46550
    },
    {
      "epoch": 17.63,
      "learning_rate": 6.890705460137214e-06,
      "loss": 0.9525,
      "step": 46560
    },
    {
      "epoch": 17.63,
      "learning_rate": 6.869025668813678e-06,
      "loss": 0.9164,
      "step": 46570
    },
    {
      "epoch": 17.64,
      "learning_rate": 6.847378823064654e-06,
      "loss": 0.8694,
      "step": 46580
    },
    {
      "epoch": 17.64,
      "learning_rate": 6.82576493054784e-06,
      "loss": 0.8768,
      "step": 46590
    },
    {
      "epoch": 17.64,
      "learning_rate": 6.804183998909275e-06,
      "loss": 0.9211,
      "step": 46600
    },
    {
      "epoch": 17.65,
      "learning_rate": 6.782636035783297e-06,
      "loss": 0.9472,
      "step": 46610
    },
    {
      "epoch": 17.65,
      "learning_rate": 6.761121048792629e-06,
      "loss": 0.897,
      "step": 46620
    },
    {
      "epoch": 17.65,
      "learning_rate": 6.739639045548307e-06,
      "loss": 0.8956,
      "step": 46630
    },
    {
      "epoch": 17.66,
      "learning_rate": 6.718190033649718e-06,
      "loss": 0.89,
      "step": 46640
    },
    {
      "epoch": 17.66,
      "learning_rate": 6.6967740206845485e-06,
      "loss": 0.9067,
      "step": 46650
    },
    {
      "epoch": 17.67,
      "learning_rate": 6.675391014228849e-06,
      "loss": 0.9293,
      "step": 46660
    },
    {
      "epoch": 17.67,
      "learning_rate": 6.654041021846935e-06,
      "loss": 0.8975,
      "step": 46670
    },
    {
      "epoch": 17.67,
      "learning_rate": 6.632724051091499e-06,
      "loss": 0.9208,
      "step": 46680
    },
    {
      "epoch": 17.68,
      "learning_rate": 6.61144010950353e-06,
      "loss": 0.9071,
      "step": 46690
    },
    {
      "epoch": 17.68,
      "learning_rate": 6.590189204612341e-06,
      "loss": 0.9133,
      "step": 46700
    },
    {
      "epoch": 17.68,
      "learning_rate": 6.568971343935559e-06,
      "loss": 0.8739,
      "step": 46710
    },
    {
      "epoch": 17.69,
      "learning_rate": 6.5477865349790836e-06,
      "loss": 0.9879,
      "step": 46720
    },
    {
      "epoch": 17.69,
      "learning_rate": 6.526634785237173e-06,
      "loss": 0.8584,
      "step": 46730
    },
    {
      "epoch": 17.7,
      "learning_rate": 6.505516102192366e-06,
      "loss": 0.8782,
      "step": 46740
    },
    {
      "epoch": 17.7,
      "learning_rate": 6.484430493315508e-06,
      "loss": 0.9559,
      "step": 46750
    },
    {
      "epoch": 17.7,
      "learning_rate": 6.463377966065753e-06,
      "loss": 0.8936,
      "step": 46760
    },
    {
      "epoch": 17.71,
      "learning_rate": 6.442358527890546e-06,
      "loss": 0.8818,
      "step": 46770
    },
    {
      "epoch": 17.71,
      "learning_rate": 6.421372186225605e-06,
      "loss": 0.8859,
      "step": 46780
    },
    {
      "epoch": 17.72,
      "learning_rate": 6.400418948494979e-06,
      "loss": 0.9444,
      "step": 46790
    },
    {
      "epoch": 17.72,
      "learning_rate": 6.379498822110974e-06,
      "loss": 0.8772,
      "step": 46800
    },
    {
      "epoch": 17.72,
      "learning_rate": 6.358611814474191e-06,
      "loss": 0.898,
      "step": 46810
    },
    {
      "epoch": 17.73,
      "learning_rate": 6.337757932973542e-06,
      "loss": 0.8942,
      "step": 46820
    },
    {
      "epoch": 17.73,
      "learning_rate": 6.3169371849861935e-06,
      "loss": 0.9228,
      "step": 46830
    },
    {
      "epoch": 17.73,
      "learning_rate": 6.296149577877564e-06,
      "loss": 0.9058,
      "step": 46840
    },
    {
      "epoch": 17.74,
      "learning_rate": 6.275395119001415e-06,
      "loss": 0.8303,
      "step": 46850
    },
    {
      "epoch": 17.74,
      "learning_rate": 6.254673815699719e-06,
      "loss": 0.8822,
      "step": 46860
    },
    {
      "epoch": 17.75,
      "learning_rate": 6.233985675302767e-06,
      "loss": 0.9226,
      "step": 46870
    },
    {
      "epoch": 17.75,
      "learning_rate": 6.213330705129106e-06,
      "loss": 0.8727,
      "step": 46880
    },
    {
      "epoch": 17.75,
      "learning_rate": 6.192708912485501e-06,
      "loss": 0.8831,
      "step": 46890
    },
    {
      "epoch": 17.76,
      "learning_rate": 6.172120304667062e-06,
      "loss": 0.8824,
      "step": 46900
    },
    {
      "epoch": 17.76,
      "learning_rate": 6.151564888957084e-06,
      "loss": 0.8971,
      "step": 46910
    },
    {
      "epoch": 17.76,
      "learning_rate": 6.131042672627186e-06,
      "loss": 0.9741,
      "step": 46920
    },
    {
      "epoch": 17.77,
      "learning_rate": 6.1105536629371795e-06,
      "loss": 0.8919,
      "step": 46930
    },
    {
      "epoch": 17.77,
      "learning_rate": 6.090097867135203e-06,
      "loss": 0.9295,
      "step": 46940
    },
    {
      "epoch": 17.78,
      "learning_rate": 6.069675292457555e-06,
      "loss": 0.9071,
      "step": 46950
    },
    {
      "epoch": 17.78,
      "learning_rate": 6.049285946128847e-06,
      "loss": 0.9176,
      "step": 46960
    },
    {
      "epoch": 17.78,
      "learning_rate": 6.0289298353619295e-06,
      "loss": 0.9774,
      "step": 46970
    },
    {
      "epoch": 17.79,
      "learning_rate": 6.008606967357866e-06,
      "loss": 0.913,
      "step": 46980
    },
    {
      "epoch": 17.79,
      "learning_rate": 5.988317349306005e-06,
      "loss": 0.9127,
      "step": 46990
    },
    {
      "epoch": 17.79,
      "learning_rate": 5.968060988383883e-06,
      "loss": 0.8902,
      "step": 47000
    },
    {
      "epoch": 17.8,
      "learning_rate": 5.947837891757291e-06,
      "loss": 0.862,
      "step": 47010
    },
    {
      "epoch": 17.8,
      "learning_rate": 5.927648066580271e-06,
      "loss": 0.8929,
      "step": 47020
    },
    {
      "epoch": 17.81,
      "learning_rate": 5.907491519995067e-06,
      "loss": 0.8711,
      "step": 47030
    },
    {
      "epoch": 17.81,
      "learning_rate": 5.887368259132175e-06,
      "loss": 0.9067,
      "step": 47040
    },
    {
      "epoch": 17.81,
      "learning_rate": 5.867278291110323e-06,
      "loss": 0.9247,
      "step": 47050
    },
    {
      "epoch": 17.82,
      "learning_rate": 5.847221623036403e-06,
      "loss": 0.9066,
      "step": 47060
    },
    {
      "epoch": 17.82,
      "learning_rate": 5.827198262005595e-06,
      "loss": 0.8699,
      "step": 47070
    },
    {
      "epoch": 17.82,
      "learning_rate": 5.807208215101257e-06,
      "loss": 0.8653,
      "step": 47080
    },
    {
      "epoch": 17.83,
      "learning_rate": 5.787251489394973e-06,
      "loss": 0.9058,
      "step": 47090
    },
    {
      "epoch": 17.83,
      "learning_rate": 5.767328091946544e-06,
      "loss": 0.8976,
      "step": 47100
    },
    {
      "epoch": 17.84,
      "learning_rate": 5.747438029803998e-06,
      "loss": 0.8853,
      "step": 47110
    },
    {
      "epoch": 17.84,
      "learning_rate": 5.727581310003516e-06,
      "loss": 0.8817,
      "step": 47120
    },
    {
      "epoch": 17.84,
      "learning_rate": 5.7077579395695464e-06,
      "loss": 0.8811,
      "step": 47130
    },
    {
      "epoch": 17.85,
      "learning_rate": 5.687967925514659e-06,
      "loss": 0.8153,
      "step": 47140
    },
    {
      "epoch": 17.85,
      "learning_rate": 5.66821127483973e-06,
      "loss": 0.9306,
      "step": 47150
    },
    {
      "epoch": 17.86,
      "learning_rate": 5.6484879945337795e-06,
      "loss": 0.8892,
      "step": 47160
    },
    {
      "epoch": 17.86,
      "learning_rate": 5.628798091573995e-06,
      "loss": 0.9015,
      "step": 47170
    },
    {
      "epoch": 17.86,
      "learning_rate": 5.60914157292578e-06,
      "loss": 0.8966,
      "step": 47180
    },
    {
      "epoch": 17.87,
      "learning_rate": 5.589518445542774e-06,
      "loss": 0.9036,
      "step": 47190
    },
    {
      "epoch": 17.87,
      "learning_rate": 5.569928716366701e-06,
      "loss": 0.8793,
      "step": 47200
    },
    {
      "epoch": 17.87,
      "learning_rate": 5.550372392327574e-06,
      "loss": 0.879,
      "step": 47210
    },
    {
      "epoch": 17.88,
      "learning_rate": 5.530849480343548e-06,
      "loss": 0.8648,
      "step": 47220
    },
    {
      "epoch": 17.88,
      "learning_rate": 5.51135998732093e-06,
      "loss": 0.9114,
      "step": 47230
    },
    {
      "epoch": 17.89,
      "learning_rate": 5.491903920154251e-06,
      "loss": 0.8699,
      "step": 47240
    },
    {
      "epoch": 17.89,
      "learning_rate": 5.472481285726194e-06,
      "loss": 0.8447,
      "step": 47250
    },
    {
      "epoch": 17.89,
      "learning_rate": 5.453092090907608e-06,
      "loss": 0.894,
      "step": 47260
    },
    {
      "epoch": 17.9,
      "learning_rate": 5.433736342557549e-06,
      "loss": 0.9071,
      "step": 47270
    },
    {
      "epoch": 17.9,
      "learning_rate": 5.414414047523186e-06,
      "loss": 0.9543,
      "step": 47280
    },
    {
      "epoch": 17.9,
      "learning_rate": 5.395125212639895e-06,
      "loss": 0.9183,
      "step": 47290
    },
    {
      "epoch": 17.91,
      "learning_rate": 5.375869844731218e-06,
      "loss": 0.8915,
      "step": 47300
    },
    {
      "epoch": 17.91,
      "learning_rate": 5.356647950608795e-06,
      "loss": 0.9314,
      "step": 47310
    },
    {
      "epoch": 17.92,
      "learning_rate": 5.337459537072531e-06,
      "loss": 0.8755,
      "step": 47320
    },
    {
      "epoch": 17.92,
      "learning_rate": 5.318304610910407e-06,
      "loss": 0.879,
      "step": 47330
    },
    {
      "epoch": 17.92,
      "learning_rate": 5.2991831788985704e-06,
      "loss": 0.9114,
      "step": 47340
    },
    {
      "epoch": 17.93,
      "learning_rate": 5.280095247801331e-06,
      "loss": 0.8897,
      "step": 47350
    },
    {
      "epoch": 17.93,
      "learning_rate": 5.261040824371155e-06,
      "loss": 0.8881,
      "step": 47360
    },
    {
      "epoch": 17.93,
      "learning_rate": 5.242019915348617e-06,
      "loss": 0.8774,
      "step": 47370
    },
    {
      "epoch": 17.94,
      "learning_rate": 5.223032527462524e-06,
      "loss": 0.9152,
      "step": 47380
    },
    {
      "epoch": 17.94,
      "learning_rate": 5.204078667429701e-06,
      "loss": 0.9092,
      "step": 47390
    },
    {
      "epoch": 17.95,
      "learning_rate": 5.1851583419552095e-06,
      "loss": 0.8716,
      "step": 47400
    },
    {
      "epoch": 17.95,
      "learning_rate": 5.166271557732216e-06,
      "loss": 0.8723,
      "step": 47410
    },
    {
      "epoch": 17.95,
      "learning_rate": 5.1474183214420105e-06,
      "loss": 0.8824,
      "step": 47420
    },
    {
      "epoch": 17.96,
      "learning_rate": 5.128598639754001e-06,
      "loss": 0.8576,
      "step": 47430
    },
    {
      "epoch": 17.96,
      "learning_rate": 5.109812519325807e-06,
      "loss": 0.873,
      "step": 47440
    },
    {
      "epoch": 17.96,
      "learning_rate": 5.091059966803069e-06,
      "loss": 0.9463,
      "step": 47450
    },
    {
      "epoch": 17.97,
      "learning_rate": 5.0723409888196235e-06,
      "loss": 0.8924,
      "step": 47460
    },
    {
      "epoch": 17.97,
      "learning_rate": 5.053655591997408e-06,
      "loss": 0.8723,
      "step": 47470
    },
    {
      "epoch": 17.98,
      "learning_rate": 5.035003782946468e-06,
      "loss": 0.8561,
      "step": 47480
    },
    {
      "epoch": 17.98,
      "learning_rate": 5.01638556826497e-06,
      "loss": 0.9264,
      "step": 47490
    },
    {
      "epoch": 17.98,
      "learning_rate": 4.997800954539256e-06,
      "loss": 0.8668,
      "step": 47500
    },
    {
      "epoch": 17.99,
      "learning_rate": 4.9792499483436786e-06,
      "loss": 0.8851,
      "step": 47510
    },
    {
      "epoch": 17.99,
      "learning_rate": 4.960732556240799e-06,
      "loss": 0.9094,
      "step": 47520
    },
    {
      "epoch": 18.0,
      "learning_rate": 4.9422487847811895e-06,
      "loss": 0.9161,
      "step": 47530
    },
    {
      "epoch": 18.0,
      "learning_rate": 4.923798640503618e-06,
      "loss": 0.8693,
      "step": 47540
    },
    {
      "epoch": 18.0,
      "learning_rate": 4.9053821299349104e-06,
      "loss": 0.8423,
      "step": 47550
    },
    {
      "epoch": 18.01,
      "learning_rate": 4.886999259589997e-06,
      "loss": 0.8751,
      "step": 47560
    },
    {
      "epoch": 18.01,
      "learning_rate": 4.868650035971934e-06,
      "loss": 0.9246,
      "step": 47570
    },
    {
      "epoch": 18.01,
      "learning_rate": 4.850334465571871e-06,
      "loss": 0.9202,
      "step": 47580
    },
    {
      "epoch": 18.02,
      "learning_rate": 4.8320525548689825e-06,
      "loss": 0.8921,
      "step": 47590
    },
    {
      "epoch": 18.02,
      "learning_rate": 4.813804310330639e-06,
      "loss": 0.9056,
      "step": 47600
    },
    {
      "epoch": 18.03,
      "learning_rate": 4.7955897384122206e-06,
      "loss": 0.8923,
      "step": 47610
    },
    {
      "epoch": 18.03,
      "learning_rate": 4.777408845557252e-06,
      "loss": 0.8862,
      "step": 47620
    },
    {
      "epoch": 18.03,
      "learning_rate": 4.759261638197321e-06,
      "loss": 0.8786,
      "step": 47630
    },
    {
      "epoch": 18.04,
      "learning_rate": 4.7411481227520925e-06,
      "loss": 0.8691,
      "step": 47640
    },
    {
      "epoch": 18.04,
      "learning_rate": 4.723068305629308e-06,
      "loss": 0.8811,
      "step": 47650
    },
    {
      "epoch": 18.04,
      "learning_rate": 4.705022193224806e-06,
      "loss": 0.917,
      "step": 47660
    },
    {
      "epoch": 18.05,
      "learning_rate": 4.687009791922492e-06,
      "loss": 0.8593,
      "step": 47670
    },
    {
      "epoch": 18.05,
      "learning_rate": 4.669031108094357e-06,
      "loss": 0.8618,
      "step": 47680
    },
    {
      "epoch": 18.06,
      "learning_rate": 4.6510861481004585e-06,
      "loss": 0.8887,
      "step": 47690
    },
    {
      "epoch": 18.06,
      "learning_rate": 4.6331749182889075e-06,
      "loss": 0.8931,
      "step": 47700
    },
    {
      "epoch": 18.06,
      "learning_rate": 4.61529742499589e-06,
      "loss": 0.9249,
      "step": 47710
    },
    {
      "epoch": 18.07,
      "learning_rate": 4.597453674545671e-06,
      "loss": 0.8507,
      "step": 47720
    },
    {
      "epoch": 18.07,
      "learning_rate": 4.5796436732505884e-06,
      "loss": 0.8721,
      "step": 47730
    },
    {
      "epoch": 18.07,
      "learning_rate": 4.561867427411004e-06,
      "loss": 0.8869,
      "step": 47740
    },
    {
      "epoch": 18.08,
      "learning_rate": 4.5441249433153756e-06,
      "loss": 0.864,
      "step": 47750
    },
    {
      "epoch": 18.08,
      "learning_rate": 4.526416227240182e-06,
      "loss": 0.9562,
      "step": 47760
    },
    {
      "epoch": 18.09,
      "learning_rate": 4.50874128544998e-06,
      "loss": 0.8747,
      "step": 47770
    },
    {
      "epoch": 18.09,
      "learning_rate": 4.491100124197378e-06,
      "loss": 0.9361,
      "step": 47780
    },
    {
      "epoch": 18.09,
      "learning_rate": 4.473492749723029e-06,
      "loss": 0.8964,
      "step": 47790
    },
    {
      "epoch": 18.1,
      "learning_rate": 4.4559191682556515e-06,
      "loss": 0.8863,
      "step": 47800
    },
    {
      "epoch": 18.1,
      "learning_rate": 4.438379386011959e-06,
      "loss": 0.8743,
      "step": 47810
    },
    {
      "epoch": 18.11,
      "learning_rate": 4.420873409196768e-06,
      "loss": 0.8858,
      "step": 47820
    },
    {
      "epoch": 18.11,
      "learning_rate": 4.403401244002903e-06,
      "loss": 0.8827,
      "step": 47830
    },
    {
      "epoch": 18.11,
      "learning_rate": 4.385962896611228e-06,
      "loss": 0.8894,
      "step": 47840
    },
    {
      "epoch": 18.12,
      "learning_rate": 4.368558373190657e-06,
      "loss": 0.8759,
      "step": 47850
    },
    {
      "epoch": 18.12,
      "learning_rate": 4.3511876798981385e-06,
      "loss": 0.874,
      "step": 47860
    },
    {
      "epoch": 18.12,
      "learning_rate": 4.333850822878638e-06,
      "loss": 0.8973,
      "step": 47870
    },
    {
      "epoch": 18.13,
      "learning_rate": 4.316547808265159e-06,
      "loss": 0.9036,
      "step": 47880
    },
    {
      "epoch": 18.13,
      "learning_rate": 4.299278642178739e-06,
      "loss": 0.8777,
      "step": 47890
    },
    {
      "epoch": 18.14,
      "learning_rate": 4.282043330728436e-06,
      "loss": 0.9507,
      "step": 47900
    },
    {
      "epoch": 18.14,
      "learning_rate": 4.264841880011328e-06,
      "loss": 0.9153,
      "step": 47910
    },
    {
      "epoch": 18.14,
      "learning_rate": 4.247674296112547e-06,
      "loss": 0.8811,
      "step": 47920
    },
    {
      "epoch": 18.15,
      "learning_rate": 4.230540585105169e-06,
      "loss": 0.9088,
      "step": 47930
    },
    {
      "epoch": 18.15,
      "learning_rate": 4.213440753050368e-06,
      "loss": 0.9669,
      "step": 47940
    },
    {
      "epoch": 18.15,
      "learning_rate": 4.196374805997283e-06,
      "loss": 0.8938,
      "step": 47950
    },
    {
      "epoch": 18.16,
      "learning_rate": 4.179342749983095e-06,
      "loss": 0.8748,
      "step": 47960
    },
    {
      "epoch": 18.16,
      "learning_rate": 4.162344591032996e-06,
      "loss": 0.8602,
      "step": 47970
    },
    {
      "epoch": 18.17,
      "learning_rate": 4.145380335160143e-06,
      "loss": 0.8387,
      "step": 47980
    },
    {
      "epoch": 18.17,
      "learning_rate": 4.128449988365746e-06,
      "loss": 0.9504,
      "step": 47990
    },
    {
      "epoch": 18.17,
      "learning_rate": 4.111553556639003e-06,
      "loss": 0.9184,
      "step": 48000
    },
    {
      "epoch": 18.18,
      "learning_rate": 4.094691045957122e-06,
      "loss": 0.9352,
      "step": 48010
    },
    {
      "epoch": 18.18,
      "learning_rate": 4.077862462285298e-06,
      "loss": 0.8969,
      "step": 48020
    },
    {
      "epoch": 18.18,
      "learning_rate": 4.061067811576747e-06,
      "loss": 0.8765,
      "step": 48030
    },
    {
      "epoch": 18.19,
      "learning_rate": 4.044307099772648e-06,
      "loss": 0.8814,
      "step": 48040
    },
    {
      "epoch": 18.19,
      "learning_rate": 4.027580332802194e-06,
      "loss": 0.9287,
      "step": 48050
    },
    {
      "epoch": 18.2,
      "learning_rate": 4.010887516582562e-06,
      "loss": 0.8886,
      "step": 48060
    },
    {
      "epoch": 18.2,
      "learning_rate": 3.994228657018939e-06,
      "loss": 0.9064,
      "step": 48070
    },
    {
      "epoch": 18.2,
      "learning_rate": 3.9776037600045e-06,
      "loss": 0.8726,
      "step": 48080
    },
    {
      "epoch": 18.21,
      "learning_rate": 3.961012831420341e-06,
      "loss": 0.903,
      "step": 48090
    },
    {
      "epoch": 18.21,
      "learning_rate": 3.944455877135622e-06,
      "loss": 0.8985,
      "step": 48100
    },
    {
      "epoch": 18.21,
      "learning_rate": 3.927932903007459e-06,
      "loss": 0.8694,
      "step": 48110
    },
    {
      "epoch": 18.22,
      "learning_rate": 3.911443914880919e-06,
      "loss": 0.875,
      "step": 48120
    },
    {
      "epoch": 18.22,
      "learning_rate": 3.894988918589082e-06,
      "loss": 0.8663,
      "step": 48130
    },
    {
      "epoch": 18.23,
      "learning_rate": 3.8785679199530025e-06,
      "loss": 0.8657,
      "step": 48140
    },
    {
      "epoch": 18.23,
      "learning_rate": 3.8621809247816775e-06,
      "loss": 0.8369,
      "step": 48150
    },
    {
      "epoch": 18.23,
      "learning_rate": 3.845827938872093e-06,
      "loss": 0.9184,
      "step": 48160
    },
    {
      "epoch": 18.24,
      "learning_rate": 3.829508968009199e-06,
      "loss": 0.9021,
      "step": 48170
    },
    {
      "epoch": 18.24,
      "learning_rate": 3.813224017965944e-06,
      "loss": 0.8143,
      "step": 48180
    },
    {
      "epoch": 18.25,
      "learning_rate": 3.7969730945031865e-06,
      "loss": 0.8886,
      "step": 48190
    },
    {
      "epoch": 18.25,
      "learning_rate": 3.7807562033698065e-06,
      "loss": 0.9324,
      "step": 48200
    },
    {
      "epoch": 18.25,
      "learning_rate": 3.7645733503025915e-06,
      "loss": 0.9046,
      "step": 48210
    },
    {
      "epoch": 18.26,
      "learning_rate": 3.7484245410263185e-06,
      "loss": 0.9251,
      "step": 48220
    },
    {
      "epoch": 18.26,
      "learning_rate": 3.7323097812536957e-06,
      "loss": 0.8963,
      "step": 48230
    },
    {
      "epoch": 18.26,
      "learning_rate": 3.716229076685429e-06,
      "loss": 0.8992,
      "step": 48240
    },
    {
      "epoch": 18.27,
      "learning_rate": 3.7001824330101575e-06,
      "loss": 0.9274,
      "step": 48250
    },
    {
      "epoch": 18.27,
      "learning_rate": 3.68416985590444e-06,
      "loss": 0.9148,
      "step": 48260
    },
    {
      "epoch": 18.28,
      "learning_rate": 3.6681913510328348e-06,
      "loss": 0.9065,
      "step": 48270
    },
    {
      "epoch": 18.28,
      "learning_rate": 3.6522469240478196e-06,
      "loss": 0.8755,
      "step": 48280
    },
    {
      "epoch": 18.28,
      "learning_rate": 3.636336580589783e-06,
      "loss": 0.8729,
      "step": 48290
    },
    {
      "epoch": 18.29,
      "learning_rate": 3.6204603262871338e-06,
      "loss": 0.8672,
      "step": 48300
    },
    {
      "epoch": 18.29,
      "learning_rate": 3.6046181667561906e-06,
      "loss": 0.8922,
      "step": 48310
    },
    {
      "epoch": 18.29,
      "learning_rate": 3.5888101076011594e-06,
      "loss": 0.9143,
      "step": 48320
    },
    {
      "epoch": 18.3,
      "learning_rate": 3.5730361544142554e-06,
      "loss": 0.9018,
      "step": 48330
    },
    {
      "epoch": 18.3,
      "learning_rate": 3.5572963127755933e-06,
      "loss": 0.9062,
      "step": 48340
    },
    {
      "epoch": 18.31,
      "learning_rate": 3.541590588253196e-06,
      "loss": 0.9089,
      "step": 48350
    },
    {
      "epoch": 18.31,
      "learning_rate": 3.5259189864030873e-06,
      "loss": 0.8879,
      "step": 48360
    },
    {
      "epoch": 18.31,
      "learning_rate": 3.5102815127691647e-06,
      "loss": 0.8782,
      "step": 48370
    },
    {
      "epoch": 18.32,
      "learning_rate": 3.494678172883248e-06,
      "loss": 0.8934,
      "step": 48380
    },
    {
      "epoch": 18.32,
      "learning_rate": 3.4791089722651436e-06,
      "loss": 0.858,
      "step": 48390
    },
    {
      "epoch": 18.32,
      "learning_rate": 3.46357391642248e-06,
      "loss": 0.8915,
      "step": 48400
    },
    {
      "epoch": 18.33,
      "learning_rate": 3.4480730108509164e-06,
      "loss": 0.8748,
      "step": 48410
    },
    {
      "epoch": 18.33,
      "learning_rate": 3.432606261033977e-06,
      "loss": 0.9395,
      "step": 48420
    },
    {
      "epoch": 18.34,
      "learning_rate": 3.4171736724430748e-06,
      "loss": 0.8829,
      "step": 48430
    },
    {
      "epoch": 18.34,
      "learning_rate": 3.401775250537587e-06,
      "loss": 0.9428,
      "step": 48440
    },
    {
      "epoch": 18.34,
      "learning_rate": 3.3864110007647886e-06,
      "loss": 0.8737,
      "step": 48450
    },
    {
      "epoch": 18.35,
      "learning_rate": 3.3710809285598444e-06,
      "loss": 0.8674,
      "step": 48460
    },
    {
      "epoch": 18.35,
      "learning_rate": 3.3557850393458933e-06,
      "loss": 0.9067,
      "step": 48470
    },
    {
      "epoch": 18.35,
      "learning_rate": 3.3405233385338965e-06,
      "loss": 0.9227,
      "step": 48480
    },
    {
      "epoch": 18.36,
      "learning_rate": 3.325295831522768e-06,
      "loss": 0.8856,
      "step": 48490
    },
    {
      "epoch": 18.36,
      "learning_rate": 3.3101025236993432e-06,
      "loss": 0.9014,
      "step": 48500
    },
    {
      "epoch": 18.37,
      "learning_rate": 3.294943420438301e-06,
      "loss": 0.8598,
      "step": 48510
    },
    {
      "epoch": 18.37,
      "learning_rate": 3.279818527102252e-06,
      "loss": 0.9083,
      "step": 48520
    },
    {
      "epoch": 18.37,
      "learning_rate": 3.26472784904176e-06,
      "loss": 0.9031,
      "step": 48530
    },
    {
      "epoch": 18.38,
      "learning_rate": 3.249671391595177e-06,
      "loss": 0.8882,
      "step": 48540
    },
    {
      "epoch": 18.38,
      "learning_rate": 3.2346491600888317e-06,
      "loss": 0.9199,
      "step": 48550
    },
    {
      "epoch": 18.39,
      "learning_rate": 3.2196611598369174e-06,
      "loss": 0.8987,
      "step": 48560
    },
    {
      "epoch": 18.39,
      "learning_rate": 3.204707396141504e-06,
      "loss": 0.8686,
      "step": 48570
    },
    {
      "epoch": 18.39,
      "learning_rate": 3.1897878742925603e-06,
      "loss": 0.9033,
      "step": 48580
    },
    {
      "epoch": 18.4,
      "learning_rate": 3.174902599567975e-06,
      "loss": 0.9194,
      "step": 48590
    },
    {
      "epoch": 18.4,
      "learning_rate": 3.1600515772334694e-06,
      "loss": 0.8713,
      "step": 48600
    },
    {
      "epoch": 18.4,
      "learning_rate": 3.1452348125426966e-06,
      "loss": 0.8661,
      "step": 48610
    },
    {
      "epoch": 18.41,
      "learning_rate": 3.131929018938706e-06,
      "loss": 0.861,
      "step": 48620
    },
    {
      "epoch": 18.41,
      "learning_rate": 3.1171773582013175e-06,
      "loss": 0.873,
      "step": 48630
    },
    {
      "epoch": 18.42,
      "learning_rate": 3.1024599702746295e-06,
      "loss": 0.9513,
      "step": 48640
    },
    {
      "epoch": 18.42,
      "learning_rate": 3.087776860364977e-06,
      "loss": 0.946,
      "step": 48650
    },
    {
      "epoch": 18.42,
      "learning_rate": 3.073128033666595e-06,
      "loss": 0.9314,
      "step": 48660
    },
    {
      "epoch": 18.43,
      "learning_rate": 3.0585134953616034e-06,
      "loss": 0.9007,
      "step": 48670
    },
    {
      "epoch": 18.43,
      "learning_rate": 3.043933250619957e-06,
      "loss": 0.8711,
      "step": 48680
    },
    {
      "epoch": 18.43,
      "learning_rate": 3.029387304599485e-06,
      "loss": 0.8262,
      "step": 48690
    },
    {
      "epoch": 18.44,
      "learning_rate": 3.014875662445926e-06,
      "loss": 0.8423,
      "step": 48700
    },
    {
      "epoch": 18.44,
      "learning_rate": 3.0003983292928196e-06,
      "loss": 0.9157,
      "step": 48710
    },
    {
      "epoch": 18.45,
      "learning_rate": 2.9859553102616012e-06,
      "loss": 0.8903,
      "step": 48720
    },
    {
      "epoch": 18.45,
      "learning_rate": 2.971546610461573e-06,
      "loss": 0.8955,
      "step": 48730
    },
    {
      "epoch": 18.45,
      "learning_rate": 2.95717223498988e-06,
      "loss": 0.8984,
      "step": 48740
    },
    {
      "epoch": 18.46,
      "learning_rate": 2.942832188931566e-06,
      "loss": 0.9556,
      "step": 48750
    },
    {
      "epoch": 18.46,
      "learning_rate": 2.92852647735945e-06,
      "loss": 0.88,
      "step": 48760
    },
    {
      "epoch": 18.46,
      "learning_rate": 2.914255105334285e-06,
      "loss": 0.8675,
      "step": 48770
    },
    {
      "epoch": 18.47,
      "learning_rate": 2.9000180779046316e-06,
      "loss": 0.9134,
      "step": 48780
    },
    {
      "epoch": 18.47,
      "learning_rate": 2.885815400106917e-06,
      "loss": 0.9608,
      "step": 48790
    },
    {
      "epoch": 18.48,
      "learning_rate": 2.871647076965411e-06,
      "loss": 0.8994,
      "step": 48800
    },
    {
      "epoch": 18.48,
      "learning_rate": 2.8575131134922496e-06,
      "loss": 0.8952,
      "step": 48810
    },
    {
      "epoch": 18.48,
      "learning_rate": 2.8434135146873654e-06,
      "loss": 0.8752,
      "step": 48820
    },
    {
      "epoch": 18.49,
      "learning_rate": 2.8293482855385913e-06,
      "loss": 0.8607,
      "step": 48830
    },
    {
      "epoch": 18.49,
      "learning_rate": 2.815317431021569e-06,
      "loss": 0.8884,
      "step": 48840
    },
    {
      "epoch": 18.5,
      "learning_rate": 2.8013209560997843e-06,
      "loss": 0.9027,
      "step": 48850
    },
    {
      "epoch": 18.5,
      "learning_rate": 2.7873588657245765e-06,
      "loss": 0.9004,
      "step": 48860
    },
    {
      "epoch": 18.5,
      "learning_rate": 2.773431164835094e-06,
      "loss": 0.9029,
      "step": 48870
    },
    {
      "epoch": 18.51,
      "learning_rate": 2.759537858358341e-06,
      "loss": 0.8909,
      "step": 48880
    },
    {
      "epoch": 18.51,
      "learning_rate": 2.7456789512091407e-06,
      "loss": 0.9311,
      "step": 48890
    },
    {
      "epoch": 18.51,
      "learning_rate": 2.731854448290161e-06,
      "loss": 0.8944,
      "step": 48900
    },
    {
      "epoch": 18.52,
      "learning_rate": 2.7180643544919003e-06,
      "loss": 0.9426,
      "step": 48910
    },
    {
      "epoch": 18.52,
      "learning_rate": 2.7043086746926794e-06,
      "loss": 0.859,
      "step": 48920
    },
    {
      "epoch": 18.53,
      "learning_rate": 2.6905874137586164e-06,
      "loss": 0.854,
      "step": 48930
    },
    {
      "epoch": 18.53,
      "learning_rate": 2.676900576543706e-06,
      "loss": 0.9064,
      "step": 48940
    },
    {
      "epoch": 18.53,
      "learning_rate": 2.66324816788972e-06,
      "loss": 0.8218,
      "step": 48950
    },
    {
      "epoch": 18.54,
      "learning_rate": 2.6496301926262846e-06,
      "loss": 0.8665,
      "step": 48960
    },
    {
      "epoch": 18.54,
      "learning_rate": 2.636046655570834e-06,
      "loss": 0.88,
      "step": 48970
    },
    {
      "epoch": 18.54,
      "learning_rate": 2.622497561528614e-06,
      "loss": 0.902,
      "step": 48980
    },
    {
      "epoch": 18.55,
      "learning_rate": 2.608982915292668e-06,
      "loss": 0.8743,
      "step": 48990
    },
    {
      "epoch": 18.55,
      "learning_rate": 2.595502721643894e-06,
      "loss": 0.8765,
      "step": 49000
    },
    {
      "epoch": 18.56,
      "learning_rate": 2.5820569853509668e-06,
      "loss": 0.9031,
      "step": 49010
    },
    {
      "epoch": 18.56,
      "learning_rate": 2.5686457111704033e-06,
      "loss": 0.9003,
      "step": 49020
    },
    {
      "epoch": 18.56,
      "learning_rate": 2.5552689038465195e-06,
      "loss": 0.9086,
      "step": 49030
    },
    {
      "epoch": 18.57,
      "learning_rate": 2.5419265681113967e-06,
      "loss": 0.969,
      "step": 49040
    },
    {
      "epoch": 18.57,
      "learning_rate": 2.5286187086849823e-06,
      "loss": 0.9218,
      "step": 49050
    },
    {
      "epoch": 18.57,
      "learning_rate": 2.5153453302749983e-06,
      "loss": 0.9014,
      "step": 49060
    },
    {
      "epoch": 18.58,
      "learning_rate": 2.5021064375769786e-06,
      "loss": 0.9165,
      "step": 49070
    },
    {
      "epoch": 18.58,
      "learning_rate": 2.488902035274232e-06,
      "loss": 0.9218,
      "step": 49080
    },
    {
      "epoch": 18.59,
      "learning_rate": 2.475732128037911e-06,
      "loss": 0.9081,
      "step": 49090
    },
    {
      "epoch": 18.59,
      "learning_rate": 2.4625967205269217e-06,
      "loss": 0.8862,
      "step": 49100
    },
    {
      "epoch": 18.59,
      "learning_rate": 2.4494958173879923e-06,
      "loss": 0.8323,
      "step": 49110
    },
    {
      "epoch": 18.6,
      "learning_rate": 2.4364294232556263e-06,
      "loss": 0.8818,
      "step": 49120
    },
    {
      "epoch": 18.6,
      "learning_rate": 2.423397542752137e-06,
      "loss": 0.9437,
      "step": 49130
    },
    {
      "epoch": 18.6,
      "learning_rate": 2.4104001804876263e-06,
      "loss": 0.9139,
      "step": 49140
    },
    {
      "epoch": 18.61,
      "learning_rate": 2.3974373410599716e-06,
      "loss": 0.8876,
      "step": 49150
    },
    {
      "epoch": 18.61,
      "learning_rate": 2.384509029054849e-06,
      "loss": 0.8985,
      "step": 49160
    },
    {
      "epoch": 18.62,
      "learning_rate": 2.371615249045711e-06,
      "loss": 0.872,
      "step": 49170
    },
    {
      "epoch": 18.62,
      "learning_rate": 2.3587560055938096e-06,
      "loss": 0.9289,
      "step": 49180
    },
    {
      "epoch": 18.62,
      "learning_rate": 2.345931303248161e-06,
      "loss": 0.8827,
      "step": 49190
    },
    {
      "epoch": 18.63,
      "learning_rate": 2.3331411465455923e-06,
      "loss": 0.8837,
      "step": 49200
    },
    {
      "epoch": 18.63,
      "learning_rate": 2.320385540010672e-06,
      "loss": 0.8876,
      "step": 49210
    },
    {
      "epoch": 18.64,
      "learning_rate": 2.3076644881557586e-06,
      "loss": 0.9582,
      "step": 49220
    },
    {
      "epoch": 18.64,
      "learning_rate": 2.2949779954809957e-06,
      "loss": 0.8625,
      "step": 49230
    },
    {
      "epoch": 18.64,
      "learning_rate": 2.282326066474294e-06,
      "loss": 0.9183,
      "step": 49240
    },
    {
      "epoch": 18.65,
      "learning_rate": 2.269708705611362e-06,
      "loss": 0.8326,
      "step": 49250
    },
    {
      "epoch": 18.65,
      "learning_rate": 2.25712591735564e-06,
      "loss": 0.9282,
      "step": 49260
    },
    {
      "epoch": 18.65,
      "learning_rate": 2.2445777061583463e-06,
      "loss": 0.9427,
      "step": 49270
    },
    {
      "epoch": 18.66,
      "learning_rate": 2.2320640764584954e-06,
      "loss": 0.9077,
      "step": 49280
    },
    {
      "epoch": 18.66,
      "learning_rate": 2.219585032682836e-06,
      "loss": 0.8883,
      "step": 49290
    },
    {
      "epoch": 18.67,
      "learning_rate": 2.2071405792459033e-06,
      "loss": 0.8935,
      "step": 49300
    },
    {
      "epoch": 18.67,
      "learning_rate": 2.194730720549998e-06,
      "loss": 0.9378,
      "step": 49310
    },
    {
      "epoch": 18.67,
      "learning_rate": 2.1823554609851525e-06,
      "loss": 0.8958,
      "step": 49320
    },
    {
      "epoch": 18.68,
      "learning_rate": 2.1700148049291993e-06,
      "loss": 0.9502,
      "step": 49330
    },
    {
      "epoch": 18.68,
      "learning_rate": 2.1577087567477007e-06,
      "loss": 0.8609,
      "step": 49340
    },
    {
      "epoch": 18.68,
      "learning_rate": 2.145437320793975e-06,
      "loss": 0.8584,
      "step": 49350
    },
    {
      "epoch": 18.69,
      "learning_rate": 2.1332005014091273e-06,
      "loss": 0.8792,
      "step": 49360
    },
    {
      "epoch": 18.69,
      "learning_rate": 2.120998302922006e-06,
      "loss": 0.8952,
      "step": 49370
    },
    {
      "epoch": 18.7,
      "learning_rate": 2.1088307296491695e-06,
      "loss": 0.916,
      "step": 49380
    },
    {
      "epoch": 18.7,
      "learning_rate": 2.0966977858949853e-06,
      "loss": 0.919,
      "step": 49390
    },
    {
      "epoch": 18.7,
      "learning_rate": 2.084599475951532e-06,
      "loss": 0.8907,
      "step": 49400
    },
    {
      "epoch": 18.71,
      "learning_rate": 2.072535804098663e-06,
      "loss": 0.8494,
      "step": 49410
    },
    {
      "epoch": 18.71,
      "learning_rate": 2.0605067746039762e-06,
      "loss": 0.8661,
      "step": 49420
    },
    {
      "epoch": 18.71,
      "learning_rate": 2.048512391722779e-06,
      "loss": 0.9256,
      "step": 49430
    },
    {
      "epoch": 18.72,
      "learning_rate": 2.0365526596981542e-06,
      "loss": 0.9247,
      "step": 49440
    },
    {
      "epoch": 18.72,
      "learning_rate": 2.0246275827609405e-06,
      "loss": 0.957,
      "step": 49450
    },
    {
      "epoch": 18.73,
      "learning_rate": 2.0127371651296632e-06,
      "loss": 0.9174,
      "step": 49460
    },
    {
      "epoch": 18.73,
      "learning_rate": 2.0008814110106355e-06,
      "loss": 0.8583,
      "step": 49470
    },
    {
      "epoch": 18.73,
      "learning_rate": 1.989060324597913e-06,
      "loss": 0.8952,
      "step": 49480
    },
    {
      "epoch": 18.74,
      "learning_rate": 1.977273910073252e-06,
      "loss": 0.894,
      "step": 49490
    },
    {
      "epoch": 18.74,
      "learning_rate": 1.9655221716061378e-06,
      "loss": 0.8387,
      "step": 49500
    },
    {
      "epoch": 18.74,
      "learning_rate": 1.953805113353857e-06,
      "loss": 0.8876,
      "step": 49510
    },
    {
      "epoch": 18.75,
      "learning_rate": 1.942122739461327e-06,
      "loss": 0.8933,
      "step": 49520
    },
    {
      "epoch": 18.75,
      "learning_rate": 1.930475054061287e-06,
      "loss": 0.8525,
      "step": 49530
    },
    {
      "epoch": 18.76,
      "learning_rate": 1.9188620612741624e-06,
      "loss": 0.9493,
      "step": 49540
    },
    {
      "epoch": 18.76,
      "learning_rate": 1.90728376520809e-06,
      "loss": 0.8653,
      "step": 49550
    },
    {
      "epoch": 18.76,
      "learning_rate": 1.8957401699589817e-06,
      "loss": 0.9034,
      "step": 49560
    },
    {
      "epoch": 18.77,
      "learning_rate": 1.8842312796104267e-06,
      "loss": 0.9307,
      "step": 49570
    },
    {
      "epoch": 18.77,
      "learning_rate": 1.8727570982337573e-06,
      "loss": 0.8989,
      "step": 49580
    },
    {
      "epoch": 18.78,
      "learning_rate": 1.8613176298880376e-06,
      "loss": 0.8876,
      "step": 49590
    },
    {
      "epoch": 18.78,
      "learning_rate": 1.8499128786200192e-06,
      "loss": 0.8895,
      "step": 49600
    },
    {
      "epoch": 18.78,
      "learning_rate": 1.8385428484642199e-06,
      "loss": 0.8999,
      "step": 49610
    },
    {
      "epoch": 18.79,
      "learning_rate": 1.8272075434428326e-06,
      "loss": 0.9421,
      "step": 49620
    },
    {
      "epoch": 18.79,
      "learning_rate": 1.8159069675657725e-06,
      "loss": 0.9075,
      "step": 49630
    },
    {
      "epoch": 18.79,
      "learning_rate": 1.804641124830675e-06,
      "loss": 0.9268,
      "step": 49640
    },
    {
      "epoch": 18.8,
      "learning_rate": 1.7934100192229296e-06,
      "loss": 0.9211,
      "step": 49650
    },
    {
      "epoch": 18.8,
      "learning_rate": 1.7822136547155699e-06,
      "loss": 0.8732,
      "step": 49660
    },
    {
      "epoch": 18.81,
      "learning_rate": 1.7710520352693716e-06,
      "loss": 0.8969,
      "step": 49670
    },
    {
      "epoch": 18.81,
      "learning_rate": 1.7599251648328207e-06,
      "loss": 0.8701,
      "step": 49680
    },
    {
      "epoch": 18.81,
      "learning_rate": 1.748833047342091e-06,
      "loss": 0.9336,
      "step": 49690
    },
    {
      "epoch": 18.82,
      "learning_rate": 1.7377756867210993e-06,
      "loss": 0.948,
      "step": 49700
    },
    {
      "epoch": 18.82,
      "learning_rate": 1.7267530868814386e-06,
      "loss": 0.8871,
      "step": 49710
    },
    {
      "epoch": 18.82,
      "learning_rate": 1.715765251722401e-06,
      "loss": 0.88,
      "step": 49720
    },
    {
      "epoch": 18.83,
      "learning_rate": 1.7048121851310216e-06,
      "loss": 0.904,
      "step": 49730
    },
    {
      "epoch": 18.83,
      "learning_rate": 1.693893890981968e-06,
      "loss": 0.8818,
      "step": 49740
    },
    {
      "epoch": 18.84,
      "learning_rate": 1.6830103731376501e-06,
      "loss": 0.8907,
      "step": 49750
    },
    {
      "epoch": 18.84,
      "learning_rate": 1.6721616354481996e-06,
      "loss": 0.9283,
      "step": 49760
    },
    {
      "epoch": 18.84,
      "learning_rate": 1.6613476817513906e-06,
      "loss": 0.8835,
      "step": 49770
    },
    {
      "epoch": 18.85,
      "learning_rate": 1.6505685158727192e-06,
      "loss": 0.8348,
      "step": 49780
    },
    {
      "epoch": 18.85,
      "learning_rate": 1.639824141625379e-06,
      "loss": 0.9243,
      "step": 49790
    },
    {
      "epoch": 18.85,
      "learning_rate": 1.629114562810241e-06,
      "loss": 0.888,
      "step": 49800
    },
    {
      "epoch": 18.86,
      "learning_rate": 1.6184397832158859e-06,
      "loss": 0.9028,
      "step": 49810
    },
    {
      "epoch": 18.86,
      "learning_rate": 1.6077998066185596e-06,
      "loss": 0.9565,
      "step": 49820
    },
    {
      "epoch": 18.87,
      "learning_rate": 1.5971946367822177e-06,
      "loss": 0.8761,
      "step": 49830
    },
    {
      "epoch": 18.87,
      "learning_rate": 1.5866242774585039e-06,
      "loss": 0.9164,
      "step": 49840
    },
    {
      "epoch": 18.87,
      "learning_rate": 1.5760887323867157e-06,
      "loss": 0.946,
      "step": 49850
    },
    {
      "epoch": 18.88,
      "learning_rate": 1.565588005293872e-06,
      "loss": 0.9097,
      "step": 49860
    },
    {
      "epoch": 18.88,
      "learning_rate": 1.5551220998946681e-06,
      "loss": 0.9576,
      "step": 49870
    },
    {
      "epoch": 18.88,
      "learning_rate": 1.5446910198914644e-06,
      "loss": 0.9304,
      "step": 49880
    },
    {
      "epoch": 18.89,
      "learning_rate": 1.5342947689743093e-06,
      "loss": 0.9049,
      "step": 49890
    },
    {
      "epoch": 18.89,
      "learning_rate": 1.5239333508209386e-06,
      "loss": 0.9307,
      "step": 49900
    },
    {
      "epoch": 18.9,
      "learning_rate": 1.5136067690967537e-06,
      "loss": 0.8864,
      "step": 49910
    },
    {
      "epoch": 18.9,
      "learning_rate": 1.5033150274548324e-06,
      "loss": 0.8949,
      "step": 49920
    },
    {
      "epoch": 18.9,
      "learning_rate": 1.4930581295359292e-06,
      "loss": 0.928,
      "step": 49930
    },
    {
      "epoch": 18.91,
      "learning_rate": 1.482836078968497e-06,
      "loss": 0.9126,
      "step": 49940
    },
    {
      "epoch": 18.91,
      "learning_rate": 1.4726488793686322e-06,
      "loss": 0.9578,
      "step": 49950
    },
    {
      "epoch": 18.92,
      "learning_rate": 1.4624965343401076e-06,
      "loss": 0.8781,
      "step": 49960
    },
    {
      "epoch": 18.92,
      "learning_rate": 1.4523790474743503e-06,
      "loss": 0.9153,
      "step": 49970
    },
    {
      "epoch": 18.92,
      "learning_rate": 1.4422964223505087e-06,
      "loss": 0.8982,
      "step": 49980
    },
    {
      "epoch": 18.93,
      "learning_rate": 1.4322486625353404e-06,
      "loss": 0.9403,
      "step": 49990
    },
    {
      "epoch": 18.93,
      "learning_rate": 1.4222357715833024e-06,
      "loss": 0.907,
      "step": 50000
    },
    {
      "epoch": 18.93,
      "learning_rate": 1.4122577530365056e-06,
      "loss": 0.8715,
      "step": 50010
    },
    {
      "epoch": 18.94,
      "learning_rate": 1.4023146104247376e-06,
      "loss": 0.9014,
      "step": 50020
    },
    {
      "epoch": 18.94,
      "learning_rate": 1.392406347265418e-06,
      "loss": 0.9413,
      "step": 50030
    },
    {
      "epoch": 18.95,
      "learning_rate": 1.3825329670636545e-06,
      "loss": 0.8725,
      "step": 50040
    },
    {
      "epoch": 18.95,
      "learning_rate": 1.3726944733122083e-06,
      "loss": 0.8535,
      "step": 50050
    },
    {
      "epoch": 18.95,
      "learning_rate": 1.3628908694915067e-06,
      "loss": 0.891,
      "step": 50060
    },
    {
      "epoch": 18.96,
      "learning_rate": 1.3531221590696308e-06,
      "loss": 0.9007,
      "step": 50070
    },
    {
      "epoch": 18.96,
      "learning_rate": 1.3433883455022944e-06,
      "loss": 0.8973,
      "step": 50080
    },
    {
      "epoch": 18.96,
      "learning_rate": 1.3336894322328875e-06,
      "loss": 0.921,
      "step": 50090
    },
    {
      "epoch": 18.97,
      "learning_rate": 1.3240254226924654e-06,
      "loss": 0.8973,
      "step": 50100
    },
    {
      "epoch": 18.97,
      "learning_rate": 1.3143963202997157e-06,
      "loss": 0.8458,
      "step": 50110
    },
    {
      "epoch": 18.98,
      "learning_rate": 1.3048021284609912e-06,
      "loss": 0.872,
      "step": 50120
    },
    {
      "epoch": 18.98,
      "learning_rate": 1.2952428505702663e-06,
      "loss": 0.9046,
      "step": 50130
    },
    {
      "epoch": 18.98,
      "learning_rate": 1.2857184900092134e-06,
      "loss": 0.923,
      "step": 50140
    },
    {
      "epoch": 18.99,
      "learning_rate": 1.276229050147104e-06,
      "loss": 0.9171,
      "step": 50150
    },
    {
      "epoch": 18.99,
      "learning_rate": 1.2667745343408865e-06,
      "loss": 0.8658,
      "step": 50160
    },
    {
      "epoch": 18.99,
      "learning_rate": 1.2573549459351519e-06,
      "loss": 0.8677,
      "step": 50170
    },
    {
      "epoch": 19.0,
      "learning_rate": 1.2479702882621236e-06,
      "loss": 0.8493,
      "step": 50180
    },
    {
      "epoch": 19.0,
      "learning_rate": 1.2386205646416683e-06,
      "loss": 0.9488,
      "step": 50190
    },
    {
      "epoch": 19.01,
      "learning_rate": 1.2293057783813067e-06,
      "loss": 0.8788,
      "step": 50200
    },
    {
      "epoch": 19.01,
      "learning_rate": 1.220025932776192e-06,
      "loss": 0.879,
      "step": 50210
    },
    {
      "epoch": 19.01,
      "learning_rate": 1.2107810311091205e-06,
      "loss": 0.9016,
      "step": 50220
    },
    {
      "epoch": 19.02,
      "learning_rate": 1.2015710766505316e-06,
      "loss": 0.9045,
      "step": 50230
    },
    {
      "epoch": 19.02,
      "learning_rate": 1.192396072658486e-06,
      "loss": 0.8982,
      "step": 50240
    },
    {
      "epoch": 19.03,
      "learning_rate": 1.183256022378676e-06,
      "loss": 0.9038,
      "step": 50250
    },
    {
      "epoch": 19.03,
      "learning_rate": 1.1741509290444708e-06,
      "loss": 0.8979,
      "step": 50260
    },
    {
      "epoch": 19.03,
      "learning_rate": 1.1650807958768273e-06,
      "loss": 0.9047,
      "step": 50270
    },
    {
      "epoch": 19.04,
      "learning_rate": 1.1560456260843566e-06,
      "loss": 0.9087,
      "step": 50280
    },
    {
      "epoch": 19.04,
      "learning_rate": 1.1470454228633131e-06,
      "loss": 0.8517,
      "step": 50290
    },
    {
      "epoch": 19.04,
      "learning_rate": 1.138080189397539e-06,
      "loss": 0.8933,
      "step": 50300
    },
    {
      "epoch": 19.05,
      "learning_rate": 1.1291499288585528e-06,
      "loss": 0.8712,
      "step": 50310
    },
    {
      "epoch": 19.05,
      "learning_rate": 1.1202546444054718e-06,
      "loss": 0.8951,
      "step": 50320
    },
    {
      "epoch": 19.06,
      "learning_rate": 1.1113943391850568e-06,
      "loss": 0.8887,
      "step": 50330
    },
    {
      "epoch": 19.06,
      "learning_rate": 1.1025690163316783e-06,
      "loss": 0.9049,
      "step": 50340
    },
    {
      "epoch": 19.06,
      "learning_rate": 1.09377867896735e-06,
      "loss": 0.9133,
      "step": 50350
    },
    {
      "epoch": 19.07,
      "learning_rate": 1.0850233302016954e-06,
      "loss": 0.9116,
      "step": 50360
    },
    {
      "epoch": 19.07,
      "learning_rate": 1.0763029731319818e-06,
      "loss": 0.8717,
      "step": 50370
    },
    {
      "epoch": 19.07,
      "learning_rate": 1.0676176108430414e-06,
      "loss": 0.8689,
      "step": 50380
    },
    {
      "epoch": 19.08,
      "learning_rate": 1.0589672464074052e-06,
      "loss": 0.9233,
      "step": 50390
    },
    {
      "epoch": 19.08,
      "learning_rate": 1.050351882885181e-06,
      "loss": 0.8886,
      "step": 50400
    },
    {
      "epoch": 19.09,
      "learning_rate": 1.0417715233240755e-06,
      "loss": 0.9315,
      "step": 50410
    },
    {
      "epoch": 19.09,
      "learning_rate": 1.0332261707594603e-06,
      "loss": 0.9101,
      "step": 50420
    },
    {
      "epoch": 19.09,
      "learning_rate": 1.0247158282142844e-06,
      "loss": 0.8812,
      "step": 50430
    },
    {
      "epoch": 19.1,
      "learning_rate": 1.0162404986991391e-06,
      "loss": 0.9338,
      "step": 50440
    },
    {
      "epoch": 19.1,
      "learning_rate": 1.0078001852122042e-06,
      "loss": 0.9563,
      "step": 50450
    },
    {
      "epoch": 19.1,
      "learning_rate": 9.993948907393024e-07,
      "loss": 0.8998,
      "step": 50460
    },
    {
      "epoch": 19.11,
      "learning_rate": 9.91024618253833e-07,
      "loss": 0.9106,
      "step": 50470
    },
    {
      "epoch": 19.11,
      "learning_rate": 9.826893707168272e-07,
      "loss": 0.8867,
      "step": 50480
    },
    {
      "epoch": 19.12,
      "learning_rate": 9.743891510769265e-07,
      "loss": 0.8789,
      "step": 50490
    },
    {
      "epoch": 19.12,
      "learning_rate": 9.66123962270382e-07,
      "loss": 0.9116,
      "step": 50500
    },
    {
      "epoch": 19.12,
      "learning_rate": 9.578938072210553e-07,
      "loss": 0.8894,
      "step": 50510
    },
    {
      "epoch": 19.13,
      "learning_rate": 9.496986888403836e-07,
      "loss": 0.9187,
      "step": 50520
    },
    {
      "epoch": 19.13,
      "learning_rate": 9.415386100274371e-07,
      "loss": 0.9179,
      "step": 50530
    },
    {
      "epoch": 19.13,
      "learning_rate": 9.334135736689065e-07,
      "loss": 0.8291,
      "step": 50540
    },
    {
      "epoch": 19.14,
      "learning_rate": 9.253235826390483e-07,
      "loss": 0.8737,
      "step": 50550
    },
    {
      "epoch": 19.14,
      "learning_rate": 9.17268639799751e-07,
      "loss": 0.9253,
      "step": 50560
    },
    {
      "epoch": 19.15,
      "learning_rate": 9.092487480004908e-07,
      "loss": 0.9178,
      "step": 50570
    },
    {
      "epoch": 19.15,
      "learning_rate": 9.012639100783426e-07,
      "loss": 0.8858,
      "step": 50580
    },
    {
      "epoch": 19.15,
      "learning_rate": 8.933141288579805e-07,
      "loss": 0.9002,
      "step": 50590
    },
    {
      "epoch": 19.16,
      "learning_rate": 8.853994071516991e-07,
      "loss": 0.936,
      "step": 50600
    },
    {
      "epoch": 19.16,
      "learning_rate": 8.775197477593478e-07,
      "loss": 0.9413,
      "step": 50610
    },
    {
      "epoch": 19.17,
      "learning_rate": 8.696751534684188e-07,
      "loss": 0.8917,
      "step": 50620
    },
    {
      "epoch": 19.17,
      "learning_rate": 8.618656270539815e-07,
      "loss": 0.8577,
      "step": 50630
    },
    {
      "epoch": 19.17,
      "learning_rate": 8.540911712786814e-07,
      "loss": 0.9103,
      "step": 50640
    },
    {
      "epoch": 19.18,
      "learning_rate": 8.463517888927741e-07,
      "loss": 0.8923,
      "step": 50650
    },
    {
      "epoch": 19.18,
      "learning_rate": 8.386474826341251e-07,
      "loss": 0.9043,
      "step": 50660
    },
    {
      "epoch": 19.18,
      "learning_rate": 8.309782552281431e-07,
      "loss": 0.8924,
      "step": 50670
    },
    {
      "epoch": 19.19,
      "learning_rate": 8.233441093878913e-07,
      "loss": 0.9133,
      "step": 50680
    },
    {
      "epoch": 19.19,
      "learning_rate": 8.15745047813965e-07,
      "loss": 0.8817,
      "step": 50690
    },
    {
      "epoch": 19.2,
      "learning_rate": 8.081810731945805e-07,
      "loss": 0.8793,
      "step": 50700
    },
    {
      "epoch": 19.2,
      "learning_rate": 8.006521882055418e-07,
      "loss": 0.9057,
      "step": 50710
    },
    {
      "epoch": 19.2,
      "learning_rate": 7.931583955102184e-07,
      "loss": 0.8652,
      "step": 50720
    },
    {
      "epoch": 19.21,
      "learning_rate": 7.856996977595787e-07,
      "loss": 0.8646,
      "step": 50730
    },
    {
      "epoch": 19.21,
      "learning_rate": 7.782760975921899e-07,
      "loss": 0.9558,
      "step": 50740
    },
    {
      "epoch": 19.21,
      "learning_rate": 7.708875976341845e-07,
      "loss": 0.8661,
      "step": 50750
    },
    {
      "epoch": 19.22,
      "learning_rate": 7.635342004992829e-07,
      "loss": 0.916,
      "step": 50760
    },
    {
      "epoch": 19.22,
      "learning_rate": 7.562159087887821e-07,
      "loss": 0.8674,
      "step": 50770
    },
    {
      "epoch": 19.23,
      "learning_rate": 7.489327250915668e-07,
      "loss": 0.8723,
      "step": 50780
    },
    {
      "epoch": 19.23,
      "learning_rate": 7.416846519841092e-07,
      "loss": 0.8645,
      "step": 50790
    },
    {
      "epoch": 19.23,
      "learning_rate": 7.344716920304473e-07,
      "loss": 0.8757,
      "step": 50800
    },
    {
      "epoch": 19.24,
      "learning_rate": 7.272938477822178e-07,
      "loss": 0.8912,
      "step": 50810
    },
    {
      "epoch": 19.24,
      "learning_rate": 7.201511217786006e-07,
      "loss": 0.9061,
      "step": 50820
    },
    {
      "epoch": 19.24,
      "learning_rate": 7.130435165463856e-07,
      "loss": 0.8935,
      "step": 50830
    },
    {
      "epoch": 19.25,
      "learning_rate": 7.059710345999171e-07,
      "loss": 0.9248,
      "step": 50840
    },
    {
      "epoch": 19.25,
      "learning_rate": 6.989336784411382e-07,
      "loss": 0.8977,
      "step": 50850
    },
    {
      "epoch": 19.26,
      "learning_rate": 6.919314505595353e-07,
      "loss": 0.8927,
      "step": 50860
    },
    {
      "epoch": 19.26,
      "learning_rate": 6.849643534321937e-07,
      "loss": 0.8612,
      "step": 50870
    },
    {
      "epoch": 19.26,
      "learning_rate": 6.780323895237528e-07,
      "loss": 0.9077,
      "step": 50880
    },
    {
      "epoch": 19.27,
      "learning_rate": 6.7113556128644e-07,
      "loss": 0.9124,
      "step": 50890
    },
    {
      "epoch": 19.27,
      "learning_rate": 6.642738711600372e-07,
      "loss": 0.8554,
      "step": 50900
    },
    {
      "epoch": 19.27,
      "learning_rate": 6.574473215719023e-07,
      "loss": 0.8869,
      "step": 50910
    },
    {
      "epoch": 19.28,
      "learning_rate": 6.506559149369595e-07,
      "loss": 0.8915,
      "step": 50920
    },
    {
      "epoch": 19.28,
      "learning_rate": 6.438996536577314e-07,
      "loss": 0.9135,
      "step": 50930
    },
    {
      "epoch": 19.29,
      "learning_rate": 6.371785401242503e-07,
      "loss": 0.9115,
      "step": 50940
    },
    {
      "epoch": 19.29,
      "learning_rate": 6.30492576714159e-07,
      "loss": 0.8611,
      "step": 50950
    },
    {
      "epoch": 19.29,
      "learning_rate": 6.238417657926543e-07,
      "loss": 0.9178,
      "step": 50960
    },
    {
      "epoch": 19.3,
      "learning_rate": 6.172261097124876e-07,
      "loss": 0.9164,
      "step": 50970
    },
    {
      "epoch": 19.3,
      "learning_rate": 6.106456108139869e-07,
      "loss": 0.8778,
      "step": 50980
    },
    {
      "epoch": 19.31,
      "learning_rate": 6.041002714250455e-07,
      "loss": 0.9022,
      "step": 50990
    },
    {
      "epoch": 19.31,
      "learning_rate": 5.975900938611001e-07,
      "loss": 0.9061,
      "step": 51000
    },
    {
      "epoch": 19.31,
      "learning_rate": 5.911150804251642e-07,
      "loss": 0.8578,
      "step": 51010
    },
    {
      "epoch": 19.32,
      "learning_rate": 5.846752334078054e-07,
      "loss": 0.8978,
      "step": 51020
    },
    {
      "epoch": 19.32,
      "learning_rate": 5.78270555087157e-07,
      "loss": 0.8723,
      "step": 51030
    },
    {
      "epoch": 19.32,
      "learning_rate": 5.719010477289178e-07,
      "loss": 0.8507,
      "step": 51040
    },
    {
      "epoch": 19.33,
      "learning_rate": 5.655667135863185e-07,
      "loss": 0.8882,
      "step": 51050
    },
    {
      "epoch": 19.33,
      "learning_rate": 5.592675549001669e-07,
      "loss": 0.8987,
      "step": 51060
    },
    {
      "epoch": 19.34,
      "learning_rate": 5.53003573898836e-07,
      "loss": 0.9229,
      "step": 51070
    },
    {
      "epoch": 19.34,
      "learning_rate": 5.467747727982309e-07,
      "loss": 0.9297,
      "step": 51080
    },
    {
      "epoch": 19.34,
      "learning_rate": 5.405811538018113e-07,
      "loss": 0.8776,
      "step": 51090
    },
    {
      "epoch": 19.35,
      "learning_rate": 5.344227191006357e-07,
      "loss": 0.8739,
      "step": 51100
    },
    {
      "epoch": 19.35,
      "learning_rate": 5.282994708732503e-07,
      "loss": 0.8683,
      "step": 51110
    },
    {
      "epoch": 19.35,
      "learning_rate": 5.222114112858001e-07,
      "loss": 0.8986,
      "step": 51120
    },
    {
      "epoch": 19.36,
      "learning_rate": 5.161585424919735e-07,
      "loss": 0.8684,
      "step": 51130
    },
    {
      "epoch": 19.36,
      "learning_rate": 5.10140866632991e-07,
      "loss": 0.9026,
      "step": 51140
    },
    {
      "epoch": 19.37,
      "learning_rate": 5.041583858376497e-07,
      "loss": 0.898,
      "step": 51150
    },
    {
      "epoch": 19.37,
      "learning_rate": 4.982111022222901e-07,
      "loss": 0.9597,
      "step": 51160
    },
    {
      "epoch": 19.37,
      "learning_rate": 4.922990178907738e-07,
      "loss": 0.8837,
      "step": 51170
    },
    {
      "epoch": 19.38,
      "learning_rate": 4.864221349345388e-07,
      "loss": 0.8666,
      "step": 51180
    },
    {
      "epoch": 19.38,
      "learning_rate": 4.805804554325777e-07,
      "loss": 0.871,
      "step": 51190
    },
    {
      "epoch": 19.38,
      "learning_rate": 4.7477398145139296e-07,
      "loss": 0.9434,
      "step": 51200
    },
    {
      "epoch": 19.39,
      "learning_rate": 4.6900271504508596e-07,
      "loss": 0.8856,
      "step": 51210
    },
    {
      "epoch": 19.39,
      "learning_rate": 4.6326665825523474e-07,
      "loss": 0.8786,
      "step": 51220
    },
    {
      "epoch": 19.4,
      "learning_rate": 4.575658131110272e-07,
      "loss": 0.947,
      "step": 51230
    },
    {
      "epoch": 19.4,
      "learning_rate": 4.5190018162916124e-07,
      "loss": 0.9272,
      "step": 51240
    },
    {
      "epoch": 19.4,
      "learning_rate": 4.462697658138892e-07,
      "loss": 0.9246,
      "step": 51250
    },
    {
      "epoch": 19.41,
      "learning_rate": 4.4067456765698457e-07,
      "loss": 0.8598,
      "step": 51260
    },
    {
      "epoch": 19.41,
      "learning_rate": 4.351145891377861e-07,
      "loss": 0.9084,
      "step": 51270
    },
    {
      "epoch": 19.42,
      "learning_rate": 4.295898322231762e-07,
      "loss": 0.8822,
      "step": 51280
    },
    {
      "epoch": 19.42,
      "learning_rate": 4.241002988675469e-07,
      "loss": 0.8743,
      "step": 51290
    },
    {
      "epoch": 19.42,
      "learning_rate": 4.1864599101286704e-07,
      "loss": 0.9438,
      "step": 51300
    },
    {
      "epoch": 19.43,
      "learning_rate": 4.132269105886155e-07,
      "loss": 0.9188,
      "step": 51310
    },
    {
      "epoch": 19.43,
      "learning_rate": 4.0784305951182544e-07,
      "loss": 0.8413,
      "step": 51320
    },
    {
      "epoch": 19.43,
      "learning_rate": 4.0249443968706226e-07,
      "loss": 0.9251,
      "step": 51330
    },
    {
      "epoch": 19.44,
      "learning_rate": 3.971810530064346e-07,
      "loss": 0.903,
      "step": 51340
    },
    {
      "epoch": 19.44,
      "learning_rate": 3.919029013495723e-07,
      "loss": 0.8469,
      "step": 51350
    },
    {
      "epoch": 19.45,
      "learning_rate": 3.866599865836484e-07,
      "loss": 0.8709,
      "step": 51360
    },
    {
      "epoch": 19.45,
      "learning_rate": 3.814523105633794e-07,
      "loss": 0.9126,
      "step": 51370
    },
    {
      "epoch": 19.45,
      "learning_rate": 3.762798751310026e-07,
      "loss": 0.9175,
      "step": 51380
    },
    {
      "epoch": 19.46,
      "learning_rate": 3.7114268211629886e-07,
      "loss": 0.8866,
      "step": 51390
    },
    {
      "epoch": 19.46,
      "learning_rate": 3.6604073333657005e-07,
      "loss": 0.8963,
      "step": 51400
    },
    {
      "epoch": 19.46,
      "learning_rate": 3.6097403059666133e-07,
      "loss": 0.8935,
      "step": 51410
    },
    {
      "epoch": 19.47,
      "learning_rate": 3.5594257568895004e-07,
      "loss": 0.8668,
      "step": 51420
    },
    {
      "epoch": 19.47,
      "learning_rate": 3.5094637039333464e-07,
      "loss": 0.892,
      "step": 51430
    },
    {
      "epoch": 19.48,
      "learning_rate": 3.459854164772569e-07,
      "loss": 0.8642,
      "step": 51440
    },
    {
      "epoch": 19.48,
      "learning_rate": 3.410597156956685e-07,
      "loss": 0.8893,
      "step": 51450
    },
    {
      "epoch": 19.48,
      "learning_rate": 3.3616926979107564e-07,
      "loss": 0.8706,
      "step": 51460
    },
    {
      "epoch": 19.49,
      "learning_rate": 3.3131408049347223e-07,
      "loss": 0.8799,
      "step": 51470
    },
    {
      "epoch": 19.49,
      "learning_rate": 3.264941495204399e-07,
      "loss": 0.873,
      "step": 51480
    },
    {
      "epoch": 19.49,
      "learning_rate": 3.21709478577048e-07,
      "loss": 0.901,
      "step": 51490
    },
    {
      "epoch": 19.5,
      "learning_rate": 3.169600693558872e-07,
      "loss": 0.8856,
      "step": 51500
    },
    {
      "epoch": 19.5,
      "learning_rate": 3.1224592353709114e-07,
      "loss": 0.9333,
      "step": 51510
    },
    {
      "epoch": 19.51,
      "learning_rate": 3.0756704278831483e-07,
      "loss": 0.8498,
      "step": 51520
    },
    {
      "epoch": 19.51,
      "learning_rate": 3.0292342876473423e-07,
      "loss": 0.9494,
      "step": 51530
    },
    {
      "epoch": 19.51,
      "learning_rate": 2.9831508310904643e-07,
      "loss": 0.8959,
      "step": 51540
    },
    {
      "epoch": 19.52,
      "learning_rate": 2.9374200745150293e-07,
      "loss": 0.9343,
      "step": 51550
    },
    {
      "epoch": 19.52,
      "learning_rate": 2.892042034098319e-07,
      "loss": 0.894,
      "step": 51560
    },
    {
      "epoch": 19.52,
      "learning_rate": 2.847016725893048e-07,
      "loss": 0.8833,
      "step": 51570
    },
    {
      "epoch": 19.53,
      "learning_rate": 2.802344165827253e-07,
      "loss": 0.9339,
      "step": 51580
    },
    {
      "epoch": 19.53,
      "learning_rate": 2.75802436970396e-07,
      "loss": 0.8596,
      "step": 51590
    },
    {
      "epoch": 19.54,
      "learning_rate": 2.7140573532017375e-07,
      "loss": 0.8637,
      "step": 51600
    },
    {
      "epoch": 19.54,
      "learning_rate": 2.670443131874034e-07,
      "loss": 0.9064,
      "step": 51610
    },
    {
      "epoch": 19.54,
      "learning_rate": 2.6271817211496185e-07,
      "loss": 0.8689,
      "step": 51620
    },
    {
      "epoch": 19.55,
      "learning_rate": 2.58427313633236e-07,
      "loss": 0.961,
      "step": 51630
    },
    {
      "epoch": 19.55,
      "learning_rate": 2.5417173926014506e-07,
      "loss": 0.8929,
      "step": 51640
    },
    {
      "epoch": 19.56,
      "learning_rate": 2.499514505011291e-07,
      "loss": 0.902,
      "step": 51650
    },
    {
      "epoch": 19.56,
      "learning_rate": 2.457664488491274e-07,
      "loss": 0.9297,
      "step": 51660
    },
    {
      "epoch": 19.56,
      "learning_rate": 2.4161673578462216e-07,
      "loss": 0.8981,
      "step": 51670
    },
    {
      "epoch": 19.57,
      "learning_rate": 2.3750231277557267e-07,
      "loss": 0.8998,
      "step": 51680
    },
    {
      "epoch": 19.57,
      "learning_rate": 2.334231812774923e-07,
      "loss": 0.9299,
      "step": 51690
    },
    {
      "epoch": 19.57,
      "learning_rate": 2.2937934273339345e-07,
      "loss": 0.8879,
      "step": 51700
    },
    {
      "epoch": 19.58,
      "learning_rate": 2.253707985738096e-07,
      "loss": 0.9078,
      "step": 51710
    },
    {
      "epoch": 19.58,
      "learning_rate": 2.213975502167731e-07,
      "loss": 0.8942,
      "step": 51720
    },
    {
      "epoch": 19.59,
      "learning_rate": 2.1745959906784852e-07,
      "loss": 0.8971,
      "step": 51730
    },
    {
      "epoch": 19.59,
      "learning_rate": 2.135569465201104e-07,
      "loss": 0.8694,
      "step": 51740
    },
    {
      "epoch": 19.59,
      "learning_rate": 2.0968959395413214e-07,
      "loss": 0.8956,
      "step": 51750
    },
    {
      "epoch": 19.6,
      "learning_rate": 2.0585754273801938e-07,
      "loss": 0.8906,
      "step": 51760
    },
    {
      "epoch": 19.6,
      "learning_rate": 2.0206079422738776e-07,
      "loss": 0.904,
      "step": 51770
    },
    {
      "epoch": 19.6,
      "learning_rate": 1.982993497653407e-07,
      "loss": 0.8669,
      "step": 51780
    },
    {
      "epoch": 19.61,
      "learning_rate": 1.9457321068251376e-07,
      "loss": 0.8759,
      "step": 51790
    },
    {
      "epoch": 19.61,
      "learning_rate": 1.9088237829705257e-07,
      "loss": 0.9134,
      "step": 51800
    },
    {
      "epoch": 19.62,
      "learning_rate": 1.872268539146016e-07,
      "loss": 0.9136,
      "step": 51810
    },
    {
      "epoch": 19.62,
      "learning_rate": 1.836066388283264e-07,
      "loss": 0.915,
      "step": 51820
    },
    {
      "epoch": 19.62,
      "learning_rate": 1.8002173431890257e-07,
      "loss": 0.8212,
      "step": 51830
    },
    {
      "epoch": 19.63,
      "learning_rate": 1.7647214165450453e-07,
      "loss": 0.9038,
      "step": 51840
    },
    {
      "epoch": 19.63,
      "learning_rate": 1.7295786209081676e-07,
      "loss": 0.8813,
      "step": 51850
    },
    {
      "epoch": 19.63,
      "learning_rate": 1.694788968710448e-07,
      "loss": 0.899,
      "step": 51860
    },
    {
      "epoch": 19.64,
      "learning_rate": 1.6603524722587082e-07,
      "loss": 0.8776,
      "step": 51870
    },
    {
      "epoch": 19.64,
      "learning_rate": 1.626269143735204e-07,
      "loss": 0.9366,
      "step": 51880
    },
    {
      "epoch": 19.65,
      "learning_rate": 1.5925389951970681e-07,
      "loss": 0.8571,
      "step": 51890
    },
    {
      "epoch": 19.65,
      "learning_rate": 1.5591620385764227e-07,
      "loss": 0.9437,
      "step": 51900
    },
    {
      "epoch": 19.65,
      "learning_rate": 1.5261382856807115e-07,
      "loss": 0.829,
      "step": 51910
    },
    {
      "epoch": 19.66,
      "learning_rate": 1.4934677481920346e-07,
      "loss": 0.8877,
      "step": 51920
    },
    {
      "epoch": 19.66,
      "learning_rate": 1.4611504376680353e-07,
      "loss": 0.9432,
      "step": 51930
    },
    {
      "epoch": 19.66,
      "learning_rate": 1.4291863655409022e-07,
      "loss": 0.8771,
      "step": 51940
    },
    {
      "epoch": 19.67,
      "learning_rate": 1.397575543118257e-07,
      "loss": 0.9349,
      "step": 51950
    },
    {
      "epoch": 19.67,
      "learning_rate": 1.3663179815824877e-07,
      "loss": 0.9082,
      "step": 51960
    },
    {
      "epoch": 19.68,
      "learning_rate": 1.3354136919911943e-07,
      "loss": 0.9149,
      "step": 51970
    },
    {
      "epoch": 19.68,
      "learning_rate": 1.304862685276964e-07,
      "loss": 0.8583,
      "step": 51980
    },
    {
      "epoch": 19.68,
      "learning_rate": 1.2746649722471526e-07,
      "loss": 0.9384,
      "step": 51990
    },
    {
      "epoch": 19.69,
      "learning_rate": 1.2448205635846589e-07,
      "loss": 0.8574,
      "step": 52000
    },
    {
      "epoch": 19.69,
      "learning_rate": 1.2153294698469263e-07,
      "loss": 0.874,
      "step": 52010
    },
    {
      "epoch": 19.7,
      "learning_rate": 1.1861917014666102e-07,
      "loss": 0.9076,
      "step": 52020
    },
    {
      "epoch": 19.7,
      "learning_rate": 1.1574072687513537e-07,
      "loss": 0.9027,
      "step": 52030
    },
    {
      "epoch": 19.7,
      "learning_rate": 1.1289761818837896e-07,
      "loss": 0.939,
      "step": 52040
    },
    {
      "epoch": 19.71,
      "learning_rate": 1.1008984509216503e-07,
      "loss": 0.8745,
      "step": 52050
    },
    {
      "epoch": 19.71,
      "learning_rate": 1.0731740857975459e-07,
      "loss": 0.9096,
      "step": 52060
    },
    {
      "epoch": 19.71,
      "learning_rate": 1.0458030963189646e-07,
      "loss": 0.9269,
      "step": 52070
    },
    {
      "epoch": 19.72,
      "learning_rate": 1.0187854921687168e-07,
      "loss": 0.9159,
      "step": 52080
    },
    {
      "epoch": 19.72,
      "learning_rate": 9.921212829043791e-08,
      "loss": 0.8996,
      "step": 52090
    },
    {
      "epoch": 19.73,
      "learning_rate": 9.658104779586286e-08,
      "loss": 0.885,
      "step": 52100
    },
    {
      "epoch": 19.73,
      "learning_rate": 9.398530866389088e-08,
      "loss": 0.9243,
      "step": 52110
    },
    {
      "epoch": 19.73,
      "learning_rate": 9.142491181277635e-08,
      "loss": 0.885,
      "step": 52120
    },
    {
      "epoch": 19.74,
      "learning_rate": 8.889985814829471e-08,
      "loss": 0.9044,
      "step": 52130
    },
    {
      "epoch": 19.74,
      "learning_rate": 8.641014856367591e-08,
      "loss": 0.8616,
      "step": 52140
    },
    {
      "epoch": 19.74,
      "learning_rate": 8.395578393967096e-08,
      "loss": 0.8918,
      "step": 52150
    },
    {
      "epoch": 19.75,
      "learning_rate": 8.15367651445409e-08,
      "loss": 0.8496,
      "step": 52160
    },
    {
      "epoch": 19.75,
      "learning_rate": 7.91530930340012e-08,
      "loss": 0.8794,
      "step": 52170
    },
    {
      "epoch": 19.76,
      "learning_rate": 7.680476845131068e-08,
      "loss": 0.9434,
      "step": 52180
    },
    {
      "epoch": 19.76,
      "learning_rate": 7.449179222719371e-08,
      "loss": 0.879,
      "step": 52190
    },
    {
      "epoch": 19.76,
      "learning_rate": 7.221416517987356e-08,
      "loss": 0.88,
      "step": 52200
    },
    {
      "epoch": 19.77,
      "learning_rate": 6.997188811508348e-08,
      "loss": 0.8755,
      "step": 52210
    },
    {
      "epoch": 19.77,
      "learning_rate": 6.776496182602232e-08,
      "loss": 0.888,
      "step": 52220
    },
    {
      "epoch": 19.77,
      "learning_rate": 6.559338709342111e-08,
      "loss": 0.8898,
      "step": 52230
    },
    {
      "epoch": 19.78,
      "learning_rate": 6.345716468546537e-08,
      "loss": 0.857,
      "step": 52240
    },
    {
      "epoch": 19.78,
      "learning_rate": 6.13562953578839e-08,
      "loss": 0.9306,
      "step": 52250
    },
    {
      "epoch": 19.79,
      "learning_rate": 5.92907798538489e-08,
      "loss": 0.9057,
      "step": 52260
    },
    {
      "epoch": 19.79,
      "learning_rate": 5.726061890404255e-08,
      "loss": 0.8953,
      "step": 52270
    },
    {
      "epoch": 19.79,
      "learning_rate": 5.526581322666813e-08,
      "loss": 0.8958,
      "step": 52280
    },
    {
      "epoch": 19.8,
      "learning_rate": 5.330636352737228e-08,
      "loss": 0.9025,
      "step": 52290
    },
    {
      "epoch": 19.8,
      "learning_rate": 5.1382270499344964e-08,
      "loss": 0.909,
      "step": 52300
    },
    {
      "epoch": 19.81,
      "learning_rate": 4.9493534823230603e-08,
      "loss": 0.9035,
      "step": 52310
    },
    {
      "epoch": 19.81,
      "learning_rate": 4.764015716718362e-08,
      "loss": 0.9306,
      "step": 52320
    },
    {
      "epoch": 19.81,
      "learning_rate": 4.582213818684622e-08,
      "loss": 0.8953,
      "step": 52330
    },
    {
      "epoch": 19.82,
      "learning_rate": 4.4039478525337293e-08,
      "loss": 0.8201,
      "step": 52340
    },
    {
      "epoch": 19.82,
      "learning_rate": 4.2292178813307936e-08,
      "loss": 0.8612,
      "step": 52350
    },
    {
      "epoch": 19.82,
      "learning_rate": 4.0580239668863706e-08,
      "loss": 0.8958,
      "step": 52360
    },
    {
      "epoch": 19.83,
      "learning_rate": 3.890366169760906e-08,
      "loss": 0.8902,
      "step": 52370
    },
    {
      "epoch": 19.83,
      "learning_rate": 3.726244549263625e-08,
      "loss": 0.9169,
      "step": 52380
    },
    {
      "epoch": 19.84,
      "learning_rate": 3.5656591634547485e-08,
      "loss": 0.862,
      "step": 52390
    },
    {
      "epoch": 19.84,
      "learning_rate": 3.4086100691410605e-08,
      "loss": 0.8872,
      "step": 52400
    },
    {
      "epoch": 19.84,
      "learning_rate": 3.2550973218814504e-08,
      "loss": 0.8489,
      "step": 52410
    },
    {
      "epoch": 19.85,
      "learning_rate": 3.105120975979148e-08,
      "loss": 0.8602,
      "step": 52420
    },
    {
      "epoch": 19.85,
      "learning_rate": 2.9586810844906e-08,
      "loss": 0.8752,
      "step": 52430
    },
    {
      "epoch": 19.85,
      "learning_rate": 2.8157776992199235e-08,
      "loss": 0.8803,
      "step": 52440
    },
    {
      "epoch": 19.86,
      "learning_rate": 2.676410870720014e-08,
      "loss": 0.8906,
      "step": 52450
    },
    {
      "epoch": 19.86,
      "learning_rate": 2.5405806482914352e-08,
      "loss": 0.8627,
      "step": 52460
    },
    {
      "epoch": 19.87,
      "learning_rate": 2.4082870799857493e-08,
      "loss": 0.8945,
      "step": 52470
    },
    {
      "epoch": 19.87,
      "learning_rate": 2.2795302126021877e-08,
      "loss": 0.8908,
      "step": 52480
    },
    {
      "epoch": 19.87,
      "learning_rate": 2.1543100916887604e-08,
      "loss": 0.8649,
      "step": 52490
    },
    {
      "epoch": 19.88,
      "learning_rate": 2.032626761544476e-08,
      "loss": 0.8881,
      "step": 52500
    },
    {
      "epoch": 19.88,
      "learning_rate": 1.9144802652137916e-08,
      "loss": 0.862,
      "step": 52510
    },
    {
      "epoch": 19.88,
      "learning_rate": 1.799870644492163e-08,
      "loss": 0.9039,
      "step": 52520
    },
    {
      "epoch": 19.89,
      "learning_rate": 1.688797939922715e-08,
      "loss": 0.9219,
      "step": 52530
    },
    {
      "epoch": 19.89,
      "learning_rate": 1.5812621907995707e-08,
      "loss": 0.8901,
      "step": 52540
    },
    {
      "epoch": 19.9,
      "learning_rate": 1.4772634351623015e-08,
      "loss": 0.955,
      "step": 52550
    },
    {
      "epoch": 19.9,
      "learning_rate": 1.3768017098025887e-08,
      "loss": 0.9374,
      "step": 52560
    },
    {
      "epoch": 19.9,
      "learning_rate": 1.2798770502575608e-08,
      "loss": 0.8951,
      "step": 52570
    },
    {
      "epoch": 19.91,
      "learning_rate": 1.1864894908164559e-08,
      "loss": 0.8899,
      "step": 52580
    },
    {
      "epoch": 19.91,
      "learning_rate": 1.0966390645150703e-08,
      "loss": 0.9127,
      "step": 52590
    },
    {
      "epoch": 19.91,
      "learning_rate": 1.0103258031379792e-08,
      "loss": 0.8931,
      "step": 52600
    },
    {
      "epoch": 19.92,
      "learning_rate": 9.275497372196463e-09,
      "loss": 0.8841,
      "step": 52610
    },
    {
      "epoch": 19.92,
      "learning_rate": 8.483108960422037e-09,
      "loss": 0.8885,
      "step": 52620
    },
    {
      "epoch": 19.93,
      "learning_rate": 7.726093076365626e-09,
      "loss": 0.877,
      "step": 52630
    },
    {
      "epoch": 19.93,
      "learning_rate": 7.0044499878241245e-09,
      "loss": 0.9001,
      "step": 52640
    },
    {
      "epoch": 19.93,
      "learning_rate": 6.318179950093317e-09,
      "loss": 0.913,
      "step": 52650
    },
    {
      "epoch": 19.94,
      "learning_rate": 5.667283205945673e-09,
      "loss": 0.9434,
      "step": 52660
    },
    {
      "epoch": 19.94,
      "learning_rate": 5.0517599856192425e-09,
      "loss": 0.8381,
      "step": 52670
    },
    {
      "epoch": 19.95,
      "learning_rate": 4.47161050687317e-09,
      "loss": 0.8375,
      "step": 52680
    },
    {
      "epoch": 19.95,
      "learning_rate": 3.926834974943283e-09,
      "loss": 0.8709,
      "step": 52690
    },
    {
      "epoch": 19.95,
      "learning_rate": 3.4667818802680553e-09,
      "loss": 0.9189,
      "step": 52700
    },
    {
      "epoch": 19.96,
      "learning_rate": 2.9892173678658374e-09,
      "loss": 0.8988,
      "step": 52710
    },
    {
      "epoch": 19.96,
      "learning_rate": 2.547027326671447e-09,
      "loss": 0.8881,
      "step": 52720
    },
    {
      "epoch": 19.96,
      "learning_rate": 2.140211913126411e-09,
      "loss": 0.923,
      "step": 52730
    },
    {
      "epoch": 19.97,
      "learning_rate": 1.7687712711378367e-09,
      "loss": 0.9279,
      "step": 52740
    },
    {
      "epoch": 19.97,
      "learning_rate": 1.43270553210062e-09,
      "loss": 0.9395,
      "step": 52750
    },
    {
      "epoch": 19.98,
      "learning_rate": 1.132014814897442e-09,
      "loss": 0.8903,
      "step": 52760
    },
    {
      "epoch": 19.98,
      "learning_rate": 8.666992258987705e-10,
      "loss": 0.93,
      "step": 52770
    },
    {
      "epoch": 19.98,
      "learning_rate": 6.367588589739626e-10,
      "loss": 0.9117,
      "step": 52780
    },
    {
      "epoch": 19.99,
      "learning_rate": 4.421937954579569e-10,
      "loss": 0.9171,
      "step": 52790
    },
    {
      "epoch": 19.99,
      "learning_rate": 2.83004104184581e-10,
      "loss": 0.8883,
      "step": 52800
    },
    {
      "epoch": 19.99,
      "learning_rate": 1.5918984145324444e-10,
      "loss": 0.8973,
      "step": 52810
    },
    {
      "epoch": 20.0,
      "learning_rate": 7.075105107334778e-11,
      "loss": 0.8681,
      "step": 52820
    }
  ],
  "logging_steps": 10,
  "max_steps": 52820,
  "num_train_epochs": 20,
  "save_steps": 500,
  "total_flos": 3.895351829972091e+17,
  "trial_name": null,
  "trial_params": null
}
