{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 1349,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03,
      "grad_norm": 1.3075611591339111,
      "learning_rate": 0.00019999891370152373,
      "loss": 3.143,
      "step": 10
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.6303632259368896,
      "learning_rate": 0.00019999565482969577,
      "loss": 2.3399,
      "step": 20
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.3852665424346924,
      "learning_rate": 0.00019999022345531834,
      "loss": 1.7321,
      "step": 30
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7239919900894165,
      "learning_rate": 0.00019998261969639324,
      "loss": 1.3512,
      "step": 40
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5635300278663635,
      "learning_rate": 0.00019997284371811954,
      "loss": 1.3388,
      "step": 50
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6905417442321777,
      "learning_rate": 0.00019996089573288983,
      "loss": 1.2353,
      "step": 60
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5719131827354431,
      "learning_rate": 0.00019994677600028568,
      "loss": 1.204,
      "step": 70
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.7672732472419739,
      "learning_rate": 0.000199930484827072,
      "loss": 1.2053,
      "step": 80
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5732651948928833,
      "learning_rate": 0.0001999120225671903,
      "loss": 1.1687,
      "step": 90
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5168470740318298,
      "learning_rate": 0.00019989138962175104,
      "loss": 1.2147,
      "step": 100
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6930299401283264,
      "learning_rate": 0.00019986858643902502,
      "loss": 1.1572,
      "step": 110
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.49699515104293823,
      "learning_rate": 0.00019984361351443343,
      "loss": 1.1542,
      "step": 120
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5159195065498352,
      "learning_rate": 0.00019981647139053738,
      "loss": 1.144,
      "step": 130
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.4984678328037262,
      "learning_rate": 0.00019978716065702568,
      "loss": 1.1546,
      "step": 140
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4763847887516022,
      "learning_rate": 0.00019975568195070253,
      "loss": 1.1143,
      "step": 150
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5145814418792725,
      "learning_rate": 0.00019972203595547335,
      "loss": 1.107,
      "step": 160
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5763629674911499,
      "learning_rate": 0.00019968622340232995,
      "loss": 1.1037,
      "step": 170
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5307971835136414,
      "learning_rate": 0.0001996482450693348,
      "loss": 1.1021,
      "step": 180
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.4900030493736267,
      "learning_rate": 0.000199608101781604,
      "loss": 1.1181,
      "step": 190
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.44996020197868347,
      "learning_rate": 0.00019956579441128943,
      "loss": 1.1382,
      "step": 200
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5349639654159546,
      "learning_rate": 0.00019952132387755965,
      "loss": 1.1026,
      "step": 210
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.46941131353378296,
      "learning_rate": 0.00019947469114658017,
      "loss": 1.1339,
      "step": 220
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6132367849349976,
      "learning_rate": 0.00019942589723149232,
      "loss": 1.1629,
      "step": 230
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.5833242535591125,
      "learning_rate": 0.00019937494319239113,
      "loss": 1.1326,
      "step": 240
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.4129420220851898,
      "learning_rate": 0.00019932183013630255,
      "loss": 1.1276,
      "step": 250
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.5098044872283936,
      "learning_rate": 0.00019926655921715923,
      "loss": 1.1047,
      "step": 260
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.48354601860046387,
      "learning_rate": 0.0001992091316357754,
      "loss": 1.1527,
      "step": 270
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.4980199337005615,
      "learning_rate": 0.00019914954863982107,
      "loss": 1.0593,
      "step": 280
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.4511754512786865,
      "learning_rate": 0.0001990878115237945,
      "loss": 1.1236,
      "step": 290
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5281345248222351,
      "learning_rate": 0.0001990239216289944,
      "loss": 1.1307,
      "step": 300
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.49406754970550537,
      "learning_rate": 0.0001989578803434907,
      "loss": 1.1253,
      "step": 310
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.40307730436325073,
      "learning_rate": 0.00019888968910209434,
      "loss": 1.1073,
      "step": 320
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.4692971110343933,
      "learning_rate": 0.00019881934938632614,
      "loss": 1.0946,
      "step": 330
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.49514269828796387,
      "learning_rate": 0.00019874686272438466,
      "loss": 1.1216,
      "step": 340
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.4385001063346863,
      "learning_rate": 0.00019867223069111288,
      "loss": 1.0631,
      "step": 350
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.5237520933151245,
      "learning_rate": 0.00019859545490796411,
      "loss": 1.1025,
      "step": 360
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.45556092262268066,
      "learning_rate": 0.00019851653704296664,
      "loss": 1.1368,
      "step": 370
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.4565790295600891,
      "learning_rate": 0.00019843547881068764,
      "loss": 1.1072,
      "step": 380
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.4629579186439514,
      "learning_rate": 0.00019835228197219573,
      "loss": 1.0693,
      "step": 390
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.484601229429245,
      "learning_rate": 0.00019826694833502295,
      "loss": 1.0472,
      "step": 400
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.5221013426780701,
      "learning_rate": 0.00019817947975312526,
      "loss": 1.0947,
      "step": 410
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.47265195846557617,
      "learning_rate": 0.00019808987812684246,
      "loss": 1.1088,
      "step": 420
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.48853638768196106,
      "learning_rate": 0.00019799814540285668,
      "loss": 1.0581,
      "step": 430
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.45954108238220215,
      "learning_rate": 0.00019790428357415032,
      "loss": 1.1373,
      "step": 440
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.4909793436527252,
      "learning_rate": 0.00019780829467996262,
      "loss": 1.0918,
      "step": 450
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.4872545599937439,
      "learning_rate": 0.00019771018080574535,
      "loss": 1.1121,
      "step": 460
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.48949578404426575,
      "learning_rate": 0.00019760994408311757,
      "loss": 1.1256,
      "step": 470
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.39528682827949524,
      "learning_rate": 0.00019750758668981924,
      "loss": 1.1134,
      "step": 480
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.5441740155220032,
      "learning_rate": 0.000197403110849664,
      "loss": 1.0463,
      "step": 490
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.48039916157722473,
      "learning_rate": 0.00019729651883249074,
      "loss": 1.1238,
      "step": 500
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.5000181794166565,
      "learning_rate": 0.00019718781295411438,
      "loss": 1.0879,
      "step": 510
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.47498947381973267,
      "learning_rate": 0.00019707699557627555,
      "loss": 1.0924,
      "step": 520
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.4218917787075043,
      "learning_rate": 0.00019696406910658918,
      "loss": 1.0946,
      "step": 530
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.5329504609107971,
      "learning_rate": 0.00019684903599849233,
      "loss": 1.1378,
      "step": 540
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.5263418555259705,
      "learning_rate": 0.0001967318987511908,
      "loss": 1.0256,
      "step": 550
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.4427650272846222,
      "learning_rate": 0.00019661265990960483,
      "loss": 1.0445,
      "step": 560
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.4551290273666382,
      "learning_rate": 0.00019649132206431394,
      "loss": 1.1043,
      "step": 570
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.593726396560669,
      "learning_rate": 0.00019636788785150038,
      "loss": 1.0986,
      "step": 580
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.41312745213508606,
      "learning_rate": 0.0001962423599528921,
      "loss": 1.0529,
      "step": 590
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.46348801255226135,
      "learning_rate": 0.00019611474109570444,
      "loss": 1.0872,
      "step": 600
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.47716087102890015,
      "learning_rate": 0.00019598503405258077,
      "loss": 1.0558,
      "step": 610
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.4998435080051422,
      "learning_rate": 0.00019585324164153237,
      "loss": 1.0639,
      "step": 620
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.41655024886131287,
      "learning_rate": 0.00019571936672587716,
      "loss": 1.0767,
      "step": 630
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.41480180621147156,
      "learning_rate": 0.00019558341221417744,
      "loss": 1.1144,
      "step": 640
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.42585453391075134,
      "learning_rate": 0.0001954453810601768,
      "loss": 1.0908,
      "step": 650
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.4502318799495697,
      "learning_rate": 0.00019530527626273591,
      "loss": 1.111,
      "step": 660
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.39226168394088745,
      "learning_rate": 0.00019516310086576733,
      "loss": 1.0432,
      "step": 670
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.5012441277503967,
      "learning_rate": 0.00019501885795816936,
      "loss": 1.0818,
      "step": 680
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.44976887106895447,
      "learning_rate": 0.00019487255067375907,
      "loss": 1.008,
      "step": 690
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.42139679193496704,
      "learning_rate": 0.000194724182191204,
      "loss": 1.0488,
      "step": 700
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.5623383522033691,
      "learning_rate": 0.00019457375573395333,
      "loss": 1.0838,
      "step": 710
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.40040522813796997,
      "learning_rate": 0.00019442127457016767,
      "loss": 1.1068,
      "step": 720
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.4295685291290283,
      "learning_rate": 0.00019426674201264814,
      "loss": 1.0237,
      "step": 730
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.4583430290222168,
      "learning_rate": 0.00019411016141876437,
      "loss": 1.0699,
      "step": 740
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.5310168862342834,
      "learning_rate": 0.00019395153619038158,
      "loss": 1.0261,
      "step": 750
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.4459216892719269,
      "learning_rate": 0.00019379086977378663,
      "loss": 1.0722,
      "step": 760
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.442926824092865,
      "learning_rate": 0.00019362816565961322,
      "loss": 1.0408,
      "step": 770
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.4096292555332184,
      "learning_rate": 0.00019346342738276592,
      "loss": 1.0738,
      "step": 780
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.5359726548194885,
      "learning_rate": 0.0001932966585223436,
      "loss": 1.0907,
      "step": 790
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.43491387367248535,
      "learning_rate": 0.00019312786270156136,
      "loss": 1.0343,
      "step": 800
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.5080567598342896,
      "learning_rate": 0.0001929570435876721,
      "loss": 1.0434,
      "step": 810
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.4781583547592163,
      "learning_rate": 0.00019278420489188668,
      "loss": 1.0415,
      "step": 820
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.39566144347190857,
      "learning_rate": 0.0001926093503692933,
      "loss": 1.0718,
      "step": 830
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.46392521262168884,
      "learning_rate": 0.00019243248381877606,
      "loss": 1.073,
      "step": 840
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.5258653163909912,
      "learning_rate": 0.00019225360908293218,
      "loss": 1.0335,
      "step": 850
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.4365910291671753,
      "learning_rate": 0.00019207273004798872,
      "loss": 1.0429,
      "step": 860
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.43422266840934753,
      "learning_rate": 0.00019188985064371816,
      "loss": 1.0758,
      "step": 870
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.4220462739467621,
      "learning_rate": 0.00019170497484335278,
      "loss": 1.0639,
      "step": 880
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.40976470708847046,
      "learning_rate": 0.0001915181066634986,
      "loss": 1.0469,
      "step": 890
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.4362642467021942,
      "learning_rate": 0.00019132925016404804,
      "loss": 1.0293,
      "step": 900
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.46935397386550903,
      "learning_rate": 0.0001911384094480916,
      "loss": 1.0348,
      "step": 910
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.4438968598842621,
      "learning_rate": 0.00019094558866182893,
      "loss": 1.0386,
      "step": 920
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.471836119890213,
      "learning_rate": 0.00019075079199447846,
      "loss": 1.0528,
      "step": 930
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.40119388699531555,
      "learning_rate": 0.00019055402367818672,
      "loss": 1.0698,
      "step": 940
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.47413596510887146,
      "learning_rate": 0.0001903552879879362,
      "loss": 0.9962,
      "step": 950
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.5058668851852417,
      "learning_rate": 0.00019015458924145228,
      "loss": 1.062,
      "step": 960
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.42623311281204224,
      "learning_rate": 0.00018995193179910998,
      "loss": 1.0893,
      "step": 970
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.3833693563938141,
      "learning_rate": 0.00018974732006383862,
      "loss": 1.093,
      "step": 980
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.4372406303882599,
      "learning_rate": 0.00018954075848102658,
      "loss": 1.082,
      "step": 990
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.4586900472640991,
      "learning_rate": 0.00018933225153842446,
      "loss": 1.0778,
      "step": 1000
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.43793752789497375,
      "learning_rate": 0.00018912180376604777,
      "loss": 1.08,
      "step": 1010
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3763284683227539,
      "learning_rate": 0.00018890941973607843,
      "loss": 1.0367,
      "step": 1020
    },
    {
      "epoch": 3.05,
      "grad_norm": 0.4240141212940216,
      "learning_rate": 0.00018869510406276536,
      "loss": 1.0402,
      "step": 1030
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.40305736660957336,
      "learning_rate": 0.00018847886140232437,
      "loss": 1.0191,
      "step": 1040
    },
    {
      "epoch": 3.11,
      "grad_norm": 0.4922249913215637,
      "learning_rate": 0.00018826069645283688,
      "loss": 1.0051,
      "step": 1050
    },
    {
      "epoch": 3.14,
      "grad_norm": 0.4305824041366577,
      "learning_rate": 0.00018804061395414796,
      "loss": 1.0107,
      "step": 1060
    },
    {
      "epoch": 3.17,
      "grad_norm": 0.4487874507904053,
      "learning_rate": 0.00018781861868776326,
      "loss": 1.0711,
      "step": 1070
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.4312799274921417,
      "learning_rate": 0.0001875947154767452,
      "loss": 1.0328,
      "step": 1080
    },
    {
      "epoch": 3.23,
      "grad_norm": 0.39055824279785156,
      "learning_rate": 0.00018736890918560808,
      "loss": 1.0223,
      "step": 1090
    },
    {
      "epoch": 3.26,
      "grad_norm": 0.469806432723999,
      "learning_rate": 0.0001871412047202125,
      "loss": 1.021,
      "step": 1100
    },
    {
      "epoch": 3.29,
      "grad_norm": 0.39434587955474854,
      "learning_rate": 0.00018691160702765877,
      "loss": 1.0415,
      "step": 1110
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.42390188574790955,
      "learning_rate": 0.00018668012109617933,
      "loss": 1.0831,
      "step": 1120
    },
    {
      "epoch": 3.35,
      "grad_norm": 0.4508221745491028,
      "learning_rate": 0.0001864467519550305,
      "loss": 1.0665,
      "step": 1130
    },
    {
      "epoch": 3.38,
      "grad_norm": 0.456382155418396,
      "learning_rate": 0.00018621150467438308,
      "loss": 1.0191,
      "step": 1140
    },
    {
      "epoch": 3.41,
      "grad_norm": 0.4391513764858246,
      "learning_rate": 0.0001859743843652124,
      "loss": 1.0308,
      "step": 1150
    },
    {
      "epoch": 3.44,
      "grad_norm": 0.45625409483909607,
      "learning_rate": 0.000185735396179187,
      "loss": 1.0133,
      "step": 1160
    },
    {
      "epoch": 3.47,
      "grad_norm": 0.4622664153575897,
      "learning_rate": 0.00018549454530855696,
      "loss": 1.036,
      "step": 1170
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.4713175296783447,
      "learning_rate": 0.00018525183698604096,
      "loss": 1.0402,
      "step": 1180
    },
    {
      "epoch": 3.53,
      "grad_norm": 0.4186880886554718,
      "learning_rate": 0.0001850072764847126,
      "loss": 1.07,
      "step": 1190
    },
    {
      "epoch": 3.56,
      "grad_norm": 0.4677225351333618,
      "learning_rate": 0.00018476086911788585,
      "loss": 1.0476,
      "step": 1200
    },
    {
      "epoch": 3.59,
      "grad_norm": 0.4261798858642578,
      "learning_rate": 0.00018451262023899974,
      "loss": 1.0704,
      "step": 1210
    },
    {
      "epoch": 3.62,
      "grad_norm": 0.4047650694847107,
      "learning_rate": 0.00018426253524150176,
      "loss": 1.0369,
      "step": 1220
    },
    {
      "epoch": 3.65,
      "grad_norm": 0.45297375321388245,
      "learning_rate": 0.000184010619558731,
      "loss": 0.957,
      "step": 1230
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.4475320875644684,
      "learning_rate": 0.0001837568786637999,
      "loss": 1.0196,
      "step": 1240
    },
    {
      "epoch": 3.71,
      "grad_norm": 0.4451870918273926,
      "learning_rate": 0.00018350131806947536,
      "loss": 1.0314,
      "step": 1250
    },
    {
      "epoch": 3.74,
      "grad_norm": 0.4011303782463074,
      "learning_rate": 0.00018324394332805912,
      "loss": 1.0676,
      "step": 1260
    },
    {
      "epoch": 3.77,
      "grad_norm": 0.4362086355686188,
      "learning_rate": 0.00018298476003126695,
      "loss": 1.0406,
      "step": 1270
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.4243050515651703,
      "learning_rate": 0.00018272377381010725,
      "loss": 1.0624,
      "step": 1280
    },
    {
      "epoch": 3.83,
      "grad_norm": 0.4446929097175598,
      "learning_rate": 0.0001824609903347587,
      "loss": 1.0577,
      "step": 1290
    },
    {
      "epoch": 3.85,
      "grad_norm": 0.4145580530166626,
      "learning_rate": 0.00018219641531444714,
      "loss": 1.0161,
      "step": 1300
    },
    {
      "epoch": 3.88,
      "grad_norm": 0.48749443888664246,
      "learning_rate": 0.00018193005449732136,
      "loss": 1.042,
      "step": 1310
    },
    {
      "epoch": 3.91,
      "grad_norm": 0.4403590261936188,
      "learning_rate": 0.0001816619136703283,
      "loss": 1.0185,
      "step": 1320
    },
    {
      "epoch": 3.94,
      "grad_norm": 0.43967655301094055,
      "learning_rate": 0.00018139199865908743,
      "loss": 1.0225,
      "step": 1330
    },
    {
      "epoch": 3.97,
      "grad_norm": 0.418138712644577,
      "learning_rate": 0.0001811203153277641,
      "loss": 1.033,
      "step": 1340
    }
  ],
  "logging_steps": 10,
  "max_steps": 6740,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "total_flos": 1.897223057281843e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
